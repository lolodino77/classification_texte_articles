message,length
"But if there are cases like (1), there will surely also be cases where the
moral considerations in favor of _ϕ_ ing do not rise to the level of a
requirement, but are sufficient to override the _N_ -prohibition. In those
cases, presumably:",239
"However, there is another story possible. Perhaps in the case where the moral
considerations are at too low a level to override the _N_ -prohibition, we can
still have _moral_ permission to _ϕ_ , but that permission no longer overrides
the _N_ -prohibition. On this story, there are two kinds of cases, in both of
which we have moral permission, but in one case the moral permission comes
along with sufficiently strong moral considerations to override the _N_
-prohibition, while in the other it does not. On this story, moral requirement
always overrides non-moral reasons; but whether moral considerations override
non-moral considerations depends on the relative strengths of the two sets of
considerations.",711
"where “ _N_ ” is some norm like that of prudence or etiquette. In this case,
the moral requirement of _ϕ_ ing overrides the _N_ -prohibition on _ϕ_ ing.
Thus, you might be rude to make a point of justice or sacrifice your life for
the sake of justice.",251
"People often talk of moral norms as overriding. The paradigm kind of case
seems to be like this:",96
"I don’t want to say that all norms are moral norms. But it may well be that
all norms governing the functioning of the will are moral norms.",140
"So far so good. Moral norms can override non-moral norms in two ways: by
creating a moral requirement contrary to the non-moral norms or by creating a
moral permission contrary to the non-moral norms.",200
"But now consider this. What happens if the moral considerations are at an even
lower level, a level insufficient to override the _N_ -prohibition? (E.g.,
what if to save someone’s finger you would need to sacrifice your arm?) Then,
it seems:",241
"Still, consider this. The judgment whether moral considerations override the
non-moral ones seems to be an eminently _moral_ judgment. It is the person
with _moral_ virtue who is best suited to figuring out whether such overriding
happens. But what happens if morality says that the moral considerations do
not override the _N_ -prohibition? Is that not a case of morality giving its
endorsement to the _N_ -prohibition, so that the _N_ -prohibition would rise
to the level of a moral prohibition as well? But if so, then that pushes us
back to the previous story where it is reasonable to take _N_ -considerations
to be subsumed into moral considerations.",656
"But this would be quite interesting. It would imply that in the absence of
sufficient moral considerations in favor of _ϕ_ ing, an _N_ -prohibition would
automatically generate a _moral_ prohibition. But this means that the real
normative upshot in all three cases is given by morality, and the _N_ -norms
aren’t actually doing any independent normative work. This suggests strongly
that on such a picture, we should take the _N_ -norms to be simply a species
of moral norms.",475
"Cases of supererogation look like that: you are morally permitted to do
something contrary to prudential norms, but not required to do so.",138
"This is a fun puzzle. It seems like David Lewis’ convention work, or Thomas
Schelling’s coordination and focal points stuff must be relevant.",141
"In ordinary life, this problem doesn’t arise as much, because as long as at
least one person is more typical, and hence takes promises to have reason-
giving force, or if public opinion is around to enforce promise-keeping, then
the issue doesn’t come up. But I think there is a lesson here and in the
[previous post](http://alexanderpruss.blogspot.com/2022/12/utilitarianism-and-
communication.html): for many ordinary practice, the utilitarian is free-
riding on the non-utilitarians.",486
"This means that in cases like this, with full transparency of behavioral
tendencies, utilitarians and amoral egoists will do well to brainwash or
hypnotize themselves into promise-keeping.",188
"Take first the case where they are both perfect amoral egoists. Amoral egoists
don’t care about promises. So the fact that an amoral egoist promised to raise
the right hand is no evidence at all that they will raise the right hand,
unless there is something in it for them. But is there anything in it for
them? Well, if Bob raises his right hand, then there is something in it for
Alice to raise her right hand. But note that this conditional is true
_regardless_ of whether they’ve made any promises to each other, and it is
equally true that if Bob raises his left hand, then there is something in it
for Alice to raise her left hand.",637
"The promise is simply irrelevant here. It is true that in normal
circumstances, it makes sense for egoists to keep promises in order to fool
people into thinking that they have morality. But I’ve assumed full shared
knowledge of each other’s tendencies here, and so no such considerations apply
here.",300
"It is true that if Alice expects Bob to expect her to keep her promise, then
Alice will expect Bob to raise his right hand, and hence she should raise her
right hand. But since she’s known to be an amoral egoist, there is no reason
for Bob to expect Alice to keep her promise. And the same vice versa.",301
"They confer before the game and promise to one another to raise the right
hand. They go into their separate rooms. And what happens next?",137
"What if they are utilitarians? It makes no difference. Since in this case both
always get the same outcome, there is no difference between utilitarians and
amoral egoists.",171
"Suppose Alice and Bob are perfect utilitarians or perfect amoral egoists in
any combination. They are about to play a game where they raise a left hand or
a right hand in a separate booth, and if they both raise the same hand, they
both get something good. Otherwise, nobody gets that good. Nobody sees what
they’re doing in the game: the game is fully automated. And they both have
full shared knowledge of the above.",418
"My feeling is it's not hard to solve -- as long as you don't place artificial
restrictions on what counts as a reason, in the way the utilitarian or egoist
does.",161
"If the above argument is correct—and I am far from confident of that, since it
makes my head spin—then we have an argument that in order for communication to
be possible, at least one of the agents must be convention-bound. One way to
be convention-bound is to think, in a way utilitarians don’t, that convention
provides non-consequentialist reasons. Another way is to be an akratic
utilitarian, addicted to following convention. Now, the possibility of
communication is essential for the utility of the kinds of social animals that
we are. Thus we have an argument that at least some subjective utilitarians
will have to become convention-bound, either by getting themselves to believe
that convention has normative force or by being akratic.",744
"This is not a refutation of utilitarianism. Utilitarians, following Parfit,
are willing to admit that there could be utility maximization reasons to cease
to be utilitarian. But it is, nonetheless, really interesting if something as
fundamental as communication provides such a reason.",285
"But I’ve been trying really hard to figure out how is it that such a
conventional behavior would indicate to Bob that the lion is on the left path.",147
"Here is a brief way to put it. For Alice and Bob, convention carries no weight
except as a predictor of the behavior of convention-bound people, i.e., people
who are not subjectively perfect utilitarians. It is shared knowledge between
Alice and Bob that neither is convention-bound. So convention is irrelevant to
the problem at hand, the problem of getting Bob to avoid the lion. But there
is no solution to the problem absent convention or some other tool unavailable
to the utilitarian (a natural law theorist might claim that mimicry and
pointing are _natural_ indicators).",578
"Alice and Bob are both perfect Bayesian epistemic agents and subjectively
perfect utilitarians (i.e., they always do what by their lights maximizes
expected utility). Bob is going to Megara. He comes to a crossroads, from
which two different paths lead to Megara. On exactly one of these paths there
is a man-eating lion and on the other there is nothing special. Alice knows
which path has the lion. The above is all shared knowledge for Alice and Bob.",453
"Suppose the lion is on the left path. What should Alice do? Well, if she can,
she should bring it about that Bob takes the right path, because doing so
would clearly maximize utility. How can she do that? An obvious suggestion:
Engage in a conventional behavior indicating a where the lion is, such as
pointing left and roaring, or saying “Hail well-met traveler, lest you be
eaten, I advise you to avoid the leftward leonine path.”",432
"I put this as an issue about communication. But maybe it’s really an issue
about communication but coordination. Maybe the literature on repeated games
might help in some way.",175
"If Alice were a typical human being, she would have a habit of using
established social conventions to tell the truth about things, except perhaps
in exceptional cases (such as the murderer at the door), and so her use of the
conventional lion-indicating behavior would correlate with the presence of
lions, and would provide Bob with evidence of the presence of lions. But Alice
is not a typical human being. She is a subjectively perfect utilitarian.
Social convention has no normative force for Alice (or Bob, for that matter).
Only utility does.",549
"Similarly, if Bob were a typical human being, he would have a habit of forming
his beliefs on the basis of testimony interpreted via established social
conventions absent reason to think one is being misinformed, and so Alice’s
engaging in conventional left-path lion-indicating behavior would lead Bob to
think there is a lion on the left, and hence to go on the right. And while it
woudl still be true that social convention has no normative force for Alice,
Alice would think have reason to think that Bob follows convention, and for
the sake of maximizing utility would suit her behavior to his. But Bob is a
perfect Bayesian. He doesn’t form beliefs out of habit. He updates on
evidence. And given that Alice is not a typical human being, but a
subjectively perfect utilitarian, it is unclear to me why her engaging in the
conventional left-path lion-indicating behavior is more evidence for the lion
being on the left than for the lion being on the right. For Bob knows that
convention carries no normative force for Alice.",1029
"I think that's correct. The more one concentrates on good form, the more
detrimental negative transfer becomes. This also applies in martial arts like
Tae Kwon Do, on the self-defense side, whereby training to 'pull' kicks and
punches (i.e. to safeguard your training partner), negatively transfers to
real-life situations.",323
I have no idea if anything like this transfer works for other people.,69
"And I _have_ noticed some transfer of skills and maybe even of the virtue of
patience both between the various sports and between the sports and other
repetitive activities, such as grading. There is a distinctive feeling I have
when I am half-way through something, and where I am fairly confident I can
finish it, and a kind of relaxation past the half-way point where I become
more patient, and time seems to flow “better”. For instance, I can compare how
tired I feel half-way through a long set of climbs and how tired I feel half-
way through a 2 km swim, and the comparison can give me some strength. Similar
positive thinking can happen while grading, things like “I can do it” or
“There isn’t all that much left.” Though there are also differences between
the sports and the grading, because in grading the quality of the work matters
a lot more, and since I am not racing against myself so there is no point of a
burst of speed at the end if I find myself with an excess of energy. Pacing is
also much less important for grading.",1039
"I do have a piece of anecdotal data, though. I’ve been doing some endurance-
ish sports. Nothing nearly like a marathon, but things like swimming 2-3 km,
or climbing for an hour, typically (but [not
always](http://alexanderpruss.blogspot.com/2022/12/a-new-but-uncertified-
world-record.html)) competing against myself.",318
"There are empirical indications that various skills and maybe even virtues are
pretty domain specific. It seems that being good at reasoning about one thing
need not make one good at reasoning about another, even if the reasoning is
formally equivalent.",253
"BTW, it may depend on how much one keeps to proper form in the different
racquet sports. Someone like me who plays lots of different racquet sports
(regularly: badminton; semi-regularly: tennis, racquetball, table tennis,
pickleball; used to do occasional squash until our university's one court
closed as nobody but my son and I played; used to do crossminton during
Covid), maybe at an upper beginner level, perhaps does not have enough good
form in any one of the sports for it to matter. I hadn't played much tennis
this fall, but I played a fair amount of badminton, and seemed to find my
tennis improved when I got back to it, maybe due to transfer of thinking about
things like ""how do I hit the shuttle away from where my opponents are"", or
maybe just due to general fitness improvement.",795
"This is akin to the 'positive transfer' of skills, as discussed with the sport
science. So-called 'negative transfer', its opposite, is to be avoided at all
costs. For example, if I try to play squash to improve my racket skills, I
will ruin my tennis game. The racket skills are subtly different, due to the
'wrist flick' in the squash technique.",347
"I've wondered about such incompossible goods myself. Weightlifting can reduce
agility, for example, and while being tall is great for basketball, it is not
good for weightlifting. Various niches seem to exist. It does raise the
question of what a perfect human being consists of, however. Are some of these
""perfections"" merely accidental in the sense that they exploit what are
normatively speaking (in relation to human nature) flaws? We know some sports
are actually bad for the human body, or neglect the overall health of the
body. Certain perfections seem to be perfections only in an analogical sense,
perhaps something along the lines of being a ""good thief"" or an ""effective
deceiver"".  
  
Where intelligence is concerned, I am tempted to argue against incompossible
goods either because intelligence isn't like that or for similar natural law
reasons, but even more strongly, especially on account of the centrality of
intelligence to humanity.  
  
Consider your favorite déformation professionnelle, which, I submit, is more
of a result of imprudence, habit, ignorance, lack of practice using other
methods, and even effeminacy and arrogance. Someone with a rigorous
philosophical education is less likely to try to pigeonhole reality into the
reductive and simplified straitjacket of our physical models in the manner of
at least some physicists who generally lack serious exposure to philosophy and
may even hold it in contempt out of ignorance. A physicist may also be tempted
to pigeonhole simply because of pride; if he isn't any good at metaphysics,
then his thoughts on a metaphysical subject matter aren't likely to be very
valuable or interesting, and that stings the prideful man accustomed to
feeling like a hotshot. There is also the threat of seeing one's own field put
in its methodological place, so to speak, deflating any pretensions to the
kind of ultimacy that metaphysics lays claim to. A competent physics may also
derive greater pleasure from exercising his specialized competence and choose
his methods simply on the basis of what feels good and now what is called for
by a problem. So here the question resurfaces: is there an incompossibility
between being a good physicist and a good metaphysician? I suspect there isn't
intrinsically, even if that is often the case which I suspect is rather a
result of how one's time is spent. But even if it is the case, because general
knowledge is superior and more worthy of human attention than specialized
knowledge, we could argue that competence in physics that occurs at the
expense of philosophical depth is, in fact, a kind of failure to attain human
excellence by failing to devote proportional attention and effort to the kinds
of knowledge that are most essential, and in doing so, risking intellectual
deformation in important and even necessary matters.",2844
"**Final remark:** The argument applies to any exclusive and exhaustive
division of reasons into “simple” (i.e., non-combination) types.",135
"**Response:** That may be right in the simple case. But now imagine that the
“red” set is a saturated nonmeasurable subset of the spinner edge, and the
“green” set is also such. A saturated nonmeasurable subset has no reasonable
probability assignment, not even a non-trivial range of probabilities like
from 1/3 to 1/2 (at best we can assign it the full range from 0 to 1). Now the
reason-giving strength of a chancy outcome is proportionate to the
probability. But in the saturated nonmeasurable case, there is no probability,
and hence no meaningful strength for the red-based reason or for the green-
based reason. But there is a meaningful strength for the red-or-green moral-
cum-prudential reason. The red-or-green-based reason hence does not reduce to
two separate reasons, one moral and one prudential.",811
"One might think that reasons for action are exhaustively and exclusively
divided into the moral and the prudential. Here is a problem with this.
Suppose that you have a spinner divided into red and green areas. If you spin
it and it lands into red, something nice happens to you; if it lands on green,
something nice happens to a deserving stranger. You clearly have reason to
spin the spinner. But, assuming the division of reasons, your reason for
spinning it is neither moral nor prudential.",494
"So what should we say? One possibility is to say that there are _only_ reasons
of one type, say the moral. I find that attractive. Then benefits to yourself
also give you _moral_ reason to act, and so you simply have a moral reason to
spin the spinner. Another possibility is to say that in addition to moral and
prudential reasons there is some third class of “mixed” or “combination”
reasons.",394
"Now, one might have technical worries about saturated nonmeasurable sets
figuring in decisions. I do. (E.g., see the Axiom of Choice chapter in my
infinity book.) But now instead of supposing saturated nonmeasurable sets,
suppose a case where an agent subjectively has literally no idea whether some
event _E_ will happen—has no probability assignment for _E_ whatsoever, not
even a ranged one (except for the full range from 0 to 1). The spinner landing
on a set believed to be saturated nonmeasurable might be an example of such a
case, but the case could be more humdrum—it’s just a case of extreme
agnosticism. And now suppose that the agent is told that if they so opt, then
they will get something nice on _E_ and a deserving stranger will get
something nice otherwise.",775
"**Objection:** The chance _p_ of the spinner landing on red is a prudential
reason and the chance 1 − _p_ of its landing on green is a moral reason. So
you have _two_ reasons, one moral and one prudential.",205
"And because pure (Tarskian) geometry is decidable, while the theory of the
positive integers is not decidable, the positive integers are not definable in
terms of pure geometry, so we cannot eliminate the quantification over
positive integers. In fact, it is known that the rational numbers are not
definable in terms of pure geometry either, so neither the incommensurability
formulation nor theory irrationality formulation is a purely geometric claim.",454
"I was thinking of the decidability of Th(N), where N is our ""intended"" model
of the naturals, not of the decidability of any particular recursive
axiomatization. (Th(N) is not recursively axiomatizable, of course.)",214
"It is correct to say that the Greeks discovered an incommensurability fact.
But it is, I think, worth noting that this incommensurability fact is not
really geometric fact: it is a geometric-cum-arithmetical fact. Here is why.
The claim that two line segments are commensurable says that there are
positive integers _m_ and _n_ such that _m_ copies of the first segment have
the same length as _n_ copies of the second. This claim is essentially
arithmetical in that it quantifies over positive integers.",504
"Don't you rather mean _""Th(something)""_ to be our ""intended"" model of
""something"", such that ""something"" could be the naturals N, such that Th(N) is
our ""intended"" model of naturals N?!?  
  
Why isn't Th(N) recursively axiomattizaböe though?!?",244
"I think it is sometimes said that it is anachronistic to attribute to the
ancient Greeks the discovery that the square root of two is irrational,
because what they discovered was a properly _geometrical_ fact, that the side
and diagonal of a square are incommensurable, rather than a fact about real
numbers.",308
"About half-way through, I ducked into the storage area inside the rock and
changed to a dry shirt.",98
"I just noticed that you mentioned capturing video footage for Guinness, so I
suppose that answers my prior question. I apologize for the oversight.
Congrats again!",163
"A Kindle Fire running a pre-release version of my [Giant
Stopwatch](https://play.google.com/store/apps/details?id=omegacentauri.mobi.simplestopwatch&hl=en_US&gl=US)
app provided unofficial timing for audience to see and for my pacing. I had to
modify the app to have a periodic beep to meet Guinness's requirements of an
audible stop signal.",341
"I wore moderately worn (one small hole) and comfortable 5.10 Anasazi shoes, a
Camp USA Energy harness, shorts and a T-shirt. (I have not received any
sponsorship.) My belayer used a tube-style device and wore belay gloves.",222
"The top of the wall is 15.13 meters vertically from the ground (as measured by
a geology grad student), at 3.5 degree slab.",123
"As we say in Australia, you are 'a gun'! Have you ever thought about writing
philosophically about climbing? Perhaps even just in the vaguely existential
vein that Murakami mines in his 'What I Talk About When I Talk About Running'.",232
"I climbed in sets of 10. The planned pace was 8:18 per set and a 44-45 second
rest between sets (clock runs during rests,), averaging at 49.8 seconds per
climb including descent. I was always ahead of pace, and I occasionally took a
mini break at the mid-point time if I was too far ahead.",289
"On the ground there was a sheet of paper with the start and end times of each
break printed in large letters (calculated by [this
script](https://gist.github.com/arpruss/10e364904dfcc19b043a594232e0acde)), as
well as the mid-point time for each set of 10 to keep me better on pace.",281
"Wow, I had no idea that their confirmation process was so extensive! I wonder
what purpose the ""notable moments"" list is meant to be playing, especially
since they already have the video itself.",194
"I am guessing that if one is doing one of the longer records, say an 8 hour
one, they aren't going to want to watch all of the video, except maybe at high
speed, and so looking at notable moments might make sense.  
  
I expect they also choose some small fraction of the records to feature on
social media, and I could see them using the notable moments list to extract
video for that.  
  
I pity those who don't have programming skills, though. Inserting a running
count of laps into a video by manually inserting a title into the video at
each point with a video editor program would be as much an endurance sport as
actually doing the laps. It took me a while to type up the times of all the
climb tops, but after that I just had the computer automatically generate a
video track for the inset window with time and counts.",827
"I spent over a whole day documenting things for Guinness. They want photos,
attempt video (with running count--there was more python scripting to generate
that, plus looking at the video to figure out the times of all the ascents),
statements from two witnesses and two timekeepers for the attempt, a
measurement statement from a ""surveyor or other qualified person"" (a geology
grad student in our case), a measurement video, two witnesses for the
measurement, an index to the photos, documentation of timekeeper and witness
qualifications, and a notable moments list for the video.  
  
On the bright side, all this means that their records are probably pretty
reliable.  
  
It's now submitted, and they should respond in three months. Fingers crossed.
For GBP 500, they can do a rush review in five days, but why bother?",823
"I was actually really stressed yesterday. I had already beaten the record
unofficially in practice, but with lots of people coming to watch (local
climbers, grad students and colleagues), I didn't want to disappoint.
Contributing to the stress was that the conditions changed from my practice
runs (the auto-belay was down from maintenance and I had to use a manual
belay; this involved lengthening the route slightly, increasing the length of
each set and decreasing the total count, as well as an effective increase in
my weight since the auto-belay subtracts a few pounds due to its spring-
loading), and that I hadn't been able to train on the particular route for
several weeks prior to Wednesday due to the auto-belay being down for
maintenance while on Wednesday's approximately half-distance-at-half-time
practice I was more tired at the end than I should have been due to poor
pacing.",893
"And now for something not very philosophical. Today, in front of two witnesses
and two timekeepers and with the help of Levi Durham doing an amazing feat of
belaying me for an hour, I beat the [Guinness World
Record](https://www.guinnessworldrecords.com/world-records/438677-greatest-
vertical-distance-climbed-on-an-artificial-climbing-wall-in-1-hour-indi) in
greatest vertical distance climbed in one hour on an indoor climbing wall. The
previous record was 928.5m and I did 1013.7m (with about half a minute to
spare). On Baylor's climbing wall, this involved 67 climbs divided into sets
of 10 (the last was 7), with about a minute of rest between sets (the clock
kept on running during the rest).",700
"Since Guinness requires video proof in addition to human witnesses, in the
interests of redundancy, I had three cameras pointed at the attempt. The best
footage (above) is from a Sony A7R2 with a zoom lens at 16mm, producing 1080P
at 59.94 fps. Video was processed with Adobe Premiere Rush. The processing
consisted of trimming the start and end, and adding a timing video track I
generated with a [Python OpenCV2
script](https://gist.github.com/arpruss/3a705c859d4ea4a482c4e47e96a08f79),
synchronized with single-frame precision at the 1:00:00 point with the footage
of Giant Stopwatch (barely visible under the table towards the end of the
video; early in the video, glare hides it). For the unofficial version I link
above, I accelerated the middle climbs 10X in Premiere Rush.",780
"I trained for about three months, not very heavily. In training did two
unofficial full-length practice runs, and in each I beat the previous record:
in the first one I got 947.1 meters and in the second I got 1004.5, so I was
pretty confident I could beat the 928.5 meters on the official attempt (though
I was still pretty nervous). I also trained by doing a small number of
approximately 1/2 or 1/3 sized practices (maybe three or so), and more regular
shorter runs (1-10 climbs) at fast pace.",496
"Most of my practice was with an auto-belay, and at a shorter distance per
climb (and hence greater number of climbs needed) since the auto-belay makes
it impossible to get to the top of the wall. The auto-belay is also spring
loaded so it effectively decreases body weight (by 7 lbs at the bottom
according to my measurement). Then a couple of weeks ago the auto-belay was
closed by management due to a maintenance issue, and I had a break in training
until the Wednesday before the official attempt when I trained with a manual
belay.",535
"You should make a living out of that, Alex.  
Would give you a lot less stress.",79
"The route was a standard 5.7 grade for most of my training (including when I
unofficially beat the records), with Rock management kindly agreeing to keep
the route up for several months for me. For the final attempt, we added holds
to make the finish at the top of the wall, and changed three other holds to
easier ones. (Guinness has no route grade requirements.)",364
"In the morning I stress-baked pumpkin muffins for myself and the volunteers. I
had the muffins, water and loose chalk on a table for use during breaks.",151
"First, we have “officially” non-lethal weapons: tasers, gas, etc. Some of
these might violate current international law, but it seems that a pacifist
country could modify its commitment to some accords.",202
"Third, we might subdivide moderate pacifists based on whether they prohibit
all violence that foreseeably leads to death or just violence that
intentionally leads to death. If it is only intentionally lethal violence that
is forbidden, then quite a bit of modern warfare can stand. If the enemy is
attacking with tanks or planes, one can intentionally destroy the tank or
plane as a weapon, while only foreseeing, without intending, the death of the
crew. (I don’t know how far one can take this line without sophistry. Can one
drop a bomb on an infantry unit intending to smash up their rifles without
intending to kill the soldiers?) Similarly, one can bomb enemy weapons
factories.",684
"I’ve been wondering whether it is possible for a country to count as pacifist
and yet wage a defensive war. I think the answer is positive, as long as one
has a moderate pacifism that is opposed to lethal violence but not to all
violence. I think that a prohibition of all violence is untenable. It seems
obvious that if you see someone about to shoot an innocent person, and you can
give the shooter a shove to make them miss, you presumptively should.",453
"Second, “lethal” weapons can be used less than lethally. For instance, with
modern medicine, abdominal gunshot wounds are only 10% fatal, yet they are no
doubt very effective at stopping an attacker. While it may seem weird to
imagine a pacifist shooting someone in the stomach, when the chance of
survival is 90%, it does not seem unreasonable to say that the pacifist could
be aiming to stop the attacker non-lethally. After all, tasers sometimes kill,
too. They do so less than 0.25% of the time, but that’s a difference of degree
rather than of principle.",559
"Whether such a limited way of waging war could be successful probably depends
on the case. If one combined the non-lethal (or not intentionally lethal)
means with technological and numerical superiority, it wouldn’t be surprising
to me if one could win.",253
"If you can tase one person to stop the murder of ten, then (1) should be
permissible if it’s the only option. But tasers occasionally kill people. We
don’t know how often. Apparently it’s [less than 1 in
400](https://www.usatoday.com/in-depth/news/investigations/2021/04/23/police-
use-tasers-ends-hundreds-deaths-like-daunte-wright/7221153002/) uses. Suppose
it’s 1 in 4000. Then option (1) results in 250 enemy deaths.",420
"Alex  
  
Of course one should never murder anyone, but the question is: would killing
Putin be murder?",103
"Alex  
  
Doesn't you post here entail that we should murder Putin?",67
"Very well. Now consider this on a national level. Suppose there are a million
enemy soldiers ordered to commit genocide against ten million, and you have
two ways to stop them:",176
"Note that a version of this argument goes through even if the moderate
pacifist backs up and says that tasers are too lethal. For suppose instead of
tasers we have drones that destroy the dominant hand of an enemy soldier while
guaranteeing survival (with science fictional medical technology). It’s
clearly right to release such a drone on a soldier who is about to kill ten
innocents. But now compare:",403
"I think (4) is still morally preferable to causing the kind of disruption to
the lives of a million people that plan (3) would involve.",135
"Now, imagine that one person is attacking you and nine other innocents, with
the intent of killing the ten of you, and you can stop them with a taser.
Surely you should, and surely the moderate pacifist will say that this is an
appropriate use case for the taser.",263
"One should never murder anyone. Killing, on the other hand, can sometimes be
justified.  
  
One question about killing the leader of an invading country is whether the
leader counts as a civilian, since the killing of civilians is forbidden by
the Geneva Convention. There is also some worry about the Geneva Convention's
killing by ""perfidy"", which is taken to rule out at least some assassinations.
So, as a matter of positive international law, it seems a difficult question.  
  
Were there no international law on the matter, I wouldn't see a significant
difference between killing a political leader and killing a general, if both
are giving orders to fight. Morally speaking, but not necessarily in
international law, both seem to me to be equally combatants.  
  
Besides the moral and legal questions, there is also a prudential question. In
my post I assumed that killing the general would stop the invasion. I got to
assume that because I was making up the case. Whether in actual fact killing a
leader would stop an invasion is less clear. Indeed such a thing might be seen
as such a serious attack on the country that the retaliation might be really
horrific.",1173
"These may seem to be consequentialist arguments. I don't think so. I don't
have the same intuitions if we replace the general by the general's innocent
child in (2) and (4), even if killing the child were to stop the war (e.g., by
making the general afraid that their other children would be murdered).",302
"Imagine a moderate pacifist who rejects lethal self-defense, but allows non-
lethal self-defense when appropriate, say by use of tasers.",136
"So maybe our choice is between tasing a million, thereby non-intentionally
killing 250 soldiers, and intentionally killing one general. It seems to me
that (2) is morally preferable, even though our moderate pacifist has to allow
(1) and forbid (2).",249
"Here is a picture on which this is correct. We exercise a normative power by
exercising a natural power in such a context that the successful exercise of
the natural power is partly constitutive of a normative fact. For instance, we
utter a promise, thereby exercising a natural power to engage in a certain
kind of speech act, and our exercise of that speech act is partly constitutive
of, rather than causal of, the state of affairs of our being obligated to
carry out the promised action.",491
"I think the difficulty with a causal model is the fact that in paradigm cases
of normative power, there is a natural power that _is_ being exercised, and we
have the intuition that the exercise of the natural power is necessary and
sufficient for the normative effect. But on a causal model, why couldn’t I
cause a promissory-type obligation without promising, simply causing the
relevant property of being obligated to come to be instantiated in me? And why
couldn’t I engage in the speech act while yet remaining normatively unbound,
because my normative power wasn’t exercised in parallel with the natural
power?",615
"There are two versions of the above model. On one version, there is an
underlying fundamental conditional normative fact _C_ , such as that if I have
promised something then I should do it, and my exercise of normative power
supplies the antecedent _A_ of that conditional, and then the normative
consequent of _C_ comes to be grounded in _C_ and _A_. On another version,
there there are some natural acts that are directly constitutive of a
normative state of affairs, not merely by supplying the antecedent of a
conditional normative fact. I think the first version of the model is the more
plausible in paradigmatic cases.",625
"Maybe the answer to both questions is that I could, but only metaphysically
and not causally. In other words, it could be that the laws of nature, or of
human nature, make it impossible for me to exercise one of the powers without
the other, just as I cannot wiggle my ring finger without wiggling my middle
finger as well. On this view, if there is a God, he could cause me to acquire
promissory-type obligations without my promising, and he could let me engage
in the natural act of promising while blocking the exercise of normative power
and leaving me normatively unbound. This doesn’t seem particularly
problematic.",621
"A normative power is a power to change a normative condition.
[Raz](https://core.ac.uk/download/pdf/230182259.pdf) says the change is not
produced “causally” but “normatively”.",176
"But why not allow for a causal model? Why not suppose that a normative power
is a causal power to make an irreducible normative property come to be
instantiated in someone? Thus, my power to promise is the power to cause
myself to be obligated to do what I have promised.",271
"Perhaps the real problem for a lot of people with a causal view of normative
powers is that it tends to lead to a violation of supervenience. For if it is
metaphysically possble to have the exercise of the normative power without the
exercise of the natural power, or vice versa, then it seems we don’t have
supervenience of the normative on the non-normative. But supervenience does
not seem to me to be inescapable.",417
"According to the guise of the good thesis, one always acts for the sake of an
apparent good. There is a weaker and a stronger version of this:",142
I think there is still reason to be sceptical of the strong version.,68
"But perhaps we can say this. We have a normative power to endow some neutral
things with value by making them our ends. And in fact the only way to act for
an end that does not have any independent value is by exercising that
normative power. And exercising that normative power involves your seeing the
thing you’re endowing with value as valuable. And maybe the only way to raise
your arm or for Bob to bake the cake in the examples is by exercising the
normative power, and doing so involves seeing the end as good. Maybe. This has
some phenomenological plausibility and it would be nice if it were true,
because the strong guise of the good thesis is pretty plausible to me.",678
"**Case 2:** Back when they were dating in high school, Bob promised to try his
best to bake a nine-layer chocolate cake for Alice’s 40th birthday. Since
then, Bob and Alice have had a falling out, and hate each other’s guts.
Moreover, Alice and all her guests hate chocolate. But Alice doesn’t release
Bob from his promise. Bob tries his best to bake the cake in order to fulfill
his promise, and happens to succeed. In trying to bake the cake, Bob acted for
the end of producing a cake. But producing the cake was worthless, since no
one would eat it. The only value was in the trying, since that was the
fulfillment of his promise.",633
"This isn’t quite enough for a defense of the strong thesis. For even if the
success is good, it does not follow that you perceive the success as good. You
might subscribe to an axiological theory on which success is not good in
general, but only success at something good.",272
"**Case 1:** There is some device which does something useful when you trigger
it. It is triggered by electrical activity. You strap it on to your arm, and
raise your arm, so that the electrical activity in your muscles triggers the
device. Your raising your arm has the arm going up as an end, but that end is
not perceived as good, but merely neutral. All you care about is the
electrical activity in your muscles.",415
"For the strong version to have any plausibility, “good” must include cases of
purely instrumental goodness.",107
"**Weak** : Whenever you act, you act for an end that you perceive is good.",74
"**Strong** : Whenever you act, you act for an end, and every end you act for
you perceive as good.",98
"I was going to leave it at this. But then I thought of a way to save the
strong guise of the good thesis. Success is valuable as such. When I try to do
something, succeeding at it has value. So the arm going up or the cake being
produced _are_ valuable as necessary parts of the success of one’s action. So
perhaps every end of your action _is_ trivially good, because it is good for
your action to succeed, and the end is a (constitutive, not causal) means to
success.",469
"In both cases, it is still true that the agent acts for a good end—the useful
triggering of the device and the production of the cake. But in both cases it
seems they are also acting for a worthless end. Thus the cases seem to fit
with the weak but not the strong guise of the good thesis.",289
"Clearly the prudent thing to do is to try to win. For if you don’t try to win,
then you are guaranteed not to get any money. But if you do try, you won’t
lose anything, and you might gain.",188
"If you lose, but you tried to win, she pays you double what you lost.",69
"Is this possible? I think so. We just need to
[distinguish](http://alexanderpruss.blogspot.com/2019/08/two-ways-to-pursue-y-
for-sake-of-z.html) between pursuing victory for the sake of something else
that follows from victory and pursuing victory for the sake of something that
might follow from the pursuit of victory.",320
"Suppose Alice can read your mind, and you are playing poker against a set of
people not including Alice. You don’t care about winning, just about money.
Alice has a deal for you that you can’t refuse.",200
"Here is the oddity: you are trying to win in order to get paid, but you only
get paid if you don’t win. Thus, you are trying to achieve something, the
achievement of which would undercut the end you are pursuing.",212
"So the view has to be that sometimes _F_ -norms take precedence over moral
norms, but not always. There must thus be norms which are neither _F_ -norms
nor moral norms that decide whether _F_ -norms or moral norms take precedence.
We can call these “overall norms of combination”. And it is crucial to the
view that the norms of combination themselves be neither _F_ -norms nor moral
norms.",390
"Maybe there is a view on which the overall ones take into account not the
first-order moral and _F_ -considerations, but only the deliverances of the
moral and _F_ -norms of combination, but that seems needlessly complex.",221
"This view violates Ockham’s razor: Why would we have moral norms of
combination if the overall norms of combination always override them anyway?",144
"Sacrifice a slight amount of _F_ -considerations for a great deal of good for
one’s children.",93
"Sacrifice an enormous amount of _F_ -considerations for a slight good for
one’s children.",89
"But here is an oddity. Morality already combines _F_ -considerations and first
order paradigmatically moral considerations. Consider two actions:",145
"Some philosophers think that sometimes norms other than moral norms—e.g.,
prudential norms or norms of the meaningfulness of life—take precedence over
moral norms and make permissible actions that are morally impermissible. Let
_F_ -norms be such norms.",253
"A view where _F_ -norms _always_ override moral norms does not seem plausible.
In the case of prudential or meaningfulness, it would point to a fundamental
selfishness in the normative constitution of the human being.",217
"_Morality_ says that (1) is obligatory but (2) is permitted. Thus, morality
already weighs _F_ and paradigmatically moral concerns and provides a
combination verdict. In other words, there already are _moral_ norms of
combination. So the view would be that there are moral norms of combination
and overall norms of combination, both of which take into account exactly the
same first order considerations, but sometimes come to different conclusions
because they weigh the very same first order considerations differently (e.g.,
in the case where a moderate amount of _F_ -considerations needs to be
sacrificed for a moderate amount of good for one’s children).",660
"Moreover, the view has the following difficulty: It seems that the best way to
define a type of norm (prudential, meaningfulness, moral, etc.) is in terms of
the types of consideration that the norm is based on. But if the overall norms
of combination take into account the very same types of consideration as the
moral norms of combination, then this way of distinguishing the types of norms
is no longer available.",416
"Mutual enmity: _x_ and _y_ have shared knowledge that they each pursue the
other’s ill-being for a reason other than the other’s well-being.",140
"Michael Huemer advances a version of this argument in his ""Ethical
Intuitionism"", somewhere around page 180 or 190 or the like (I don't have the
book in front of me, sorry). I forget the exact details, but it may be worth
checking out what he said.",248
"The reason for the qualification on reasons in 3 is that one might say that
someone who punishes someone in the hope of their reform is pursuing their
ill-being for the sake of their well-being. I don’t know if that is the right
way to describe reformative punishment, but it’s safer to include the
qualification in (3).",320
"Both competition and moral opposition are compatible with mutual love, but
mutual enmity is not compatible with either direction of love.",137
"Note that cases of moral opposition are all cases of competition. Cases of
mutual enmity are also cases of competition, except in rare cases, such as
when a party suffers from depression or acedia which makes them not be opposed
to their own ill-being.",252
"Woops. This was supposed to be a comment on the overriding moral reasons post.
Sorry!",85
"I suspect that most cases of mutual enmity are also cases of moral opposition,
but I am less clear on this.",107
"Moral opposition: _x_ and _y_ have shared knowledge that they are pursuing
incompatible goals and each takes the other’s pursuit to be morally wrong.",149
"I think loving one’s competitors could be good practice for loving one’s (then
necessarily non-mutual) enemies.",111
"This has the odd result that on externalist consequentialism, in most sports
and other games, at least one side is acting wrongly. For it is extremely rare
that there is an exact tie between the values of one side winning and the
value of the other side winning. (Some people enjoy victory more than others,
or have somewhat more in the way of fans, etc.)",355
"I wonder if consequentialism can be salvaged from this argument with the
following consideration:  
  
Suppose that the utility of winning accrues only if the victory is achieved
against a capable opponent who is highly motivated to win. (For example, I
have seen boxing matches where the victor is visibly disappointed or even
enraged when he perceives that his opponent threw in the towel prematurely.)
In this case, each competitor would be behaving morally if and only if he
tries his hardest to win, even given consequentialism.",533
"On internalist consequentalism, where the right action is defined by expected
utilities, we would expect that if both sides are unbiased investigators, in
most of the games, at least one side would at take the expected utility of the
other side’s winning to be higher. For if both sides are perfect investigators
with the same evidence and perfect priors, then they will assign the same
expected utilities, and so at least one side will take the other’s to have
higher expected utility, except in the rare case where the two expected
utilities are equal. And if both sides assign expected utilities completely at
random, but unbiasedly (i.e., are just as likely to assign a higher expected
utility to the other side winning as to themselves), then bracketing the rare
case where a side assigns equal expected utility to both victory options, any
given side will have a probability of about a half of assigning higher
expected utility to the other side’s victory, and so there will be about a 3/4
chance that at least one side will take the other side’s victory to be more
likely. And other cases of unbiased investigators will likely fall somewhere
between the perfect case and the random case, and so we would expect that in
most games, at least one side will be playing for an outcome that they think
has lower expected utility.",1330
"Yeah, I think I made a number of mistakes in my argument.  
  
On consequentialism what is evaluated is the action, not the end of the
action. So even if my winning has lower utility than your winning under
similar circumstances, it does not follow that my trying to win has lower
utility than my not trying to win. There are two possibilities, after all,
assuming I try to win. Either I will succeed or I won't. If I won't succeed,
then the harder I tried, the more enjoyable the victory for you, for your fans
and for my fans. If I do succeed, the utility is lower than if I had tried and
you nonetheless succeeded (I am assuming your victory has higher utility), but
it may still be higher than had I failed to try (in which case very likely I
would not have succeeded) because then there would have been general
disappointment. So a case can be made that my trying to win is better than my
not trying to win, even if other things being equal my winning is worse than
your winning. And similar things seem to hold on expected utility versions.  
  
Still, suppose that the utility of your winning is higher than of my winning,
and I am about to win, but I have some subtle way of throwing the game so no
one can tell, and everyone will enjoy the game pretty much as much. Then on
externalist consequentialism I should throw the game in this way. Whether such
a way of throwing the game is available depends on many factors: what the game
is, who the audience are, what level one and one's opponent are. Still, there
are probably a number of combinations where such throwing is available, and
the slight loss in quality of play is outweighed by the benefits of your
winning.",1676
"So, the result is that either on externalist or internalist consequentialism,
in most sports and other competitions, at least one side is acting morally
wrongly or is acting in the light of an epistemic vice.",208
"I’ve been thinking about who competitors, opponents and enemies are, and I am
not very clear on it. But I think we can start with this:",135
"In the ideal case, competitors both rightly pursue the incompatible goals, and
each knows that they are both so doing.",118
"Given externalist consequentialism, where the right action is the one that
actually would produce better consequences, ideal competition will be
extremely rare, since the only time the pursuit of each of two incompatible
goals will be right is if there is an exact tie between the values of the
goals, and that is extremely rare.",329
"Of course, in practice, the two sides are not unbiased. One might overestimate
the value of oneself winning and the underestimate the value of the other
winning. But that is likely to involve some epistemic vice.",212
"Let _α_ be the non-zero infinitesimal length of a single point. Then [ _a_ ,
_a_ ] is a single point. Its length thus will be _α_ , and not _a_ − _a_ = 0.
So [ _a_ , _b_ ] can’t _always_ have real-number length _b_ − _a_. But maybe
at least it can in the case where _a_ < _b_? No. For suppose that _m_ ([ _a_ ,
_b_ ]) = _b_ − _a_ whenever _a_ < _b_. Then _m_ (( _a_ , _b_ ]) = _b_ − _a_ −
_α_ whenever _a_ < _b_ , since ( _a_ , _b_ ] is missing exactly one point of [
_a_ , _b_ ]. But then let _c_ = ( _a_ + _b_ )/2 be the midpoint of [ _a_ , _b_
]. Then:",555
"since ( _a_ , _b_ ) is equal to the disjoint union of ( _a_ , _c_ ), the point
_c_ and (c,b).",93
"_m_ ([ _a_ , _b_ ]) = _m_ ([ _a_ , _c_ ]) + _m_ (( _c_ , _b_ ]) = ( _c_ − _a_
) + ( _b_ − _c_ − _α_ ) = _b_ − _a_ − _α_ ,",121
"Suppose that you want to measure the size _m_ ( _I_ ) of an interval _I_ , but
you have the conviction that single points matter, so [ _a_ , _b_ ] is bigger
than ( _a_ , _b_ ), and you want to use infinitesimals to model that
difference. Thus, _m_ ([ _a_ , _b_ ]) will be infinitesimally bigger than _m_
(( _a_ , _b_ )).",320
"_m_ (( _a_ , _b_ )) = _m_ (( _a_ , _c_ )) + _α_ \+ _m_ (( _c_ , _b_ )) = _c_ −
_a_ \+ _α_ \+ _b_ − _c_ = _b_ − _a_ \+ _α_ ,",123
"That leaves [ _a_ , _b_ ) and ( _a_ , _b_ ]. By symmetry if one has length _b_
− _a_ , surely so does the other. And in fact Milovich gave me [a
proof](https://mathoverflow.net/questions/108170/hyperreal-finitely-additive-
measure-on-0-1-assigning-b-a-to-a-b-or-a-b) that there is no contradiction in
supposing that _m_ ([ _a_ , _b_ )) = _m_ (( _b_ , _a_ ]) = _b_ − _a_.",370
"At the same time, intuitively, _some_ intervals from _a_ to _b_ should have
length _exactly_ _b_ − _a_ , which is a real number (assuming _a_ and _b_ are
real). Which ones? The choices are [ _a_ , _b_ ], ( _a_ , _b_ ), [ _a_ , _b_ )
are ( _a_ , _b_ ].",251
"As usual, write [ _a_ , _b_ ] for the interval of the real line from _a_ to
_b_ including both _a_ and _b_ , ( _a_ , _b_ ) for the interval of the real
line from _a_ to _b_ excluding _a_ and _b_ , and [ _a_ , _b_ ) and ( _a_ , _b_
] respectively for the intervals that include _a_ and exclude _b_ and vice
versa.",312
"Thus at least some intervals will have lengths that aren’t real numbers: their
length will be a real number plus or minus a (non-zero) infinitesimal.",149
"What about ( _a_ , _b_ )? Can that always have real number length _b_ − _a_ if
_a_ < _b_? No. For if we had that, then we would absurdly have:",142
"Probability-match: _E_ _p_ 1 _A_ = _p_ ( _A_ ) for any event _A_ , where 1 _A_
is 1 on _A_ and 0 elsewhere",106
"Linearity: _E_ _p_ ( _a_ _f_ + _b_ _g_ ) = _a_ _E_ _p_ _f_ \+ _b_ _E_ _p_ _g_
for _a_ and _b_ in _V_",100
"Dominance: if _f_ ≤ _g_ everywhere, then _E_ _p_ _f_ ≤ _E_ _p_ _g_ , and if
_f_ < _g_ everywhere, then _E_ _p_ _f_ < _E_ _p_ _g_.",129
"Now, embed _V_ in a hyperreal field _V_ 2 that contains a supremum for every
subset of _V_ , and embed _V_ 2 in _V_ 3 which has a supremum for every subset
of _V_ 2. Let _Ω_ be our probability space.",199
"The apparent solution works as follows. For any gamble with values in some
real or hyperreal field _V_ and any finitely-additive probability _p_ with
values in _V_ , we generate a hyperreal expected value _E_ _p_ , which
satisfies these plausible axioms:",254
"Let _X_ be the space of bounded _V_ 2-valued functions on _Ω_ and let _M_ ⊆
_X_ be the subspace of simple functions (with respect to the algebra of sets
that _Ω_ is defined on). For _f_ ∈ _M_ , let _ϕ_ ( _f_ ) be the integral of
_f_ with respect to _p_ , defined in the obvious way. The supremum on _V_ 2
(which has values in _V_ 3) is then a seminorm dominating _ϕ_. Extend _ϕ_ to a
_V_ -linear function _ϕ_ on _X_ dominated by _V_ 2. Note that if _f_ > 0
everywhere for _f_ with values in _V_ , then _f_ > _α_ > 0 everywhere for some
_α_ ∈ _V_ 2, and hence _ϕ_ (− _f_ ) ≤ − _α_ by seminorm domination, hence 0 <
_α_ ≤ _ϕ_ ( _f_ ). Letting _E_ _p_ be _ϕ_ restricted to the _V_ -valued
functions, our construction is complete.",726
"How to evaluate expected utilities of gambles whose values are hyperreal,
where the probabilities may be real or hyperreal, which I raise in Section 4.2
of my paper on [accuracy in infinite domains](http://philsci-
archive.pitt.edu/21251/).",240
"How to value gambles on a countably infinite fair lottery where the gamble is
positive and asymptotically approaches zero at infinity. The
[problem](http://alexanderpruss.blogspot.com/2022/11/dominance-and-countably-
infinite-fair.html) is that any positive non-infinitesimal value is too big
and any infinitesimal value violates strict dominance.",347
"The problem of how to value the St Petersburg paradox. The particular version
that interests me is one from [Russell and
Isaacs](https://philarchive.org/rec/RUSINP-2) which says that any finite value
is too small, but any infinite value violates strict dominance (since, no
matter what, the payoff will be less than infinity).",326
"How does this get around the arguments I link to in (1) and (2) that seem to
say that this can’t be done? The trick is this: the expected value has values
in a hyperreal field _W_ which will be larger than _V_ , while (4)–(6) only
hold for gambles with values in _V_. The idea is that we distinguish between
what one might call primary values, which are particular goods in the world,
and what one might call distribution values, which specify how much a random
distribution of primary values is worth. We do not allow the distribution
values themselves to be the values of a gamble. This has some downsides, but
at least we can have (4)–(6) on _all_ gambles.",659
"I think like this. First it looks like the [Hahn-Banach dominated extension
theorem](https://en.wikipedia.org/wiki/Hahn%E2%80%93Banach_theorem) holds for
_V_ 2-valued _V_ 1-linear functionals on _V_ 1-vector spaces _V_ 1 ⊆ _V_ 2 are
real or hyperreal field, except that our extending functional may need to take
values in a field of hyperreals even larger than _V_ 2. The crucial thing to
note is that any subset of a real or hyperreal field has a supremum in a
larger hyperreal field. Then where the proof of the Hahn-Banach theorem uses
infima and suprema, you move to a larger hyperreal field to get them.",608
"Binary Wagers: If _U_ is 0 outside _A_ and _c_ on _A_ , then _E_ _p_ _U_ = _c_
_P_ ( _A_ ).",91
"Disjoint Additivity: If _U_ 1 and _U_ 2 are wagers supported on disjoint
events (i.e., there is no _n_ such  
that _U_ 1( _n_ ) and _U_ 2( _n_ ) are both non-zero), then _E_ _p_ ( _U_ 1+
_U_ 2) = _E_ _p_ _U_ 1 \+ _E_ _p_ _U_ 2.",227
Yeah. I have a more general solution along the same lines. Will post soon.,74
"Dominance: If _U_ 1 < _U_ 2 everywhere, then _E_ _p_ _U_ 1 < _E_ _p_ _U_ 2.",75
"Suppose we have a finitely-additive probability assignment _p_ (perhaps real,
perhaps hyperreal) for a countably infinite lottery with tickets 1, 2, ... in
such a way that each ticket has infinitesimal probability (where zero counts
as an infinitesimal). Now suppose we want to calculate the expected value or
previsio _E_ _p_ _U_ of any bounded wager _U_ on the outcome of the lottery,
where we think of the wager as assigning a value to each ticket, and the wager
is bounded if there is a finite _M_ such that | _U_ ( _n_ )| < _M_ for all
_n_.",545
"You could restrict previsions to real-valued wagers. (This is not entirely
arbitrary. What would it mean to win $β?) Then the wager ‘constant β’ would
have no prevision. So there would be no contradiction. The best you could do
would be ‘constant zero’. This has prevision zero, which is strictly less than
β, as expected.",322
"But we can’t. For suppose we have it. Let _U_ ( _n_ ) = 1/(2 _n_ ). Fix a
positive integer _m_. Let _U_ 1( _n_ ) be 2 for _n_ ≤ _m_ \+ 1 and 0
otherwise. Let _U_ 2( _n_ ) be 1/ _m_ for _n_ > _m_ \+ 1 and 0 for _n_ ≤ _m_
\+ 1. Then by Binary Wagers and by the fact that each ticket has infinitesimal
probability, _E_ _p_ _U_ 1 is an infinitesimal _α_ (since the probability of
any finite set will be infinitesimal). By Binary Wagers and Dominance, _E_ _p_
_U_ 2 ≤ 1/( _m_ +1). Thus by Disjoint Additivity, _E_ _p_ ( _U_ 1+ _U_ 2) ≤
_α_ \+ 1/( _m_ +1) < 1/ _m_. But _U_ < _U_ 1 \+ _U_ 2 everywhere, so by
Dominance we have _E_ _p_ _U_ < 1/ _m_. Since 0 < _U_ everywhere, by Dominance
and Binary Wagers we have 0 < _E_ _p_ _U_.",724
"Thus, _E_ _p_ _U_ is a non-zero infinitesimal _β_. But then _β_ < _U_ ( _n_ )
for all _n_ , and so by Binary Wagers and Dominance, _β_ < _E_ _p_ _U_ , a
contradiction.",167
"Of course, for any thing that enjoys heaven, strugges in purgatory or suffers
in hell, I should care that it does so. But should I have that kind of special
care that we have about things that happen to ourselves for what happens to
the soul? I say not, or at most slightly. For suppose that it turned out on
the correct metaphysics that my matter continues to exist after death. Should
I care whether it burns, decays, or is dissected, with that special care with
which we care about what happens to ourselves? Surely not, or at most
slightly. Why not? Because the matter won’t be a part of me when this happens.
(The “at most slightly” flags the fact that we can care about “dignitary
harms”, such as nobody showing up at our funeral, or us being defamed, etc.)",763
"But clearly heaven, purgatory and hell in the interim state is something we
should care about.",94
"First, the soul isn't the part of me that normally feels pain. The soul is the
part of me by virtue of which *I* feel pain. When I feel pain, there is only
one thing that feels pain--me, not me and my soul.  
  
Second, imagine that materialism is true, and the pain center of your brain is
removed from your head and put in a vat. Then that pain center is stimulated.
Should you specially care? Not at all! It's formerly your pain center--it was
that by which you feel pain--but it's not connected in the right way to the
whole, so what happens to it is irrelevant. Or suppose that we have a version
of materialism on which during a cerebrum transplant you stay with the
cerebrumless body (e.g., some versions of animalism). Your cerebrum is removed
and pain-stimulated in a vat. In terms of special care, this is surely
irrelevant.",833
"According to Catholic corruptionists, when I die, my soul will continue to
exist, but I won’t; then at the Resurrection, I will come back into existence,
receiving my soul back. In the interim, however, it is my soul, not I, who
will enjoy heaven, struggle in purgatory or suffer in hell.",288
"Isn't the reason that you wouldn't care what happens to your body after you
die is not just that it's not a part of you when it happens but also that the
part of you that would normally feel the pain (if you were
burned/decayed/dissected) doesn't.  
  
With the soul you (run with me for a little on this) would
suffer/struggle/enjoy the afterlife. Now obviously you on curroptionism
wouldn't suffer/struggle/enjoy but the part of you that normally would feel
the pain does. And so the special care may still be applied under
curroptionism.",540
"If _X_ is finite, then local finiteness of action is trivial. If _X_ is
infinite, then it will be satisfies in some cases but not others. For
instance, it will be satisfied if _G_ is permutations that only move a finite
number of members of _X_ at a time. It will on the other hand fail if _X_ is a
infinite bunch of people regularly spaced in a line and _G_ is shifts.",369
"**Proof of Therem:** Suppose that _G_ has locally finite action. Define _Ω_ =
_X_ × _V_. By Theorem 2 of my invariance of [non-classical probabilities
paper](https://arxiv.org/abs/2010.07366), there is a strongly _G_ -invariant
regular (i.e., ⌀ ≺ _A_ if _A_ is non-empty) qualitative probability ≼ on _Ω_.
Given a value distribution _f_ , let _f_ * = {( _x_ , _v_ ) : _v_ ≤ _f_ ( _x_
)} be a subset of _Ω_. Define _f_ ≼ _g_ iff _f_ * ≼ _g_.",440
"The trick to the proof of the Theorem is to reduce preferences between
distributions to comparisons of subsets of _X_ × _V_ and to reduce comparisons
of subsets of _X_ to preferences between binary distributions.",212
"A group of symmetries _G_ has locally finite action a set _X_ provided that
for each finite subset _H_ of _G_ and each _x_ ∈ _X_ , applying finite
combinations of members of _G_ to _x_ generates only a finite subset of _X_.
(More precisely, if ⟨ _H_ ⟩ is the subgroup generated by _G_ , then ⟨ _H_ ⟩
_x_ is finite.)",315
"I forgot to say that G acts on X x V by acting on the first component in the
proof.",83
"Of course, for a general social choice principle we need more than just a
decision whether to give one and the same good to the members of some set. But
we can still formalize those questions in terms of something pretty close to
qualitative probabilities. For a general framework, suppose a population set
_X_ (a set of people or places in spacetime or some other sites of value) and
a set of values _V_ (this could be a set of types of good, or the set of real
numbers representing values). We will suppose that _V_ comes with a transitive
and reflexive (preorder) preference relation ≤. Now let _Ω_ = _X_ × _V_. A
value distribution is a function _f_ from _X_ to _V_ , where _f_ ( _x_ ) = _v_
means that _x_ gets something of value _v_.",739
"Now suppose there is a (not necessarily total) strongly _G_ -invariant
reflexive and transitive preference ordering ≼ on the value distributions
satisfying (4)–(6). Given a subset _A_ of _X_ , define _A_ † to be the value
distribution that gives _w_ to all the members of _A_ and _v_ to all the non-
members, where _v_ < _w_. Define _A_ ≼ _B_ iff _A_ † ≼ _B_ †. This will be a
strongly _G_ -invariant reflexive and transitive relation on the subsets of
_X_. It will be regular by the Pareto condition. Finally, additivity follows
from the sameness independence condition. Local finiteness of action of _G_
then follows from Theorem 2 of my paper. ⋄",648
"Here, _f_ ∘ _g_ is the value distribution where site _x_ gets _f_ ( _g_ ( _x_
)).",81
"In other words, the mutual ranking between two value distributions does not
depend on what the two distributions do to the people on whom the
distributions agree. If it’s better to give $4 to Jones than to give $2 to
Smith when Kowalski is getting $7, it’s still better to give $4 to Jones than
to give $2 to Smith when Kowalski is getting $3. There is probably some other
name in the literature for this property, but I know next to nothing about
social choice literature.",473
"Write _f_ ≈ _g_ when _f_ ≼ _g_ and _g_ ≼ _f_ , and _f_ ≺ _g_ when _f_ ≼ _g_
but not _g_ ≼ _f_. Similarly for values _v_ and _w_ , write _v_ < _w_ if _v_ ≤
_w_ but not _w_ ≤ _v_.",177
"For instance, in the past I’ve proved theorems on qualitative probabilities. A
qualitative probability is a relation ≼ on the subsets of some sample space
_Ω_ such that:",169
"Strong _G_ -invariance: if _g_ ∈ _G_ and _f_ is a value distribution, then _f_
∘ _g_ ≈ _f_.",91
"We want to generate a reflexive and transitive preference ordering ≼ on the
set _V_ _X_ of value distributions.",111
"Finally, we want to have some sort of symmetries on the population. The most
radical would be that the value distributions don’t care about permutations of
people, but more moderate symmetries may be required. For this we need a group
_G_ of permutations acting on _X_.",269
"**Theorem:** Assume the Axiom of Choice. Suppose ≤ on _V_ is reflexive,
transitive and non-trivial in the sense that it contains two values _v_ and
_w_ such that _v_ < _w_. There exists a reflexive, transitive preference
ordering ≼ on the value distributions satisfying (4)–(6) if and only if there
is such an ordering that is total if and only if _G_ has locally finite action
on _X_.",385
"Totality, reflexivity, transitivity and strong _G_ -invariance for value
distributions follows from the same conditions for subsets of _Ω_. Regularity
of ≼ on the subsets of _Ω_ and additivity implies that if _A_ ⊂ _B_ then _A_ ≺
_B_. The Pareto condition for ≼ on the value distributions follows since if
_f_ and _g_ satisfy are such that _f_ ( _x_ ) ≤ _g_ ( _x_ ) for all _x_ with
strict inequality for some _x_ , then _f_ * ⊂ _g_ *. Finally, the complicated
sameness independence condition follows from additivity.",517
"Note that while it is natural to think of _X_ has just a set of people or of
locations, [inspired by Kenny
Easwaran](https://www.google.com/url?q=https%3A%2F%2Fwww.dropbox.com%2Fs%2Fdklfwsl2ql1rt6s%2FAggregation.pdf%3Fraw%3D1&sa=D&sntz=1&usg=AOvVaw2nfKx0sldlPHYVX-
lddt22) one can also think of it as a set _Q_ × _Ω_ where _Ω_ is a probability
space and _Q_ is a population, so that _f_ ( _x_ , _ω_ ) represents the value
_x_ gets at location _ω_. In that case, _G_ might be defined by symmetries of
the population and/or symmetries of the probability space. In such a setting,
we might want a weaker Pareto principle that supposes additionally that _f_ (
_x_ , _ω_ ) < _g_ ( _x_ , _ω_ ) for some _x_ and _all_ _ω_. With that weaker
Pareto principle, the proof that the existence of a _G_ -invariant preference
of the right sort on the distributions implies local finiteness of action does
not work. However, I think we can still prove local finiteness of action in
that case if the symmetries in _G_ act only on the population (i.e., for all
_x_ and _ω_ there is an _y_ such that _g_ ( _x_ , _ω_ ) = ( _y_ , _ω_ )). In
that case, given a subset _A_ of the population _Q_ , we define _A_ † to be
the distribution that gives _w_ to all the persons in _A_ with certainty
(i.e., everywhere on _Ω_ ) and gives _v_ to everyone else, and the rest of the
proof should go through, but I haven’t checked the details.",1407
"Pareto: If _f_ ( _x_ ) ≤ _g_ ( _x_ ) for all _x_ with _f_ ( _x_ ) < _g_ ( _x_
) for some _x_ , then _f_ ≺ _g_.",110
"if _A_ ∩ _C_ = _B_ ∩ _C_ = ⌀, then _A_ ≼ _B_ iff _A_ ∩ _C_ ≼ _B_ ∩ _C_
(additivity).",84
"Sameness independence: if _f_ 1, _f_ 2, _g_ 1, _g_ 2 are value distributions
and _A_ ⊆ _X_ is such that (a) _f_ 1 ≼ _f_ 2, (b) _f_ 1( _x_ ) = _f_ 2( _x_ )
and _g_ 1( _x_ ) = _g_ 2( _x_ ) if _x_ ∉ _A_ , (c) _f_ 1( _x_ ) = _g_ 1( _x_ )
and _f_ 2( _x_ ) = _g_ 2( _x_ ) if _x_ ∈ _A_.",279
"A comment by a referee of a recent paper of mine that one of my results in
decision theory didn’t actually depend on numerical probabilities and hence
could extend to social choice principles made me realize that this may be true
for some other things I’ve done.",262
"But need not think of _Ω_ as a space of possibilities and of ≼ as a
probability comparison. We could instead think of it as a set of people who
are candidates for getting some good thing, with _A_ ≼ _B_ meaning that it’s
at least as good for the good thing to be distributed to the members of _B_ as
to the members of _A_. Axioms (1) and (2) are then obvious. And axiom (3) is
an independence axiom: whether it is at least as good to give the good thing
to the members of _B_ as to the members of _A_ doesn’t depend on whether we
give it to the members of a disjoint set _C_ at the same time.",592
"The person who thinks survival reduced to a cerebrum is implausible for an
animal might, however, say that this is what’s odd about it. An animal reduced
to cerebrum lacks internal life support organs (heart, lungs, etc.) It is odd
to think that some animals can survive without internal life support and
others cannot.",319
"Hence even a snake can exist without its life-support organs, but only for a
short period of time.",98
"One might object that the spatial case and the temporal case are different,
because in the spatial case we are talking of partial presence and in the
temporal case of full presence. But a four-dimensionalist will disagree. To
exist at a time is to be partly present at that time. So to a four-
dimensionalist the analogy is pretty strict.",338
"It initially seems weird to say that some animals can survive reduced to a
cerebrum and others cannot. But it’s not that weird when we add that the ones
that can’t survive reduced to a cerebrum are animals that don’t _have_ a
cerebrum.",235
"But compare this: Some animals can partly exist in spatial locations where
they have no living cells, and others cannot. The outer parts of my hairs are
parts of me, but there are no living cells there. If my hair is in a room,
then I am partly in that room, even if no living cells of mine are in the
room. But on the other hand, there are some animals (at least the unicellular
ones, but maybe also some soft invertebrates) that can only exist where they
have a living cell.",476
"Animalists think humans are animals. Suppose I am an animalist and I think
that I go with my cerebrum in cerebrum-transplant cases. That may seem weird.
But suppose we make an equal opportunity claim here: all animals that have
cerebra go with their cerebra. If your dog Rover’s cerebrum is transplanted
into a robotic body, then the cerebrumless thing is not Rover. Rather, Rover
inhabits a robotic body or that body comes to be a part of Rover, depending on
views about prostheses. And the same is true for any animal that has a
cerebrum.",540
"Finally, compare this. Suppose Snaky a rattlesnake stretched along a line in
space. Now suppose we simultaneously annihilate everything in Snaky. Now,
“simultaneously” is presumably defined with respect to some reference frame
_F_ 1. Let _z_ be a point in Snaky’s rattle located just prior (according to
_F_ 1) to Snaky’s destruction. Then Snaky is partly present at _z_. But with a
bit of thought, we can see that there is another reference frame _F_ 2 where
the only parts of Snaky simultaneous with _z_ are parts of the rattle: all the
non-rattle parts of Snaky have already been annihilated at _F_ 2, but the
rattle has not. Then in _F_ 2 the following is true: there is a time at which
Snaky exists but nothing outside of Snaky’s rattle exists. Hence Snaky can
exist as just a rattle, albeit for a very, very short period of time.",835
"I love reductions. But alas it looks to me like reasons and goods are not
reducible in either direction.",104
"Another family of goods, though, are necessary goods. That God exists is good,
but it is necessarily true. That various mathematical theorems are beautiful
is necessarily true. Yet no one has reason to promote a necessary truth.",228
"Maybe, though, this isn’t quite right. If Alice is an agent, then Alice’s
existence is a good, but the fact that some agent or other exists isn’t a good
as such. I’m not sure. It seems like a world with agents is better for the
existence of agency, and not just better for the particular agents it has.
Adding _another_ agent to the world seems a lesser value contribution than
just ensuring that there is agency at all. But I could be wrong about that.",453
"However, while it might be the case that something is good just in case an
agent should “stand for it”, it does not seem right to think that it is good
_to the extent that_ an agent should “stand for it”. For the degree to which
an agent should stand for a good is determined not just by the magnitude of
the good, but the agent’s relationship to the good. I should celebrate my
children’s accomplishments more than strangers’.",427
"Perhaps, though, we can modify the story in terms of goods-for- _x_ , and say
that _G_ is good-for- _x_ to the extent that _x_ should stand for _G_. But
that doesn’t seem right, either. I should stand for justice for all, and not
merely to the degree that justice-for-all is good-for-me. Moreover, there
goods that are good for non-agents, while a non-agent does not have a reason
to do anything.",396
The simplest story would be that goods reduce to reasons to promote them.,73
"But perhaps we could have a subtler story on which goods reduce not just to
reasons to promote them, but to reasons to “stand for them” (taken as the
opposite of “standing against them”), where promotion is one way of “standing
for” a good, but there are others, such as celebration. It does not make sense
to promote the existence of God, the existence of agents, or the Pythagorean
theorem, but celebrating these goods makes sense.",433
"But there seem to be goods that give no one a reason to promote them. Consider
the good fact that there exist (in the eternalist sense: existed, exist now,
will exist, or exist timelessly) agents. No agent can promote the fact that
there exist agents: that good fact is part of the agent’s thrownness, to put
it in Heideggerese.",328
"However, these considerations seem to me to depend to some degree on which
decisions one is making. If Daniel is on the soccer team and deciding how hard
to work, it makes little difference whether he is on the Belgian or Brazilian
team. But suppose instead that Daniel is has two talents: he could become an
excellent nurse or a top soccer player. As a nurse, he would help relieve the
suffering of a number of patients. As a soccer player, in addition to the
intrinsic goods of the sports, he would contribute to his fellow citizens’
pleasure and desire satisfaction. In _this_ decision, it seems that the number
of fellow citizens _does_ matter. The number of people Daniel can help as a
nurse is not very dependent on the total population, but the number of people
that his soccer skills can delight varies linearly with the total population,
and if the latter number is large enough, it seems that it would be quite
reasonable for Daniel to opt to be a soccer player. So we could have a case
where if Daniel is Belgian he should become a nurse but if Brazilian then a
soccer player (unless Brazil has a significantly greater need for nurses than
Belgium, that is). But once on the team, it doesn’t seem to matter much.",1223
"The map from axiology to moral reasons is quite complex, contextual, and
heavily agent-centered. The hope of reducing moral reasons to axiology is very
slim indeed.",164
"An order of magnitude more people _wanted_ the Brazilians to win, and getting
what one wants is good. An order of magnitude more people would have felt
significant and appropriate _pleasure_ had the Brazilians won, and an
appropriate pleasure is good. And given both wishful thinking as well as
reasonable general presumptions about there being more talent available in a
larger population base, we can suppose that a lot more people _expected_ the
Brazilians to win, and it’s good if what one thinks is the case is in fact the
case.",533
"That said, I do think that the larger population of Brazil imbues the
Brazilians’ games and practices with _some_ not insignificant additional moral
weight than the Belgians’. It would be odd if the pleasure, desire
satisfaction and expectations of so many counted for _nothing_. But on the
other hand, it should make no significant difference to the Belgians whether
they are playing Greece or Brazil: the Belgians shouldn’t practice less
against the Greeks on the grounds that an order of magnitude fewer people will
be saddened when the Greeks lose than when Brazilians do.",576
"You might think that the good of the many outweighs the good of the few, and
Belgians are few. But, clearly, the above facts gave very little moral reason
to the Belgian players to lose. One might respond that the above facts gave
lots of reason to the Belgians to lose, but these reasons were outweighed by
the great value of victory to the Belgian players, or perhaps the significant
intrinsic value of playing a sport as well as one can. Maybe, but if so then
just multiply both countries’ populations by a factor of ten or a hundred, in
which case the difference between the goods (desire satisfaction, pleasure and
truth of belief) is equally multiplied, but still makes little or no moral
difference to what the Belgian players should do.",744
"Or consider this from the point of view of the Brazilian players. Imagine you
are one of them. Should the good of Brazil—around two hundred million people
caring about the game—be a crushing weight on your shoulders, imbuing
everything you do in practice and in the game with a great significance? No!
It’s still “just a game”, even if the value of the good is spread through two
hundred million people. It would be weird to think that it is a minor
pecadillo for a Belgian to slack off in practice but a grave sin for a
Brazilian to do so, because the Brazilian’s slacking hurts an order of
magnitude more people.",614
"In 2018, the Belgians beat the Brazilians 2-1 in the 2018 World Cup soccer
quarterfinals. There are about 18 times as many Brazilians and Belgians in the
world. This raises a number of puzzles in value theory, if for simplicity we
ignore everyone but Belgians and Brazilians in the world.",288
"As an Aristotelian who believes in individual forms, I’m puzzled about cases
of species-level flourishing that don’t seem reducible to individual
flourishing. On a biological level, consider how some species (e.g., social
insects, slime molds) have individuals who do not reproduce. Nonetheless it is
important to the flourishing of the _species_ that the species include some
individuals that do reproduce.",407
"However, there is still a puzzle. If it is a part of every human’s good that
“I am a member of a species that landed on the moon”, does that mean the good
is multiplied the more humans there are, because there are more instances of
this external flourishing? I think not. External flourishing is tricky this
way. The goods don’t always aggregate summatively between people in the case
of external flourishing. If external flourishing were aggregated summatively,
then it would have been better if Russia rather than Poland produced
Copernicus, because there are more Russians than Poles, and so there would
have been more people with the external good of “being a citizen of a country
that produced Copernicus.” But that’s a mistake: it is a good that each Pole
has, but the good doesn’t multiply with the number of Poles. Similarly, if
Belgium is facing off Brazil for the World Cup, it is not the case that it
would be way better if the Brazilians won, just because there are a lot more
Brazilians who would have the external good of “being a fellow citizen with
the winners of the World Cup.”",1095
"We might handle this kind of a case by attributing to other individuals their
_contribution_ to reproduction of the species. But I think this doesn’t solve
the problem. Consider a non-biological case. There are things that are
achievements of the human species, such as having reached the moon, having
achieved a four minute mile, or having proved the Poincaré conjecture. It
seems a stretch to try to individualize these goods by saying that we all
contributed to them. (After all, many of us weren’t even alive in 1969.)",522
"I think a good move for an Aristotelian who believes in individual forms is to
say that “No man or bee is an island.” There is an external flourishing in
virtue of the species at large: it is a part of _my_ flourishing that humans
landed on the moon. Think of how members of a social group are rightly proud
of the achievements of some famous fellow-members: we Poles are proud of
having produced Copernicus, Russians of having launched humans into space, and
Americans of having landed on the moon.",499
"In my previous post, I suggested that the interpersonal moral Satan’s Apple
was a reason to embrace causal finitism: to deny that an outcome (say, the
disaster) can causally depend on infinitely many inputs (the agents’ choices).
But the finite cases make me less confident. In the case where _N_ is large,
and our best estimate of the probability of another agent choosing _B_ is a
value _p_ not close to the threshold ratio _q_ , it still seems
counterintuitive that you should morally choose _B_ , and so should everyone
else, even though that yields the disaster.",567
"But now back to infinity. In the interpersonal moral Satan’s Apple, we have
infinitely many agents choosing between _A_ and _B_. But now instead of the
threshold being a finite number, the threshold is an infinite cardinality (one
can also make a version where it’s a co-cardinality). And this threshold has
the property that other people’s choices can _never_ be such that your choice
will put things above the threshold—either the threshold has already been met
without your choice, or your choice can’t make it hit the threshold. In the
finite case, it depended on the numbers involved whether you should choose _A_
or _B_. But the exact same reasoning as in the finite case, but now without
_any_ statistical inputs being needed, shows that you should choose _B_. For
it literally cannot make any difference to whether a disaster happens, no
matter what other people choose.",878
"Let me take another look at the [interpersonal moral Satan’s
Apple](http://alexanderpruss.blogspot.com/2022/11/the-interpersonal-satans-
apple.html), but start with a finite case.",179
"_""But now instead of the threshold being a finite number, the threshold is an
infinite cardinality (one can also make a version where it’s a co-
cardinality). And this threshold has the property that other people’s choices
can **never** be such that your choice will put things above the threshold —
either the threshold has already been met without your choice, or your choice
can’t make it hit the threshold.""_  
  
Such a bad formulation.  
Rather than pointing out, what's ""never"" the case, one should rather point
out, what's always the case there. The case with such a threshold is, that
such a threshold is either met or not met with or without your choice. Or in
other words such a threshold is met with or without your choice or is not met
with or without your choice.  
So specifically and particularly you making a choice doesn't matter for the
conditions of such a threshold either being met or being not met. But what
matters for the conditions of such a threshold either being met or being not
met is the actual state of affairs of a specific and particular kind of set,
in which you might be contained or not contained.  
It doesn't matter, which particular and specific bricks are used to obtain a
specific and particular wall. But what matters for the wall is if the set of
all bricks making out that wall is corresponding to the set of all natural
numbers.  
As for you as a single and specifical or particular brick - well, you can now
choose between being a part of that infinte wall or being not a part of that
infinte wall - holding out terrorists, illigal immigrants AND legal
immigrants, such as your ancesters were at one point in time and history, OR
NOT doing that - you can give an apple to a child OR NOT do that.  
It’s your choice. You kinda have to make that choice and also have to leave
with the consequences resulting from that made choice of yours.",1884
"Well, I think, that regardless of these probability considerations there is a
good reason - independent of your probability analysis - for making a choice
for option B here.  
I mean, that a feed and alive child in a prison is always better to have than
having the same [child dieing from
hunger](https://www.theworldcounts.com/challenges/people-and-poverty/hunger-
and-obesity/how-many-people-die-from-hunger-each-year).  
Sooo... I guess, that option B is objectively a better choice than option A
utility wise regardless of what else of ""threshold""-this and
""probability""-that.  
But I guess, that's just my personal opinion here.",633
"But you might not have a uniform distribution. You might, for instance, have a
reasonable estimate that a proportion _p_ of other people will choose _B_
while the threshold is _M_ ≈ _q_ _N_ for some fixed ratio _q_ between 0 and 1.
If _q_ is not close to _p_ , then facts about the binomial distribution show
that the probability that _M_ − 1 other people choose _B_ goes approximately
exponentially to zero as _N_ increases. Assuming that the badness of the
disaster is linear or at most polynomial in the number of agents, if the
number of agents is large enough, choosing _B_ will be a good thing. Of
course, you might have the unlucky situation that _q_ (the ratio of threshold
to number of people) and _p_ (the probability of an agent choosing _B_ ) are
approximately equal, in which case even for large _N_ , the risk that you’re
near the threshold will be too high to allow you to choose _B_.",899
"But in the infinite case, no matter what strategy other people adopt, whether
pure or mixed, choosing _B_ is better.",116
"Consider a situation where a _finite_ number _N_ of people independently make
a choice between _A_ and _B_ and some disastrous outcome happens if the number
of people choosing _B_ hits a threshold _M_. Suppose further that if you fix
whether the disaster happens, then it is better you to choose _A_ than _B_ ,
but the disastrous outcome outweighs all the benefits from all the possible
choices of _B_.",402
"Intuitively, you should do some sort of expected utility calculation based on
your best estimate of the probability _p_ that among the _N_ − 1 people other
than you, _M_ − 1 will choose _B_. For if fewer or more than _M_ − 1 of them
choose _B_ , your choice will make no difference, and you should choose _B_.
If _F_ is the difference between the utilities of _B_ and _A_ , e.g., the
utility of feeding the apple to the hungry child (assumed to be fairly
positive), and _D_ is the utility of the disaster (very negative), then you
need to see if _p_ _D_ \+ _F_ is positive or negative or zero. Modulo some
concerns about attitudes to risk, if _p_ _D_ \+ _F_ is positive, you should
choose _B_ (feed the child) and if its negative, you shouldn’t.",745
"For instance, maybe _B_ is feeding an apple to a hungry child, and _A_ is
refraining from doing so, but there is an evil dictator who likes children to
be miserable, and once enough children are not hungry, he will throw all the
children in jail.",246
"But I think in the finite case one can remove the counterintuitiveness. For
there are mixed strategies that if adopted by everyone are better than
everyone choosing _A_ or everyone choosing _B_. The mixed strategy will
involve choosing some number 0 < _p_ best < _q_ (where _q_ is the threshold
ratio at which the disaster happens) and everyone choosing _B_ with
probability _p_ best and _A_ with probability 1 − _p_ best, where _p_ best is
carefully optimized allow as many people to feed hungry children without a
significant risk of disaster. The exact value of _p_ best will depend on the
exact utilities involved, but will be close to _q_ if the number of agents is
large, as long as the disaster doesn’t scale exponentially. Now our
statistical reasoning shows that when your best estimate of the probability of
other people choosing _B_ is _not_ close to the threshold ratio _q_ , you
should just straight out choose _B_. And the worry I had is that everyone
doing that results in the disaster. But it does not seem problematic that in a
case where your data shows that people’s behavior is not close to optimal,
i.e., their behavior propensities do not match _p_ best, you need to act in a
way that doesn’t universalize very nicely. This is no more paradoxical than
the fact that when there are criminals, we need to have a police force, even
though ideally we wouldn’t have one.",1387
"If you have a uniform distribution over the possible number of people other
than you choosing _B_ , the probability that this number is _M_ − 1 will be 1/
_N_ (since the number of people other than you choosing _B_ is one of 0, 1,
..., _N_ − 1). Now, we assumed that the benefits of _B_ are such that they
don’t outweigh the disaster even if everyone chooses _B_ , so _D_ \+ _N_ _F_ <
0. Therefore (1/ _N_ ) _D_ \+ _F_ < 0, and so in the uniform distribution case
you shouldn’t choose _B_.",489
"_""Your giving an apple makes no difference whatsoever.""_  
  
And yet the previous proposition of that _""interpersonal Satan's Apple""_
suggests otherwise to be the case, such that **you giving an apple MIGHT make
a difference WHATSOEVER**.  
Hm. I guess, that this nonsensical intuition comes from the false
presupposition of _""causal finitism""_.  
So don't wonder if you giving an apple might make a difference whatsoever,
such that you might find that apple of yours in the hands of a [hungry child
sitting behind bars alone or separated from his or her parents behind
bars](https://en.wikipedia.org/wiki/Trump_administration_family_separation_policy).  
  
Besides that, one might change the past. Well, not the past of your own
timeline. But if there are multiple similar timelines, then one might be able
to jump from one to another one, such that a change in the other timeline
doesn't alter anything in the previous timeline, like in [Dragon
Ball](https://dragonball.fandom.com/wiki/Time_Machine).  
One might call this phenomenon of multiple timelines independent or branching
timelines to be the ""multiverse"". Just a suggestion of mine.",1145
"Interesting. Mistaken belief can generate the belief that you are IN the
paradox, but it doesn't seem to generate the paradox itself. For it's not
going to be true that everyone doing the right thing (feeding hungry children)
results in disaster, just that we think it will.",274
"Now, we deontologists are used to situations where a disaster happens because
one did the right thing. That’s because consequences are not the only thing
that counts morally, we say. But in the moral interpersonal Satan’s Apple,
there seems to be no deontology in play. It seems weird to imagine that
disaster could strike because everyone did what was consequentialistically
right.",382
"If causal finitism is the solution, then it is at least a little interesting
that the domain of moral obligations is smaller than the logically possible
even though it extends beyond the physically possible. (I’m taking it as given
that causal finitism doesn’t just follow from the PNC.)  
  
Actually, now that I think about it, is causal finitism a solution? Let's
grant that it is impossible for one effect to have infinitely many causes.
Assume I am ignorant about this fact. It surely isn’t impossible for me to
intend to do something that I mistakenly believe to be such a cause. And won’t
that mistaken belief generate a similar paradox?",644
"Consider a moral interpersonal version of [Satan’s Apple](http://philsci-
archive.pitt.edu/1595/1/15.1.bayesbind.pdf): infinitely many people
independently choose whether to give a yummy apple to a (different) hungry
child, and if infinitely many choose to do so, some calamity happens to
everyone, a calamity outweighing the hunger the child suffers. You’re one of
the potential apple-givers and you’re not hungry yourself. The disaster
strikes if and only if infinitely many people _other than you_ give an apple.
Your giving an apple makes no difference whatsoever. So it seems like you
_should_ give the apple to the child. After all, you relieve one child’s
hunger, and that’s good whether or not the calamity happens.",723
"One way out is causal finitism: Satan’s Apple is impossible, because the
disaster would have infinitely many causes.",116
"One can also do the same thing within [Buchak’s REU
theory](https://smile.amazon.com/Risk-Rationality-Lara-Buchak/dp/0198801289),
since that theory is equivalent to applying LSI↑ with a probability
transformed by a monotonic map of [0,1] to [0,1] keeping endpoints fixed,
which is exactly what I did when moving from _P_ to _P_ _ϵ_.",332
"Fubini's theorem applies to expected values defined with respect to a measure.
The credence function P_e is not a measure in general, because in general it
fails finite additivity. Thus, the standard Lebesgue integral with respect to
P_e is undefined. I don't know what a ""block integral"" is.  
  
The point of level-set integrals for me is that they allow one to define a
fairly well-behaved expectation or prevision with respect to credence
assignments that are not probabilities because instead of additivity they only
satisfy monotonicity (P(A) is less than or equal to P(B) if A is a subset of
B).",602
"If _U_ _ϵ_ is the “trimmed” utility function from my previous post, then LSI↑
_P_ _ϵ_ ( _U_ ) = _E_ ( _U_ 2 _ϵ_ ), so the two approaches are equivalent.",152
"Ah, ""block"" is my term. :-)  
  
Here's the background for why I am interested in expected values with respect
to non-probabilities. The credences or degrees of belief of real human beings
are unlikely to be consistent. In particular, they are unlikely to satisfy the
axioms of probability, especially additivity. At the same time, real human
beings need a way of making predictions. Mathematical expectation is out,
because that requires at least a finitely-additive measure (normally Lebesgue
integrals are defined with respect to a countably-additive measure but they
can also be defined with respect to a finitely-additive one). So we need some
other method for making predictions or generating expectations when the
credences do not satisfy the axioms of probability.",772
"Of course, _P_ _ϵ_ is not in general a probability, but it does satisfy the
Zero, Non-Negativity, Normalization and Monotonicity axioms, and we can now
use LSI↑ [level-set
integral](http://alexanderpruss.com/papers/InconsistentCredences.pdf) to
calculate utilities with _P_ _ϵ_.",278
"Why calculate the expected utility via _""level-set integrals""_ , when
according to [Fubini](https://proofwiki.org/wiki/Fubini%27s_Theorem) you can
also calculate the expected utility with ""block integrals"" or any other
appropriate transformations of the x and y coordinates gaining the same exact
result?  
Why not calculate it with [polar
coordinates](https://en.wikipedia.org/wiki/Polar_coordinate_system)?  
Sure, that would be more difficult to do without having any rotational
symmetries here.  
But you can do that and by doing that properly you or we should gain the same
result for the expected utility.  
Sooo...  
What exactly makes _""level-set integrals""_ so special here?!?  
I don't see any particular good reason for this specific approach for
calculating expected utilities over ""block integrals"" here.",817
"This morning, however, I noticed that one can also take the idea of
discounting small probabilities more literally and still get the exact same
results as by trimming utility functions. Specifically, given a probability
function _P_ and a probability discount threshold _ϵ_ , we form a credence
function _P_ _ϵ_ by letting _P_ _ϵ_ ( _A_ ) = _P_ ( _A_ ) if _ϵ_ ≤ _P_ ( _A_ )
≤ 1 − _ϵ_ , _P_ _ϵ_ ( _A_ ) = 0 if _P_ ( _A_ ) < _ϵ_ and _P_ _ϵ_ ( _A_ ) = 1
if _P_ ( _A_ ) > 1 − _ϵ_. This discounts close-to-zero probabilities to zero
and raises close-to-one probabilities to one. (We shouldn’t forget the second
or things won't work well.)",633
"In [yesterday’s post](http://alexanderpruss.blogspot.com/2022/11/how-to-
discount-small-probabilities.html), I argued that there is something
problematic about the idea of discounting small probabilities, given that in a
large enough lottery _every_ possibility with has a small probability. I then
offered a way of making sense of the idea by “trimming” the utility function
at the top and bottom.",398
"Moreover, the trimming procedure can yield an answer to what I think is the
biggest objection to small-probability discounting, namely that in a long
enough run—and everyone should think there is a non-negligible chance of
eternal life—even small probabilities can add up. If you are regularly offered
the same small chance of a gigantic benefit during an eternal future, and you
turn it down each time because the chance is negligible, you’re almost surely
missing out on an infinite amount of value. But we can apply the trimming
procedure at the level of choice of policies rather than of individual
decisions. Then if small chances are offered often enough, they won’t all be
trimmed away.",693
"Here is my friendly proposal. Let _U_ be the utility function we want to
evaluate the value of. Let _T_ be the smallest value such that _P_ ( _U_ > _T_
) ≤ _ϵ_ /2. (This exists: _T_ = inf { _λ_ : _P_ ( _U_ > _λ_ ) ≤ _ϵ_ /2}.) Let
_t_ be the largest value such that _P_ ( _U_ < _t_ ) ≤ _ϵ_ /2 (i.e., _t_ = sup
{ _λ_ : _P_ ( _U_ < _λ_ ) ≤ _ϵ_ /2}). Take _U_ and replace any values bigger
than _T_ with _T_ and any values smaller than _t_ with _t_ , and call the
resulting utility function _U_ _ϵ_. We now replace _U_ with _U_ _ϵ_ in our
expected value calculations. (In the lottery example, we will be trimming from
both ends at the same time.)",642
"In this post I want to offer a precise and friendly amendment to the solution
of neglecting small probabilities. But first why we need an amendment.
Consider a game where an integer _K_ is randomly chosen between  − 1 and _N_
for some large fixed positive _N_ , so large that 1/(2+ _N_ ) < _ϵ_ , and you
get _K_ dollars. The game is clearly worth playing. But if you discount
“possibilities that have very small probabilities”, you are left with
_nothing_ : every possibility has a very small probability!",505
"A very intuitive solution to a variety of problems in infinite decision theory
is that “for possibilities that have very small probabilities of occurring, we
should discount those probabilities down to zero” when making decisions
([Monton](https://quod.lib.umich.edu/cgi/p/pod/dod-idx/how-to-avoid-
maximizing-expected-utility.pdf?c=phimp;idno=3521354.0019.018;format=pdf)).",374
"Perhaps this is uncharitable. Maybe the idea is not that we discount to zero
_all_ possibilities with small probabilities, but that we discount such
possibilities until the total discount hits the threshold _ϵ_. But while this
sounds like a charitable interpretation of the suggestion, it leaves the
theory radically underdetermined. For _which_ possibilities do we discount? In
my lottery case, do we start by discounting the possibilities at the low end (
− 1, 0, 1, ...) until we have hit the threshold? Or do we start at the high
end ( _N_ , _N_ − 1, _N_ − 2, ...) or somewhere in the middle?",596
"Suppose throughout this post that _ϵ_ > 0 counts as our threshold of “very
small probabilities”. No doubt _ϵ_ < 1/100.",118
"The result is a precise theory (given the mysterious threshold _ϵ_ ). It
doesn’t neglect all possibilities with small probabilities, but rather it
trims low-probability outliers. The trimming procedure respects the fact that
often utility functions are defined up to positive affine transformations.",299
"In Satan’s Apple, for instance, the overall outcome is not just the sum of the
outcomes of the individual decisions to eat or not to eat, and so Satan’s
Apple is not a counterexample to (1). In fact, few of the paradoxes of
infinite sequences of decisions are counterexamples to (1).",283
"_""But if she greedily takes infinitely many, she is kicked out of paradise, an
outcome so bad that the whole apple does not outweigh it.""_  
  
How about taking only the slices with even numbers?  
Is she then also doomed to leaving paradise, just because she took an infinite
amount of slices from Satan's apple, but not exactly the whole (100%) apple?!?  
 **∑n∈ℕ(1/2^n)/2=1/(1-1/2)·1/2=1 (=100% of Satan's apple)  
≠ ∑m∈ℕ(1/2^(2m))/2=∑m∈ℕ(1/4^m)/2=1/(1-1/4)·1/2=2/3 (≈66.67% of Satan's
apple)**  
  
Is Hilbert's Hotel not capable of accommodating new guests, just because all
and every room is currently occupied?  
From the wiki article for [""Hilbert's paradox of the Grand
Hotel""](https://en.wikipedia.org/wiki/Hilbert%27s_paradox_of_the_Grand_Hotel):  
 _ **Analysis**  
Hilbert's paradox is a veridical paradox: it leads to a counter-intuitive
result that is provably true. The statements ""there is a guest to every room""
and ""no more guests can be accommodated"" are not equivalent when there are
infinitely many rooms...._  
  
And these are the problems/propositions, which philosophers are hung up on
these days.",1123
"Yup, in the story, taking all the even-numbered slices, or all the prime-
numbered slices, or all the power-of-two-numbered slices will get you kicked
out of paradise.",167
"If so, then I guess, that any and every finite amount of slices will do for
Eve, as long as she doesn't go for any amount of slices with cardinality equal
to the cardinality of the set of all natural numbers. If she is ought to
maximise her utility AND there is no certain bound or limit to that
maximisation of a finite amount of slices of Satan's apple, then go figure,
what such a ""maximum"" in this case might be.  
 **As for me I will take an arbitrary amount of percentage below 100% of that
pie, I mean, of that _""Satan's apple""_ with an arbitrary finite amount of
slices.**  
Thank you very much.",603
"If at each time you are choosing between a finite number of betting portfolios
fixed in advance, with the betting portfolio in each decision being tied to a
set of events wholly independent of all the later or earlier events or
decisions, with the overall outcome being just the sum or aggregation of the
outcomes of the betting portfolios, and with the utility of each portfolio
well-defined given your information, then you should at each time maximize
utility.",463
"There are [many](http://philsci-archive.pitt.edu/1595/1/15.1.bayesbind.pdf)
paradoxes of infinite sequences of decisions where the sequence of individual
decisions that maximize expected utility is unfortunate. Perhaps the most
vivid is Satan’s Apple, where a delicious apple is sliced into infinitely many
pieces, and Eve chooses which pieces to eat. But if she greedily takes
infinitely many, she is kicked out of paradise, an outcome so bad that the
whole apple does not outweigh it. For any set of pieces Eve eats, another
piece is only a plus. So she eats them all, and is damned.",585
"I don’t know if there is something particularly significant about a paradox
violating (1). I think there is, but I can’t quite put my finger on it. On the
other hand, (1) is such a complex principle that it may just seem _ad hoc_.",230
"True. Even still, one wonders what it would mean for God to turn a stone into
a child of Abraham; it wouldn't be a literal biological descendent, nor would
it have undergone a conversion. I suppose just creating a person and declaring
them to be under the Abrahamic covenant could suffice?  
  
Pointless overthinking, of course.",329
"If you like infinitesimals, you might say that the expected value of the
lottery is infinitesimal and the probability of getting less than some
positive number _x_ is 1 − _α_ for an infinitesimal _α_. That makes it sound
like a better deal, but it’s not all that clear.",269
"The expected value of the lottery is zero with respect to any finitely-
additive real-valued probability measure that fits the description (i.e.,
assign equal probablity to each number). And for any positive number _x_ , the
probability that you will get less than _x_ is one. It’s not clear to me that
it’s worth going for this.",329
"Professor Pruss,  
  
Here's a theological/philosophical question that I thought you might be
interested in. Speaking to the multitudes, John the Baptist says that ""God is
able from these stones to raise up children to Abraham"" (Luke 3:8). Setting
aside any questions of historicity (e.g. whether Abraham was a historical
figure, and so on), it can be safely assumed that John the Baptist (and those
to whom he was speaking) regarded the Judeans as literal, biological
descendants of Abraham. So it seems that, if taken at face value, he is saying
that God could turn the stones into literal, biological descendants of
Abraham. I wonder how this might bear on, for instance, essentiality of
origins.  
  
Of course, I think the solution is to avoid this sort of strict literalism,
but either way, it's fun to think about.",821
"Suppose someone offers you, at no cost whatsoever, something of specified
positive value. However small that value, it seems irrational to refuse it.",149
"But what if someone offers you a random amount of positive value for free.
Strict dominance principles say it’s irrational to refuse it. But I am not
completely sure.",166
"Imagine a lottery where some positive integer _n_ is picked at random, with
all numbers equally likely, and if _n_ is picked, then you get 1/ _n_ units of
value. Should you play this lottery for free?",200
"Of course, infinite fair lotteries are dubious. So I don’t set much store by
this example.",90
"But there is a difference: Bob pursues friendship because of the particular
ineffable “thick” kind of value that friendship has. Alice doesn’t know what
“thick” kind of value friendship has, but on the basis of Bob’s testimony, she
knows that it has some such value or other, and that it is a great and
significant value. As long as Alice knows what kinds of actions friendship
requires, she can pursue friendship without that knowledge, though it’s
probably more difficult for her, perhaps in the way that it is more difficult
for a tone-deaf person to play the piano, though in practice the tone-deaf
person could learn what kinds of finger movements result in aesthetically
valuable music without grasping that aesthetic value.",730
"Suppose Alice is blind to the intrinsic value of friendship and Bob can see
the intrinsic value of friendship. Bob then told Alice that friendship is
intrinsically valuable. Alice justifiedly trusts Bob in moral matters, and so
Alice concludes that friendship has intrinsic value, even though she can’t
“see” it. Alice and Bob then both pursue friendship for its own sake.",372
"The Aristotelian tradition makes the grasp of the particular thick kind of
value involved in a virtuous activity be a part of the full possession of that
virtue. On that view, Alice cannot have the full virtue of friendship. There
is something she is missing out on, just as the tone-deaf pianist is missing
out on something. But she is not, I think, less praiseworthy than Bob. In fact
Alice’s pursuit of friendship involves the exercise of a virtue which Bob’s
does not: the virtue of faith, as exhibited in Alice’s trust in Bob’s
testimony about the value of friendship.",573
I suspect that pursuing a thing for its own sake is a primitive concept.,72
"It is tempting to say that you pursue a thing for its own sake provided that
you pursue it because of the intrinsic value you take it to have. But that,
too, is incorrect. For suppose that a rich benefactor tells you that they will
give you a ton of money if you gain something of intrinsic value today. You
know that truth is valuable for its own sake, so you find out something. In
doing so, you find out the truth _because_ the truth is intrinsically
valuable. But your pursuit of that truth is entirely instrumental, despite
your reason being the intrinsic value.",567
"Brian:  
  
That's an option, but it seems to me that pursuing y for the sake of y is
different from pursuing y for its own sake, in the same way that x knowing
themselves is not the same thing as x knowing x, and similarly for other kinds
of reflexive actions. For x to play chess by themselves is not the same as for
x to play chess with x. The game is essentially different because when you
play chess by yourself you know what you're planning. (One could imagine a
case where Brian plays chess with Brian, without it being Brian playing chess
by himself, by supposing time-travel.) The Frege puzzles capture a part of the
difference, but I am not sure they capture all of it.",679
"1) Maybe seeking something for its own sake is a combination of both? Not
seeking it for the sake of something else, and also seeking it because of the
intrinsic value it has?  
  
2) As for the example of seeking the truth (which has intrinsic value, as
specified) for the money you'll be given, I think the usage of reason in _""But
your pursuit of that truth is entirely instrumental, despite your reason being
the intrinsic value.""_ is a bit incomplete, since most people would use the
word ""reason"" to describe the actual goal they have in mind for which seeking
a true fact is purely instrumental.  
  
The intrinsic value of the truth then is kinda like any other property any
other thing might have that has utility - the intrinsic value is subordinated
and viewed in the light of the use it has for giving you money.  
  
You might as well be talking about seeking the proper tools to rob a bank with
a vast sum of money.",929
"Suppose you pursue truth for its own sake. As we learn from Aristotle, it does
not follow that you don’t pursue truth for the sake of something else. For the
most valuable things are both intrinsically and instrumentally valuable, and
so they are typically pursued both for their own sake and for the sake of
something else.",324
"What if you pursue something, but not for the sake of something else. Does it
follow that you pursue the thing for its own sake? Maybe, but it’s not as
clear as it might seem. Imagine that you eat fiber for the sake of preventing
colon cancer. Then you hear a study that says that fiber doesn’t prevent colon
cancer. But you continue to eat fiber, out of a kind of volitional inertia,
without any reason to do so. Then you are pursuing the consumption of fiber
not for the sake of anything else. But merely losing the instrumental reason
for eating fiber doesn’t give you a non-instrumentally reason. Rather, you are
now eating fiber irrationally, for no reason.",662
"Here's another reason to think there is a difference. If I achieve x for the
sake of y, then y is a final cause of x. But if I achieve x for its own sake,
then x is not its own final cause. So to achieve x for its own sake is not the
same as to achieve x for the sake of x. And what goes for achievement probably
goes for pursuit.  
  
Now, you might say that if I achieve x for the sake of y AND x and y are
distinct, then y is a final cause of x. But now it looks like there is a
serious structural difference between achieving x for its own sake and
achieving x for the sake of y: in the latter case we have final causation and
in the former we don't. But now it seems ""x for the sake of y"" claims are
disjunctive in nature.",727
"Perhaps it is impossible to do something for no reason. But even if it is
impossible to do something for no reason, it is incorrect to _define_ pursuing
something for its own sake as pursuing it not for the sake of something else.
For that you _pursue something for its own sake_ states something positive
about your pursuit, while that you _don’t pursue it for the sake of anything
else_ states something negative about your pursuit. There is a kind of valuing
of the thing for its own sake that is needed to pursue the thing for its own
sake.",544
"If there is a primitive notion in the vicinity, wouldn't it just be the three-
place predicate ""x pursues y for the sake of z""? From here, we can analyze ""x
pursues y for its own sake"" as ""x pursues y for the sake of y,"" and we can
analyze ""x pursues y for the sake of something else"" as ""for some z, x pursues
y for the sake of z & z is not y.""  
  
(Maybe there would be Frege-puzzle problems with this proposal, e.g., where y
= z but the agent doesn't know this, and pursues y for the sake of z?)",499
"Hence, to pursue a thing for its own sake is not the same as to pursue it
because it has intrinsic value. Nor is it to pursue it not for the sake of
something else.",164
"Wesley:  
  
1\. But you can seek something for its own sake while seeking it for the sake
of something else as well.  
  
2\. So, this is the weird thing about my example: the non-instrumental value
is being instrumentally pursued. (It kind of reminds me of Frege's infamous
""The concept horse is not a concept"".) But the point remains that the non-
instrumental value is indeed a goal one has, just as when one is seeking to
rob a bank, the obtaining of the tools is a goal one has. Sure, you can use
""goal"" or ""reason"" in such a way as to indicate the ultimate goal which one
non-instrumentally pursues, but then the account of non-instrumental pursuit
becomes circular: you non-instrumentally pursue X iff X is your non-
instrumentally pursued goal  
  
By the way, one can combine my truth and ""volitional inertia"" examples.
Suppose that a rich eccentric is paying me each time I get something of
intrinsic value. I am greedy and generally lacking in virtue, so I pursue all
sorts of things of intrinsic value solely for the sake of money. Then the
eccentric withdraws the offer. Out of volitional inertia, I continue to pursue
the things of intrinsic value, and do so because they have intrinsic value,
but I don't suddenly come to pursue them for their own sake. So in this
example, I pursue something because of its intrinsic value, and for no other
reason, and yet I do not pursue it for its own sake.  
  
I still think there is no way out of these cases other than to make the
concept of pursuit of a thing for its own sake primitive.",1545
"1) You can indeed seek something for its own sake while also seeking it for
the sake of something else, but that implies there are two motives properly
distinct from the other; and one could then perhaps say that what defines the
motive of seeking something for its own sake is to not seek it for the sake of
something else AND to seek it for the intrinsic value it has. This motive,
having such a structure, would still be properly distinct from the other
motive which DOES seek something for the sake of something else.  
  
2) So about seeking a thing of intrinsic value instrumentally, I think this
just reifies (or is that the wrong word to use?) or reduces the intrinic value
of a thing to just a means - you could literally just replace it and have the
rich man tell you he's gonna give you much money if you find something
completely red today.  
  
The redness in this case, just like the intrinsic value in the other, is just
an identifier that you're looking for in order to gain something else. So I
think there's a confusion of meaning going on when someone says they pursue X
because of the intrinsic value it has. One could take this in an instrumental
sense, or one could instead take this in a sense similar to how one loves
others for their own sake, or oneself for one's own sake.  
  
When one seeks the good of another person for the other's own sake, I guess
one is thereby recognising the intrinsic axiology or value-ness of the person
and doing the action on the basis of that.  
  
One sees the value of the other and recognises that benefitting the other
person itself, taking the person as the end because they're valuable simply as
such (axiologically I guess?) is good. So benefitting them is just
intrinsically worth seeking of itself, with the end being the person, and the
grounds being the value & worth of the person properly distinct from any other
end.  
  
  
3) As for achieving X for the sake of Y, I think the person doing the
achieving is also crucial. For the person wanting to achieve X for the sake of
Y, Y is the final cause of **their achieving** X, not X by itself simpliciter.  
  
So it seems one could say that, for the person wanting to achieve X, if he
wanted to do this for its own sake, he'd be taking X as the final cause of the
very achieving itself, or the seekig to achieve. There's no problem in taking
X as the final cause of itself then, since it's not about a final cause
inhering in X itself.  
  
  
4) I'd also love to know the difference between seeking X for X's sake and
seeking it for its own sake, because those two seem identical to me - what is
""its own sake"" in regards to X? How could it not be, well.....X itself? Since
the ""own"" is self-referential to X?  
  ",2735
"what about emergent properties? ex. atoms, neurons, Brians, consciousness.
Similar to other parts for what makes a human being",126
"1\. The material aspect of the typical human being is an 80 kg atomic
arrangement. (Known by science.)  
2\. If materialism is true, a typical human being is identical with its
material aspect. (By definition of materialism)  
3\. So, materialism is false or a typical human being is identical with its
material aspect. (From 2 by definition of material conditional)  
4\. So, materialism is false or a typical human being is identical with an 80
kg atomic arrangement. (From 1 and 3)  
5\. So, if materialism is true, a typical human being is identical with an 80
kg atomic arrangement. (From 4 by definition of material conditional)  
  
Which step do you dispute?",666
"Pruss: Does the materialist at least grant that the vocabulary of atomic
physics is insufficient to say everything that can truthfully be said? For
example, statements about enzymes catalyzing particular reactions (or, worse
yet, being ""life-sustaining"") are not sayable in the vocabularly of atomic
physics.",308
"On reflection, it is easy enough to get around my worry just by eliminating
the word ‘much’ from the first premise. I think the argument would go through
just as well. But I’m still puzzled about how to think of intrinsic value in
parts.",237
"Michael:  
  
I assume that the typical materialist thinks that statements about enzyme
activity and the like are statements about how atoms are arranged.  
  
Imagine a perfect computer simulation of the behavior of the atoms in a human
body. Either that simulation would include a simulation of enzyme activity or
not. If it does not, then we have weird top-down laws that ensure that the
microphysical laws have exceptions. I am open to that possibility but the
typical materialist is not. But if automatically the simulation of the
behavior of the atoms includes a simulation of enzyme activity, then the
materialist has a very good case that enzyme activity just is behavior of
atoms.",689
"The justification is empirical: The material aspect of the human being is
scientifically known to be an 80 kg atomic arrangement. If materialism is
true, the material aspect is the only aspect. So, if materialism is true, the
human being is an 80kg atomic arrangement.",268
"If materialism is true, a typical human being is an 80 kg arrangement of
atoms.",79
"Pruss: I suspect I just don't know what ""Materialism"" means (which I already
suspected, and now I'm more convinced). I'm not even entirely sure what
""material aspect"" means in a statement like ""the material aspect of a human
being is... an 80kg atomic arrangement""....  
  
Does the Materialist have to believe the following (which I'll call ""M1"")?  
  
 _The only accurate statements about a human being are statements that
describe the particular arrangement of atoms in question._  
  
If so, then the materialist surely cannot think that statements about, say,
enzyme activity or blood pressure or DNA transcription are true of humans
either, can she?",655
"@Aron Bean Also it's kinda weird to say that there can be **no such thing** as
intrinsic value...and any intrinsic value is just us evaluating things with a
subjective perspective and projecting it to them. It's weird to think we
**actually have** the ability to conceptualise something as simple and
foundational as the idea of intrinsic value...all the while such a thing
literally can't exist. Not just doesn't, but as a whole the realm of reality
doesn't and even can't have such a thing in principle...  
  
Because if the idea is by definition subjective, then we should be aware of
this. Just as we know other subjective things as subjective, like preferences,
because we know what a preference is, and know it doesn't inhere in all things
even without knowing other persons with different preferences.  
  
Yet stangely most if not all see intrinsic value not as something in the same
category as preference, but as something found out and known in reality
itself.",972
"I think the main problem with this argument is the supposition that there can
be such a thing as ""intrinsic value"", and it is independent of whether
materialism is true or not. All values are by definition subjective (because
they admit no justification, empirical or otherwise). They are not something
humans come to know, but rather, humans make (conscious or subconscious)
decisions to evaluate things according to their subjective perspective,
emotions and preferences, and then project the values they generate onto
entities.",530
"P1 seems to beg the question, no? If materialism (which I'm taking to mean
""objects have no parts in addition to their material/atomic parts"") is true,
then P1 would be like saying ""a typical human being has much more intrinsic
value than any human-sized object""....",266
"Alexander:  
  
Sure. ""If X, then Y."" in your arguments is a material conditional, which is
logically equivalent to ""Not X or Y."" by material implication and also
logically equivalent to ""It's not, that X and not Y."" by basically De Morgan's
law.  
Further some material conditionals are true as some material conditionals are
not true.  
So is your material conditional _""If materialism is true, a typical human
being is an 80 kg arrangement of atoms.""_ or ""Materialism is not true or a
typical human being is an 80 kg arrangement of atoms."" or ""It's not, that
materialism is true and a typical human being is not an 80 kg arrangement of
atoms.""?!?  
Is it justified or substantiated in any given way?!?  
I don't know and I don't see that being here is the case or made to be the
case.  
  
On the other hand my material conditional ""If any human is an arrangement of
atoms, then materialism must be necessarily true."" is self-evidently true as
the material conditional ""If a drawn quadrilateral is a square, then that
drawn quadrilateral is also a rectangle."" is self-evidently true.  
  
Also where exactly is ¬Y - a typical human being is not an 80 kg arrangement
of atoms - in your argument here?  
Your premise 1 _“A typical human being has much more intrinsic value than any
80 kg arrangement of atoms.”_ doesn't appear to constitute such a claim and
statement by itself.  
Otherwise how are you exactly concluding from those two premises of yours,
that ¬X is the case - that materialism is not true?!?  
Or is your argument supposed to be not a “Denying the consequent” argument?  
If so, what kind of an argument is it then?!?",1636
"Alexander R Pruss: ""there is no objective reason to do or believe anything""  
  
You cannot believe anything at will. Nor are your choices to do something are
ever free, even if they seem to be so. All your beliefs and choices to act are
predetermined by your genetic makeup and past experiences, which express
themselves in the current emotional/cognitive (that is, biochemical) state of
your brain. This hypothesis is simpler than to suppose some immaterial stuff,
whose interaction with material things, including the brain, would be beyond
comprehension.  
Also note that being rational is not somehow ""inherently better"" than being
irrational or arational. Rather, it's just that rationality is the kind of
attitude that pays off most of the time in the long run. And even this
""paying-off"" translates to things that support the survival of the individual,
so it can be expressed in value-neutral terms.  
  
""every reason expresses the value of the thing it is a reason for""  
This is false.  
For example, if you know that p, and also know that ""if p, then q"", then this
knowledge, together with knowledge of the rule of inference ""modus ponens"" may
be a reason for you to believe (and, also know) that q. But there is nothing
that expresses the ""value of q"" in the state of knowing p, ""if p, then q"", or
in knowing ""modus ponens"", nor in its application. They are just propositions,
syntactic structures with semantic interpretation according to classical
logic. And there are many other alternative systems of logic, even some where
modus ponens is not a theorem.",1572
"A typical human being has much more intrinsic value than any 80 kg arrangement
of atoms.",88
"@Aron 1) Wow, you just buried yourself with your own arguments. If we can't
even be sure we ourselves exist, and all knowledge / perception / thinking
could just be false or irrational or even non-existent, then golly there can't
be such a thing as justification either.  
  
Certainly not individual but even less universal - other people could just not
exist as well, or be illusions, or whatever. Even if other people existed,
universal consensus or being convinced somethign is justified could also just
as well be false or non-existent.  
  
You should thereby become an absolute skeptic of everything.  
  
  
2) As for self-awareness depending on memory...every single memory you have
right now could just be false...but you'd still be aware you have those
memories. All your beliefs could be false & illusory, yet you'd still have
those beliefs.  
  
So unless the Principle of Non-contradiction is false...we can be absolutely
sure we have the memories / beliefs / experiences we actually have.  
  
You either have memories / beliefs / thoughts / experiences or you don't.  
  ",1087
"Alex  
  
You beg the question in your argument.  
Your premise 1 is only true if materialisme is false, but it is false if
materialism is true. Because in that case, a typical human being has just as
much intrinsic value as the arrangement of atoms because he is thé arrangement
of atoms.  
Intrinsic values depend on how things (can) behave, not on their constituants.  
And this particular arrangement of atoms behaves like a human being, hence has
the intrinsic value of a human being.",489
"I think materialism is false, and I’m not sure what to think about premise 1.
What kind of value does my body (the arrangement of atoms) have on a
hylomorphic view? Does it mainly have instrumental value? In general, if W is
a whole with intrinsic value, do its parts (the xs) mainly have instrumental
value, since they are for the sake of W? Or does the intrinsic value of the
whole bleed into all of the parts?",412
"Is this supposed to be a [Denying the consequent [(X→Y∧¬Y) ⇒
¬X]](https://askaphilosopher.org/2013/11/19/denying-the-consequent/) argument?  
Then where is the premise with ¬Y - a typical human being is not an 80 kg
arrangement of atoms?!?  
  
Otherwise from materialism doesn't follow a typical human being necessarily an
80 kg arrangement of atoms. But from humans being an arrangement of any amount
of atoms follows, that materialism must be necessarily true.  
So if any human is an arrangement of atoms (- yes, even little or small humans
not weighing typically 80 kg), then materialism must be necessarily true.  ",620
"If all values are subjective, there is no objective reason to do or believe
anything, because every reason expresses the value of the thing it is a reason
for.",159
"Wesley C,  
  
""How do we rule out other forms of justification?"" I don't want to rule out
other justifications to start with, that's why I wrote ""empirical or
otherwise"".  
""And even if one can't justify this universally to others, that doesn't mean
the justification isn't true.""  
I don't accept any justification that is not universal. This is a
contradiction in terms. A justification must be repeatable and (in principle)
universally accessible to all.  
""For example, one knows one's own existence immediately and uniquely through
one's personal self-awareness.""  
No, you doesn't know that, although this is admittedly tricky. To know is not
an ""achievement verb"" expressing an instantaneous event, but a ""state verb"",
which means that it is a state of an organism, and has a certain temporal
duration.  
Knowing, and also self-awareness and self-perception for that matter,
presuppose the correctness of memory, and because memory is fallible, there is
a chance (meaning that you cannot rule it out) that you are mistaken in
believing (and therefore you don't know) that you exist.",1090
"_""Which step do you dispute?”_  
  
I dispute step 3 _""So, materialism is not true. (From 1 ""A typical human being
has much more intrinsic value than any 80 kg arrangement of atoms."" and 2 ""If
materialism is true, a typical human being is an 80 kg arrangement of atoms.""_
[- maybe by a [modus tollens](https://en.wikipedia.org/wiki/Modus_tollens)?!?]
_)""_  
from your original post.  
I also reject premise 2 _""If materialism is true, a typical human being is an
80 kg arrangement of atoms.""_ here as I reject premise 2 _""If materialism is
true, a typical human being is identical with its material aspect. (By
definition of materialism)""_ from your previous comment of a red herring
deviating from my second very trivial disposition of you being not capable of
making and bringing together a simple
[syllogism](https://en.wikipedia.org/wiki/Syllogism).  
It's your ""definition"" and a straw man of materialism and not mine and besides
that:  
  
1\. The material aspect of the typical human being is an 80 kg atomic
arrangement. (Known by science.)  
2\. If the material aspect of the typical human being is an 80 kg atomic
arrangement, then materialism is true. (Trivially and self-evidently true)  
3\. So, materialism is true. (From 1 and 2 by [modus
ponens](https://en.wikipedia.org/wiki/Modus_ponens))  
  
Do you like it? No?  
Then how about a ""compromise""? How about the Truth with the capitol T?  
  
1\. The material aspect of the typical human being is an 80 kg atomic
arrangement. (Known by science.)  
 **2\. Materialism is true,[if and only
if](https://en.wikipedia.org/wiki/Logical_biconditional) the material aspect
of the typical human being is an 80 kg atomic arrangement. (By dogmatic belief
of physicalism)**  
3\. So, if materialism is true, then the material aspect of the typical human
being is an 80 kg atomic arrangement. (From 2 by biconditional implication)  
4\. So, if the material aspect of the typical human being is an 80 kg atomic
arrangement, then materialism is true (From 2 by biconditional implication)  
5\. So, materialism is true. (From 1 and 4 by modus ponens)  
  
Sooo...  
 _ **Which step do you dispute?**_",2151
"If they are merely weakly emergent, I don't see them making the value large
enough to contradict 1. It's still just an arrangement of atoms, a really cool
one, admittedly.  
  
If strongly emergent, then it's hard to say if we still have materialism.",250
"No, Alexander. That's basically MY justification for MY material conditional
and not yours.  
Well, my material conditional is self-evidently true, but if one has to give
an external justification for it, then because the material aspect of the
human being is scientifically known to be an 80 kg atomic arrangement,
therefore ""if any human is an arrangement of atoms, then materialism must be
necessarily true"".  
It is also logically equivalent to ""It's NOT, that any human is an arrangement
of atoms and matter AND materialism is NOT true."", which is of course in
itself true - this should be trivially and obviously true.  
  
On the other hand your material conditional is logically equivalent to ""It's
NOT, that materialism is true AND a typical human being is NOT an 80 kg
arrangement of atoms."", which is not necessarily true in the sense, that there
are of course instances/""possible worlds"", where it's true, that materialism
is true AND [a typical human being is NOT an 80 kg arrangement of
atoms](https://en.wikipedia.org/wiki/Human_body_weight).  
Sooo... You are either question begging here with this material conditional
and argument of yours here and or you are straw manning materialism.  
If you want to critique materialism as being bad for an ontological dogmatic
description or explanation of reality, then please, critique it properly. But
also please don't straw man it and don't question beg in this bad way with
that material conditional of yours.  
If ""any"" person should know it by now, how to do this properly, then you,
Alexander, should know this by now.  
  
Apropos knowing things. I still don't know, which of your premises
constitutes, that ""a typical human being is NOT an 80 kg arrangement of
atoms'', such that you could validly conclude with that dubious material
conditional of yours and by a ""denying the consequent"" argument, that
materialism is not true.  
So which premise of those two premises of yours here constitutes such a
claim?!?",1979
"Kratsch:  
  
Unless otherwise specified, or contextually required, ""if ... then ..."" in my
arguments is a material conditional. No claim is made that it *follows* from
materialism that a human is an 80 kg arrangement of atoms.",227
"@Aron Bean Isn't that just begging the question that values can't be
""justified""? In what sense - just because it's not empirical doesn't mean
there can't be other forms of justification. How do we rule out other forms of
justification? And even if one can't justify this universally to others, that
doesn't mean the justification isn't true. For example, one knows one's own
existence immediately and uniquely through one's personal self-awareness, yet
this type of justification isn't subjective and unjustifiable just because
it's inherently inaccessible to others.",568
"Here is an analogy that occurred to me. Consider a magnet. It’s not crazy to
think of the magnet’s magnetic field as an accident of the magnet. But the
magnetic field extends spatially beyond the magnet. Thus, it exists in places
where the magnet does not.",256
"No, I don’t think so. I mean, I think that in most contexts, it would be fine
to _say_ that there is a single, cube-shaped lodestone (1×1×1) and a field
that extends beyond it. But I have real doubts that this way of talking works
here.  
  
Here is an analogy. The question of where I am could be taken to be asking
either where my principal activity takes place or else where all of my
activities take place. According to the first way, I am where my brain is.
According to the second way, I am where my entire body is. But it is the
latter, holistic answer, that is more fundamental.  
On this analogy, the cube-shaped lodestone is like the brain; its magnetic
field is like the whole body. The substance as a whole has one small,
localized activity and another activity that is more spread out. The answer to
the question, “Where is the magnet?” depends on which activity you have in
mind, but the more fundamental version of the question concerns all of its
activities rather than some of its limited, localized activities.  
  
What am I missing? How else does a substance get its ‘where’?",1095
"On Thomistic accounts of transsubstantiation, the accidents of bread and wine
continue to exist even when the substance no longer does (having been turned
into the substance of Christ’s body and blood). This seems problematic.",226
"But where in space is the substance of the magnet? I would have thought that
it is where it acts, and since the magnetic field is how the magnet acts qua
magnet, it could not extend beyond the substance. The reason it feels like the
magnetic field extends beyond the magnet is that it acts in more than one way
(in the way it acts on the hand when it is held and in the way it acts on
magnetic metals).",402
"Imagine that there is only one substance in the world, a magnet. It has a
magnetic field extending around it, beyond the magnet, no?  
  
(Of course, one could count the magnetic field as a separate substance. But
it's not clear that that's the right view.)",257
"Actually, if we throw relativity into the mix, then we can get an even closer
analogy, assuming still that a magnet’s field is an accident of the magnet.
Imagine that the magnet is annihilated. The magnetic field disappears, but
gradually, starting near the magnet, because all effects propagate at most at
the speed of light. Thus, even when the magnet is destroyed, for a short
period its magnetic field still exists.",419
"That said, I don’t know if the magnet’s field is an accident of it. (Rob Koons
in conversation suggested it might be.) But it’s comprehensible to think of it
as such, and hence the analogy makes Thomistic transsubtantiaton
comprehensible, I think.",247
"Now, according to four-dimensionalism, time is rather like space. If so, then
an accident existing _when its substance does not_ is rather like an accident
existing _where its substance does not_. Hence to the four-dimensionalist, the
magnet analogy should be quite helpful.",274
"I agree with your eternalism; still, I think this particular worry might
remain. It seems that the idea of a substance's accidents existing at a time
at which the substance itself does not exist pushes against the very same
intuitions that might have bothered us to begin with. In other words, it seems
that the problem can be restated in eternalist terms.  
  
Thanks for the two points on consubstantiation; they're both interesting, and
I'll have to give them more thought.",476
"I am an eternalist. I think it's OK for the accidents of a substance to be
located at a time where the substance does not exist. In one sense this isn't,
however, a case of the accidents existing without the substance, because when
the accidents exist presently, the substance exists, too, albeit pastly.  
  
As for consubstantiation, here are some worries.  
  
1\. When Jesus says ""This is my body"", it seems like he is pointing to the
visible thing, namely bread. If there is bread there, then he is pointing at
the bread. Thus, if there is bread there, he is making the incorrect or at
least non-literal statement that that thing, the bread, is his body. But the
Tradition likes to take Jesus's words here literally.  
  
2\. According to Scripture and Tradition, we eat Christ's body and drink his
blood. But on a consubstantiation view, it's not clear that this is the right
way to describe it. It seems that what we really eat and drink is the co-
present bread and wine, and the body and blood just happens to come along with
it. Here's my image of consubstantiation. Suppose that magnetic fields are
substances. Then where there is a magnet, we have something like
consubstantiation: there are two substances, a magnet and a magnetic field, in
the same place (I am talking of the magnetic field inside the magnet, not the
one that extends outside of it). But suppose now you foolishly eat the magnet
(DON'T DO IT; children have died from eating two magnets and having them pinch
through intenstines). I don't think it's correct to say that you eat both
substances. It seems that what you eat is the magnet, and the magnetic field
comes along for the ride.",1665
"Hi Professor Pruss. My apologies if this is off topic, but I wanted to ask a
question about the Eucharist. Specifically, what do you think of the claim
that it is metaphysically impossible for accidents to exist in the absence of
the substance of which they are accidents? Also, do you have any particular
objections to the consubstantiation view common among Anglo-Catholics
(including myself)?",395
"So, you just gained the belief in the conjunction of _p_ and _q_. (By (5) and
(7))",82
"I don't know that it does. The main worry is that accidents depend on their
substance. But dependence can be cross-temporal, at least if eternalism is
true. See today's post, too.",179
"Before you gained the belief _p_ you didn’t believe the conjunction of _p_ and
_q_. (By (4))",92
"Abstract: Scoring rules measure the accuracy or epistemic utility of a
credence assignment. A significant literature uses plausible conditions on
scoring rules on finite sample spaces to argue for both probabilism—the
doctrine that credences ought to satisfy the axioms of probabilism—and for the
optimality of Bayesian update as a response to evidence. I prove a number of
formal results regarding scoring rules on infinite sample spaces that impact
the extension of these arguments to infinite sample spaces. A common condition
in the arguments for probabilism and Bayesian update is strict propriety: that
according to each probabilistic credence, the expected accuracy of any other
credence is worse. Much of the discussion needs to divide depending on whether
we require finite or countable additivity of our probabilities. I show that in
a number of natural infinite finitely additive cases, there simply do not
exist strictly proper scoring rules, and the prospects for arguments for
probabilism and Bayesian update are limited. In many natural infinite
countably additive cases, on the other hand, there do exist strictly proper
scoring rules that are continuous on the probabilities, and which support
arguments for Bayesian update, but which do not support arguments for
probabilism. There may be more hope for accuracy-based arguments if we drop
the assumption that scores are extended-real-valued. I sketch a framework for
scoring rules whose values are nets of extended reals, and show the existence
of a strictly proper net-valued scoring rules in all infinite cases, both for
f.a. and c.a. probabilities. These can be used in an argument for Bayesian
update, but it is not at present known what is to be said about probabilism in
this case.",1755
"Comments from a user egregiously failing in the civility required in academic
discussion have been deleted and the user has been banned. My responses to
these comments have been deleted as well out of fairness to the user. I
should, however, note for the sake of anybody who read my comments that in one
of my comments I incorrectedly stated that the logarithmic score is not
additive, and the user was right to call me out on it, but did so in a manner
that was uncivil, and failures of civility are not tolerated.  
  
(Specifically, for a subset A of Omega, let s_A(c,t)=0 unless A is a singleton
and t=1. Then let s_{w}(c,1)=log c({w}). Then the logarithmic score of c is
the sum of s_A(c,1_A(w)) as A ranges over the subsets of Omega, and hence is
additive in my sense. I was, however, correct that the logarithmic score is
not strictly proper when we allow non-probability credences, since it ony
depends on the credences at singletons.)",943
"Well, here is a model that applies to a number of cases. There are two
incommensurable goods one better served as one goes in one direction in the
spectrum and the other better served as one goes in the other direction in the
spectrum. Let’s say that we can quantify the spectrum as one from less to more
with respect to some quantity _Q_ (amount of homework, difficulty of a
question or length of a walk), and good _A_ is promoted by less of _Q_ and
incommensurable good _B_ is promoted by more of _Q_. For instance, with
homework, _A_ is the student’s having time for other classes and for non-
academic pursuits and _B_ is the student’s learning more about the subject at
hand. With exam difficulty, _A_ may be avoiding frustration and _B_ is giving
a worthy challenge. With a walk, _A_ is reducing fatigue and _B_ is increasing
health benefits. (Note that the claim that _A_ is promoted by less _Q_ and _B_
is promoted by more _Q_ may only be correct within a certain range of _Q_. A
walk that is too long leads to injury rather than health.)",1046
"This story, though it has some difficulties, is designed for choices between
options that promote significantly different goods—say, whether to read a book
or go for a walk or write a paper.",190
"Note that nothing in the above explanatory stories requires any commitment to
there being some sort of third good, a good of balance or compromise between
_A_ and _B_. There is no commitment to _Q_ 1 being the best way to position
_Q_.",235
"On both approaches, the apparent inconsistency of citing opposed goods
disappears because they are cited to explain different contrasts.",136
"Here is one suggestion. Take the choice to make _Q_ equal to _Q_ 1 to be the
conjunction of two (implicit?) choices:",116
"Now, we can explain choice (a) in terms of (a) serving good _A_ better than
the alternative, which would be to make _Q_ be bigger than _Q_ 1. And we can
explain (b) in terms of (b) serving good _B_ better than the alternative of
making _Q_ be smaller.",251
"Here is a variant suggestion. Partition the set of options into two ranges _R_
1, consisting of options where _Q_ < _Q_ 1 and _R_ 2, where _Q_ > _Q_ 1. Why
did I choose _Q_ = _Q_ 1? Well, I chose _Q_ over all the choices in _R_ 1
because _Q_ better promotes _B_ than anything in _R_ 1, and I chose _Q_ over
all the choices in _R_ 2 because _Q_ better promotes _A_ than anything in _R_
1.",387
"But a different kind of situation comes up for choices of a point on a
spectrum. For instance, suppose I am deciding how much homework to assign, how
hard a question to ask on an exam, or how long a walk to go for. What is going
on there?",238
"My usual story about how to reconcile libertarianism with the Principle of
Sufficient Reason is that when we choose, we choose on the basis of
incommensurable reasons, some of which favor the choice we made and others
favor other choices. Moreover, this is a kind of constrastive explanation.",292
"So, now, suppose we choose _Q_ = _Q_ 1. Why did one choose that? It is odd to
say that one chose _Q_ on account of reasons _A_ and _B_ that are opposed to
each other—that sounds inconsistent.",191
"Note that our preference for simplicity here is actually infinite. For if we
were to collate the data, there would not just be _one_ real number that fits
the data better than 2 does, but a _range_ _J_ of real numbers that fits the
data better than 2. And _J_ contains uncountably many real numbers. Yet we
rightly think that 2 is more likely than the claim that the true exponent is
in _J_ , so 2 must be infinitely more likely than most of the numbers in _J_.",461
"I like to illustrate the evidential force of simplicity by noting that for
about two hundred years people justifiably believed that the force of gravity
was _G_ _m_ 1 _m_ 2/ _r_ 2 even though _G_ _m_ 1 _m_ 2/ _r_ 2 + _ϵ_ fit the
observational data better if a small enough but non-zero _ϵ_. A minor point
about this struck me yesterday. There is doubtless some _p_ ≠ 2 such that _G_
_m_ 1 _m_ 2/ _r_ _p_ would have fit the observational data _better_. For in
general when you make sufficiently high precision measurements, you never find
_exactly_ the correct value. So if someone bothered to collate all the
observational data and figure out exactly which _p_ is the best fit (e.g.,
which one is exactly in the middle of the normal distribution that best fits
all the observations), the chance that that number would be 2 up to the
requisite number of significant figures would be vanishingly small, even if
_in fact_ the true value is _p_ = 2. So simplicity is not merely a tie-
breaker.",989
"However, it is implausible to think that we humans ought to do something that
nobody has been able to do until recently and even now only a few can do, and
only in limited cases, even if the something is involuntary.",216
"I agree and not just people not capable of correctly and properly Bayesian
reasoning shouldn't Bayesian reason, but also people not capable of correctly
and properly estimating things and reasoning in general should not estimate
things and reason in general.  
Just look at what happend in Sally Clark's case:  
[""Making A Math Murderer"" by Vsauce2](https://youtu.be/mLEWj-61a4I)  
I guess, that for good reasons [""Meadow's
law""](https://en.wikipedia.org/wiki/Meadow%27s_law) is no longer a law.  ",497
"But if ""Meadow's law"" is no longer a law, then why are so many theists and
apologists so fond of [Plantinga's poker
analogy](https://www.youtube.com/watch?v=KDBkmpm-APE&t=757s)?!?  
I guess, because even though they can not correctly and properly Bayesian
reason and therefore shouldn't do it, they are doing it regardless of the
possibility of them being so irrational with it.  ",380
"Even if you acquire the basic mathematical skills, keeping track of
probabilities and conditionalizing on all the evidence is simply beyond our
capabilities. I am constantly receiving vast amounts of data. I just can't
conditionalize on it. All I can do is to pick out some small subset of the
data that seems relevant, and conditionalize on that. Take the lab scientist
who sees an instrument display ""3.445"". Maybe, though even that is a stretch,
they can conditionalize on the instrument displaying ""3.445"". But that's such
a small part of their evidence: there is, for instance, the particular pattern
of lights and shadows playing over the instrument display, the flow of air
from the vents, etc. Sure, one normally approximates by assuming all that
other stuff is independent of what one cares about in the experiment. But the
fact remains that one is failing to conditionalize on all one's data.",902
"Ought implies can. Most people can’t do Bayesian reasoning correctly. So
Bayesian reasoning is not how they ought to reason. In particular, a reduction
of epistemic ought to the kinds of probability fcts that are involved in
Bayesian reasoning fails.",250
"Could it be that the epistemic responsibility is to ""go where the evidence
points"", and that Bayesianism is just the most rigorous form of that? It would
be like saying that we ought to measure carefully when cutting the pieces to
build someone's house, but that we can only do as well as our available
instruments let us, and that that is sufficient. Bayesian reasoning as such
may not be an ""available instrument"" for most of us, but we ought to
approximate it as much as we can.  
  
I think Steven Pinker just wrote a book in which he equates rationality with
something like Bayesianism. I haven't read it yet, but it's on my list!",635
"Maybe the relevant ought facts are like this: Even if we can't reason in
Bayesian way, we can acquire that ability, and we ought to. So we ought to do
something such that, if we do it, then we ought to reason in a Bayesian way.  
  
I can imagine someone saying something like, if we ought to phi, and phi-ing
implies that we ought to psi, then we ought psi.  
  
Consider something as plain as it being the case that I ought to place the
item on the shelf (I promised to, or I work at a grocery store). But I can't,
since I haven't picked up the item, and so how can I place the item on the
shelf? Clearly, we say that I can place the item, because I can pick it up
first.  
  
I realise as I type that this example isn't exactly what I started with, so
maybe this example illustrates the following principle:  
  
Principle: If you can and ought do something X, such that by doing X, you can
do something Y, and the ability to do Y is sufficient for it being the case
that you _ought_ to do Y, then you _can_ do Y and you ought to do Y.  
  
In the item-shelving case, X is pick up the item and Y is place the item on
the shelf. In the epistemology case, X is acquire Bayesian reasoning skills
and Y is reasoning in a Bayesian way. Of course, this only applies to those
who can learn, which is probably most adults.  
  
I have no idea how plausibly I find this. I'm just playing around with
possibilities.",1408
"I suppose the main worry with this argument is that perhaps only an ought
governing voluntary activity implies can. But the epistemic life is in large
part involuntary. An eye ought to transmit visual information, but some eyes
cannot—and that is not a problem because seeing is involuntary.",291
"If Bayesian reasoning isn’t how we ought to reason, what’s the point of it? I
am inclined to think it is a useful tool for figuring out the truth in those
particular cases to which it is well suited. There are different tools for
reasoning in different situations.",264
"Or suppose you are driving a fire truck to a place where five people are about
to die in a fire, and you know that you have a 1/4 chance of putting out the
fire and saving them if you get there in time. Moreover, there is a person
sleeping on the road in front of the only road to the fire, and if you stop to
remove the person from the road, it will be too late for the five. Do you
brake? Expected utilities:  − 5 lives for braking and  − 1 − 3.75 = − 4.75
lives for continuing to the fire and running over the person on the road.",532
"I think you shouldn’t redirect and you should brake. There is something
morally obnoxious about certainly causing death for a highly uncertain benefit
_when the expected values are close_. This complicates the proportionality
condition in the Principle of Double Effect even more, and provides further
evidence against expected-value utilitarianism.",349
"Suppose a trolley is heading towards five people, and you can redirect it
towards one. But the trolley needs to go up a hill before it can roll down it
to hit the five people, and your best estimate of its probability of making it
up the hill is 1/4. On the other hand, if you redirect it, it’s a straight
path to the one person, who is certain to be killed. Do you redirect? Expected
utilities:  − 1.25 lives for not redirecting and  − 1 lives for redirecting.",461
"I still feel that the fact that in my examples, almost surely, at some
*finite* point in time the expected utility non-maximizer overtakes the
expected utility maximizer, and after that the gap just increases, seems
significant. But I can't put my finger on what exactly is significant about
it.",295
"In [an earlier post](https://alexanderpruss.blogspot.com/2011/11/attitudes-to-
risk-and-law-of-large.html), I suggested that perhaps the Central Limit
Theorem (CLT) rather than the Law of Large Numbers is what one should use to
justify betting according to expected utilities. If the variables _X_ 1, _X_
2, ... satisfy the conditions of the CLT, and have non-negative expectations,
then _P_ ( _X_ 1+...+ _X_ _n_ ≥0) will eventually exceed any number less than
1/2. In particular, we won’t have the kind of disastrous situation where the
overall payoffs almost surely go negative, and so no example like my above one
can satisfy the conditions of the CLT.",655
"Hence even when the SLLN applies, we can have cases where almost surely there
are only finitely many positive payments, infinitely many negative ones, and
the negative ones add up to  − ∞.",188
"Here I want to make a minor observation. The fact that the SLLN applies to
some sequence of independent random variables is itself not sufficient to make
it rational to bet in each case according to the expectations in an infinite
run. Let _X_ _n_ be 2 _n_ / _n_ with probability 1/2 _n_ and − 1/(2 _n_ ) with
probability 1 − 1/2 _n_. Then",339
"Yes, I’d say that, if, in the case of nth expectation greater than c>0,
someone takes SLLN (if it applies) as a reason to accept all the bets, then in
your example they should refuse to accept all the bets – if they reason on the
basis of a ‘with probability 1’ result in one case, they should also do so in
the other. That said, you should take care to note exactly what the various
authors are actually arguing.  
  
Speaking for myself, I don’t think that any result about an actual infinity of
bets, or even just about limits of finite sequences of bets, is in itself a
good reason to do anything. (Though, of course, such results can give useful
hints.) What matters is the likely position when the game ends, as, in the
real world, it must.  
  
In your example, the distribution of partial sums has progressively increasing
variance and skewness. Roughly (if I’m thinking straight), variance of the nth
partial sum grows like n, 3rd moment grows like (n^2)/2. The normalized 3rd
moment (i.e. with the outcome divided by its s.d. to make the variance 1)
grows like (n^(1/2))/2. If I were really offered this sequence of bets, with
the option of choosing in advance how many to accept, I’d feel that for large
n, things would get pretty hairy, way too hairy to justify accepting on the
basis of the positive expectation, which only grows like ln(n)/2. So I’d
choose a smallish n I felt comfortable with.",1408
"The last example (with a_n = 1/n^2) is very neat. I had been trying to think
of something similar. :-)  
  
The Peköz paper I mentioned in the other post has, in addition to the variance
condition [sum of (nth variance/n^2 finite)], the condition that all the
individual expectations are greater than some strictly positive constant. In
the example, this is violated - the nth expectation is about 1/n. So again,
there’s no formal contradiction. Of course, this is no surprize.",477
"But the variance _σ_ _n_ 2 is less than _a_ _n_ /( _n_ _a_ _n_ )2 \+ 1 = (1/(
_n_ 2 _a_ _n_ )) + 1. If we let _a_ _n_ = 1/ _n_ 2 (the sum of these is
finite), then each variance is at most 2, and so the conditions of the
Kolmogorov version of the SLLN are satisfied.",266
"In discussions of maximization of expected value, the Law of Large Numbers is
sometimes invoked, at times—especially by me—off-handedly. According to the
Strong Law of Large Numbers (SLLN), if you have an infinite sequence of
independent random variables _X_ 1, _X_ 2, ... satisfying some conditions
(e.g., in the Kolmogorov version ∑ _n_ ( _σ_ _n_ 2/ _n_ 2) < ∞, where _σ_ _n_
2 is the variance of _X_ _n_ ), then with probability one, the average of the
random variables converges to the average of the mathematical expectations of
the random variables. The thought is that in that case, if the expectation of
each _X_ _n_ is positive, it is rationally required to accept the bet
represented by _X_ _n_.",705
"_E_ _X_ _n_ = (1/2 _n_ )(2 _n_ / _n_ ) − 1/(2 _n_ )(1−1/2 _n_ ) = (1/ _n_
)(1−(1/2)(1−1/2 _n_ )).",97
"If you assume that the nth expectation is bigger than c>0, and the Strong Law
of Large Numbers applies, then of course almost surely the person who accepts
all the bets will eventually be better off than the person who rejects all the
bets, and the difference between the two will grow without bound. And the
variance condition is sufficient for the Strong Law.  
  
Do you think this is true: If someone thinks the above result is a good reason
to accept rather than reject all the bets, then they should also think that in
my case we have good reason to reject rather than accept all the bets?",595
"In [a recent post](http://alexanderpruss.blogspot.com/2022/10/expected-
utility-maximization.html), showed how in some cases where the Strong Law of
Large Numbers is not met, in an infinite run it can be disastrous to bet in
each case according to expected value.",263
"Clearly _E_ _X_ _n_ > 0. So in individual decisions based on expected value,
each _X_ _n_ will be a required bet.",113
"In the above example, while the variables satisfy the SLLN, they do not
satisfy the conditions for the Kolmogorov version of the SLLN: the variances
grows exponentially. It is somewhat interesting to ask if the variance
condition in the Kolmogorov Law is enough to prevent this pathology. It’s not.
Generalize my example by supposing that _a_ 1, _a_ 2, ... is a sequence of
numbers strictly between 0 and 1 with finite sum. Let _X_ _n_ be 1/( _n_ _a_
_n_ ) with probability _a_ _n_ and  − 1/(2 _n_ ) with probability 1 − _a_ _n_.
As before, the expected value is positive, and by Borel-Cantelli (given that
the sum of the _a_ _n_ is finite) almost surely the payoffs are  − 1/(2 _n_ )
with finitely many exceptions, and hence the there is a finite positive payoff
and an infinite negative one in the infinite run.",813
"Now, just as in my previous post, almost surely (i.e., with probability one)
only finitely many of the bets _X_ _n_ will have the positive payoff. Thus,
with a finite number of exceptions, our sequence of payoffs will be the
sequence  − 1/2, − 1/4, − 1/6, − 1/8, .... Therefore, almost surely, the
average of the first _n_ payoffs converges to zero. Moreover, the average of
the first _n_ mathematical expectations converges to zero. Hence the variables
_X_ 1, _X_ 2, ... satisfy the Strong Law of Large Numbers. But what is the
infinite run payoff of accepting all the bets? Well, given that almost surely
there are only a finite number of _n_ such that the payoff of bet _n_ is not
of the form − 1/(2 _n_ ), it follows that almost surely the infinite run
payoff differs by a finite amount from  − 1/2 − 1/4 − 1/6 − 1/8 = − ∞. Thus
the infinite run payoff is negative infinity, a disaster.",890
"For instance, suppose at the beginning of a science class you are
teachingabout your studnts about significant figures, and you ask a student to
tell you the mass of a textbook in kilograms. They put it on a scale
calibrated in pounds, look up on the internet that a pound is exactly
0.45359237 kg, and report that the mass of the object is 1.496854821 kg.",356
"Now, you know that the classroom scale is not accurate to ten significant
figures. The chance that the student’s measurement was right to ten
significant figures is tiny. You _know_ that the student’s statement is wrong,
assuming that it _is_ in fact wrong.",257
"My claim was only that typically you learn something in favor of p by being
told that p is true. There are, of course, exceptions (e.g., if you know that
someone is going to be lying, in which case their saying something is evidence
that they disbelieve it, which in turn is evidence against it).  
  
That said, that an intelligent person believes a clear and explicit
contradiction may be some very slight evidence against the law of
noncontradiction.",453
"Here’s an odd phenomenon. Someone tells you something. You know it’s false,
but their telling it to you raises the probability of it.",133
"Alex  
  
Suppose you want to go to a place P. There is only one road that leads to P,
namely the road to the right.  
Now you ask me which way you should go and I tell you that the left road is
the correct one, which is the wrong way.  
What do you learn from this?",266
"On reflection, the phenomenon in the first sentence of the post isn't odd at
all. Typically if someone tells you something, that is evidence for what they
tell you, even if you know it's not true.",196
"Alex  
  
If the first digits are likely close, what the student says is not completely
wrong. It is inaccurate.  
The reason you learn something from it is because you already have knowledge
about the book's probable weight. Suppose you ask me about the distance
between the earth and the moon and I say it's 400 000 km. That's wrong, but it
is a better answer than, say, 4 million km. Suppose that before you asked me,
you estimated the distance as between 100 000 and 1 million, then now you
estimate it between 300 000 and 500 000.  
The reason you can estimate it is becasue you have a certain confindence in my
claims. Even though you know I cannot have measured the distance accurately
enough to know it's 400 000 km, you are still confident that I at least know
something about it.  
Now compare this to a situation in which I simply tell you a random distance.
The only thing you learn from this is that I am not capable of or willing to
make a genuine effort.  ",971
"Of course, some people will want to turn this story into an argument that you
don’t know that the student’s statement is wrong. My preference is just to
make this statement another example of why _knowledge_ is an unhelpful
category.",233
"So, you know that what the student says is false, but your credence in the
content has just gone up by a factor of ten.",119
"Even if you know that I am telling you a random distance, you still learn from
it. For your knowledge of such facts as that I am telling you a random
distance is never certain. It may look like I'm just making it up at random,
but there is a chance that my statement is guided by the truth. (There is also
a chance that my statement is guided by falsehood. But I think that, absent
special evidence about me having reason to positively deceive you, that chance
is smaller.) Or I may be filtering particularly ridiculous random answers
(e.g., you ask me how many miles it is from Waco to Los Angeles, and I google
""random number"", and get 4; but that's too ridiculous, so I just say 100).",687
"Nonetheless, even though you know the statement is wrong, it raises the
probability that the textbook’s mass is 1.496854821 kg (to ten significant
figures). For while most of the digits are garbage, the first couple are
likely close. Before you you heard the student’s statement, you might have
estimated the mass as somewhere between one and two kilograms. Now you
estimate it as between 1.45 and 1.55 kg, say. That raises the probability that
in fact, up to ten significant figures, the mass is 1.496854821 kg by about a
factor of ten.",537
"Suppose Alice deserves a punishment of degree _d_ , and Bob and Carl each
impose on her a different punishment of degree _d_. Who unjustly punished
Alice?",154
"Maybe we can say that each of Bob and Carl contributed to an unjust
punishment. But what each contributed was just! Still, I think the
contribution story seems best to me.",171
"If one punishment came before the other, we can say that the second punishment
was unjust, since it was the punishment of a person who no longer deserved
punishment. But what if the two punishments are simultaneous?",215
"The contribution story does seem intuitively correct, and I think we can make
sense of the fact that two just punishments combine into an unjust punishment.
If Alice deserves a punishment to degree d, then it seems Alice must have done
something which harmed someone else proportionally to degree d. This is
because the degree of punishment deserved must be proportional to the degree
of harm done. Thus, if both Bob and Carl simultaneously impose punishments of
degree d on Alice, then each has imposed punishments that are separately
proportional to the harm done, but are jointly disproportional to the harm
done. It is this disproportionality that renders the joint punishment unjust.  
  
I wonder if this suggests that punishment can only properly come from one
source (where this source may be either one individual or a collective)?
Consider the following equivalent, but slightly more specified case. A
teenager breaks into a church donation box and steals the money inside. Upon
finding out about this theft, the teen's parents separately and unbeknownst to
the other donates money to the church from the teen's bank account equal to
the amount stolen plus some amount X that fulfills the requirements of
punishment (e.g. covering secondary harms like the broken offering box and
serving as a deterrent for future theft). Similar to the previous case, each
punishment is proportional to the harm done and therefore just. Additionally,
these punishments are jointly unjust as, combined, they are clearly
disproportional to the harm done.  
  
Notice in this case it seems the problem is that the parents did not act as
one unit. They independently imposed two punishments for one bad act. These
punishments combine to one joint punishment that is issued from the collective
parents. So while individually neither parent gave an unjust punishment, they
failed as members of the actual punishing entity to properly coordinate and
issue just punishment.  
  
It's also interesting to consider an opposite case. Start with the previous
case, only this time each parent independently impose punishments that are
half of what is deserved. In this case, each punishment is individually less
than what justice calls for (and is thus unjust to the victims), but they are
jointly just. As such, the parents jointly and accidentally punished their
child justly. However, it seems neither is praiseworthy because they
individually issued unjust punishments.",2454
"Alex (Pruss)  
  
Bob's punishment is not just if Bob knows about Carl's punishment and vice
versa.  
the only way to have a just punishment in this case is by cooperating. That
means that Bob, as soon as he knows about Carl's punishment, should talk to
Carl and together they can impose a just punishment.  
If Carl and Bob ezch get to impose their punishment it is not a punishment of
degree d, but a punishment of degree (d+d) and a punishment of degree (d+d) is
unjust in the case of Alice.",494
"This fine point doesn’t affect anything I said about independence, given the
standard mathematical definition thereof. But there is an intuitive sense of
independence in which we can now see that the bits are _not_ independent. For
instance, while each bit can be 1 on its own, it is impossible to have all the
bits be 1 (this is actually impossible regardless of how I decided on choosing
the expansion, because _x_ = 1 is excluded), and indeed impossible to have all
the bits be 1 from some point on. There is a very subtle dependence between
the bits that we cannot define within classical probability, a dependence that
would be lacking if we tossed an infinite number of ""really"" independent fair
coins.",708
"Now, what I said is actually underspecified. For some numbers have two binary
expansions. E.g., 1/2 can be written as 0.100000... or as 0.011111... (compare
how in decimal we have 1/2 = 0.50000... = 0.49999...). So when talked of “the”
binary expansion, I need to choose one of the two. Suppose I do the intuitive
thing, and consistently choose the expansion that ends with an infinite string
of zeroes over the expansion that ends with an infinite string of ones.",464
"Suppose that I uniformly randomly choose a number _x_ between 0, inclusive,
and 1, exclusive. I then look at the bits _b_ 1, _b_ 2, ... after the binary
point in the binary expansion _x_ = 0. _b_ 1 _b_ 2.... Each bit has equal
probability 1/2 of being 0 or 1, and the bits are independent by the standard
mathematical definition of independence.",345
"It's also interesting to think about whether one's intuitions would be
different in a reverse case. On day n, if you take the gamble, you are sure to
get 1/2 unit and have a 1/2^n chance of losing 2^n. By expected utilities, you
should refuse. But if you always accept, then almost surely you lose only a
finite amount and gain an infinite amount.",347
"Here’s what will happen if you always go for this gamble. It is almost sure
(i.e., it has probability one) that you will only win a finite number of
times. This follows from the [Borel-Cantelli
lemma](https://en.wikipedia.org/wiki/Borel%E2%80%93Cantelli_lemma) and the
fact that ∑2− _n_ < ∞. So you will pay the price of half a unit of utility
every day for eternity, and win only a finite amount. That’s a bad deal.",416
"Well, here is one way to look at headache setup…  
  
If you make only a finite number of bets, you and your friend together are
certain to suffer an infinite number of headache days. If you accept all the
bets, it’s possible that you might win them all. Then you and your friend will
suffer no headaches. (I’m assuming that the headache-free days you win for
your friend are taken sequentially without gaps.) Of course, this outcome has
probability zero. But isn’t the _possibility_ of no headaches, even at
probability zero, to be preferred to the _certainty_ of an infinite number?
:-). And note, this sort of ‘reasoning’ applies even if the expected value of
each bet is negative. :-)  
  
Hmm… This line of thought gives zero value to any merely finite change. But if
you take the actual infinity seriously, and you compare by counting headache
days, I’m not even sure that that is wrong. Maybe it’s better to stick with
the original version with positive and negative payoffs.",982
"**Final remark:** It is worth considering what happens in interpersonal cases,
too. Suppose infinitely many people numbered 1, 2, 3, ... are given the
opportunity to play the game, with person _n_ being given the opportunity of
winning 2 _n_ units with probability 2− _n_. If everyone goes for the game,
then almost surely a finite number of people will win a finite amount while an
infinite number pay the half-unit price. That’s disastrous: an infinite price
is being paid for a finite benefit.",496
"**Response:** In any finite number of steps, of course the expected winnings
are higher than the price you pay. But nonetheless as the number of steps gets
large, the chance at those expected winnings shrinks. Imagine that the game
goes on for 200 days, the game on day 100 has finished, and you’re now
choosing your policy for the next 100 days. The expected utility of playing
for the next 100 days is 50 units. However, assuming you accept this policy,
the probability that you will win anything over the next 100 days is less than
2−100, and if you don’t win anything, you lose 50 units of utility. So it
doesn’t seem crazy to think that the no-playing policy is better, even though
it has worse expected utility. In fact, it seems like quite a reasonable thing
to neglect that tiny probability of winning, less than 2−100, and refuse to
play. And knowing that the expected utility reasoning when extended for
infinite time leads to disaster (infinite loss!) should make one feel better
about the decision to violate expected utility maximization.",1051
"I guess I've tended to think that it's precisely in cases of rare large stakes
gambles that it makes sense to depart from expected utility. For small
repeatable gambles, of course we have central limit theorem or law of large
numbers considerations.  
By the way, we don't need anything as radical as exponential growth. Barely
more than linear growth is enough. My point goes through with n (log n)^2 as
the nth prize with probability the reciprocal of that.",459
"What worries me about this is the actual infinity of people and the unbounded
bets. Suppose there are N people. It’s clear that for large N, most people are
likely to lose small amounts. This is balanced by the very small probability
that the last few people win very large amounts. To some people’s intuition
(including mine) this does not seem like a good outcome. But I think that an
_argument_ for this has to be based on this finite case.",443
"At each step, the expected winnings are 2 _n_ ⋅ 2− _n_ = 1 unit of utility,
and at the price of half a unit, it looks a good deal.",130
"Granted, this assumes you will in fact play an infinite number of times. But
it is enough to show that expected utility maximization in individual choices
is not always the best policy (and suggests a limitation in the argument
[here](https://philpapers.org/rec/ZHAIRM)).",271
"Suppose every day for eternity you will be offered a gamble, where on day _n_
≥ 1 you can choose to pay half a unit of utility to get a chance of 2− _n_ at
winning 2 _n_ units of utility.",187
"None of that suggests that there is anything wrong with Zhao and the others in
a narrow formal sense – given their conditions, their formal results hold. Of
course, the philosophical implications and practical relevance are a different
matter. The same applies to your examples.  
  
  
Against Zhao and the others, one could say this: it’s great that, given their
conditions, choosing to accept every time ‘eventually’ becomes favoured, but
is ‘eventually’ likely to be in your lifetime? It depends on the specifics.  
  
Against your examples, one could say that they require you and the other party
to have unlimited money and unlimited time to gamble with it. What matters is
the likely conditions when time or money run out.  
  
I’m doubtful about the applicability of standard decision theory for one-0ff
high stakes choices, but I’m not sure that any of these cases are decisive.  
  
Our intuitions about sequences of fair (favourable, unfavourable) bets are
reflected in the martingale (super-martingale, sub-martingale) optional
stopping theorems. But these theorems have conditions which can be violated in
quite ordinary setups. A simple example: repeated triple-or-nothing on fair
coin flips. Each bet has positive expectation, but if you accept them all, you
will lose you initial stake with probability 1.  
  
You don’t need exponential growth to get this sort of thing. A simple example
is textbook Gambler’s Ruin. A fair coin is flipped. You win $1 on Heads, lose
$1 on Tails. You play repeatedly against the house until either you go broke,
or the house does. You start with $M, the house with $N. Your chance of ruin
is M/(M+N), of ruining the house is N/(M+N). Your expected final fortune is of
course the $M you started with.  
  
But what if the house has unlimited money? Then you will be ruined, and suffer
a loss of $M, with probability 1.",1866
"**Question:** What if the game ends after a fixed large finite number of
steps?",79
"“… and suggests a limitation of the argument here.”  
  
From a formal point of view, I think the issue is that the sequence of gambles
is not ‘well-behaved’ in the sense of Zhao’s footnote 14. I can’t be sure,
because Zhao does not spell this out, but refers to _Stephen Ross “Adding
Risks: Samuelson’s Fallacy of LargeNumbers Revisited.” Journal of Financial
and Quantitative Analysis, 34:323–339, 1999_ , which is gated. (SUPPORT OPEN
ACCESS!) Zhao says _The requirement is meant to rule out improbable cases like
those where one decision has stakes that swamp all others, … ._ In this case,
the last gamble is always about the size of all the previous ones together.",670
"Ian:  
  
I am trying to argue against the thesis that you should take the bets with
positive expectation. Gambler's Ruin doesn't affect that because the bets have
zero expectation.  
  
I also have a weak intuition that cases where what goes on in each wager is
independent of what goes on in the others are more compelling. Triple-or-
nothing doesn't have this independence: once ruined, you get nothing.
Gambler's Ruin has a changing fortune.  
  
Another thing that makes my case particularly compelling to me is the
interpersonal version, where each person faces a single wager, all the wagers
completely independent, and yet if everyone maximizes their expected utility,
with probability one, the result is disastrous--infinitely many paying and
finitely many winning. It's like a tragedy of the commons, but with no
interaction between the agents' decisions, no weird undefined probabilities,
just everyone doing ordinary expected value maximization.",957
"Ian:  
  
If Causal Finitism is false, you could tweak the situation to make sure you
can't just win all the bets. For instance, you could run the story in a
supertask, make the payoffs come after the end of the supertask, and if you
""won"" all the bets (or even infinitely many of the bets), you lose all the
benefits. This does not affect the statistical independence of all the events,
because winning all the bets has zero probability, and changing things on a
zero-probability set doesn't affect independence. But it does affect
""intuitive"" independence.",558
"**Objection:** All this has to do with aggregating an infinite number of
payments, or traversing an infinite future, and hence is just another paradox
of infinity.",163
"Unbounded bets, while difficult to handle in decision theory, don't seem
metaphysically problematic. Suppose you have a friend you love as yourself but
who is currently ""scheduled"" to have a headache for eternity, while you are
currently ""scheduled"" to live forever without headache. Each time you win x
units, your friend gets x days off from headache. Each time you lose x units,
you get x days of headache. Specify that you don't get used to the headaches.
(If you think it's metaphysically impossible not to be getting used to
headaches, suppose your and your friend's memory of the previous day's
headache or lack thereof is wiped each day.)",646
"**Response:** Actually the crucial point can be made without aggregating
infinitely many payments. Suppose you adopt the policy of accepting the
gamble. Then, with probability one, there will come a day _M_ after which you
never win again. By day _M_ , you may well have won some (maybe very large)
finite amount. But after that day, you will keep on paying to play and never
win again. After some further finite number of days, your losses will overtake
your winnings, and after that you will just fall further and further behind
every day. This unhappy fate is almost sure if you always accept the gamble,
and hence if you adopt expected utility maximization in individual decisions
as your policy. And the unhappiness of this fate does not depend on
aggregation of infinitely many utilities.",794
"As I said, I can’t access Ross. But this paper [Erol A. Peköz: Samuelson's
Fallacy of Large Numbers and Optional Stopping. Journal of Risk and Insurance,
March 2002], which builds on it, states a similar result.  
  
Peköz requires the condition than Σ((Nth variance)/N^2) is finite. I’m
guessing the Ross’s condition may be similar. With even linear growth of
prizes and reciprocal linear probabilities, the sum doesn’t converge. So it
won’t converge with N (log N)^2 growth (and reciprocal probabilities) either.  
  
  
For what little it’s worth, I share your doubts about EU for rare high-stakes
gambles. My intent is to account for the apparent discrepancy between Zhao’s
remarks and yours.",696
"There are two interrelated questions: the conditions under which we have
almost sure convergence to the mean and the conditions under which we have the
particular kind of divergence that my argument uses--where almost surely if we
accept the gambles, we lose an infinite amount and gain only a finite amount.  
  
The convergence question concerns necessary and sufficient conditions for the
Strong Law of Large Numbers. Kolmogorov showed that the variance condition is
sufficient (assuming throughout that all the random variables have finite
expectations). But it is not necessary for convergence (indeed Prokhorov
showed that no condition solely on variances can be a necessary and sufficient
condition for convergence). Necessary and sufficient conditions were given by
Nagaev ( https://epubs.siam.org/doi/abs/10.1137/1117072 ), but research on
refinement continues ( https://www.jstor.org/stable/2160636 ). In any case,
the failure to meet the condition Pekoz gives does not imply lack of
convergence.  
  
Further, lack of convergence is not by itself enough to clearly show that it
isn't rational to engage in expected utility maximization. After all, lack of
convergence is compatible with the hypothesis that your total winnings will be
infinite and your total losings will be infinite, in which case it's unclear
if it's rational to play or not.  
  
However, it is much simpler to characterize cases that look like my example if
we assume independence (by the way, my original example does not assume
independence, because the Borel-Cantelli Lemma, unlike its converse which I am
about to use, does not need independence).  
  
I can run my argument with any sequence Y_1,Y_2,... of random variables each
of which has positive expected value, but where the sum P(Y_n > -epsilon) is
finite for some positive epsilon. In that case, expected utility maximization
says to accept each gamble, but if you follow that advice, you will (almost
surely) get a result at least as bad as -epsilon in all but finitely many
cases. If the random variables are independent, then by the converse Borel-
Cantelli Lemma, the condition that the sum of those probabilities is finite is
necessary for the claim that almost surely you will get a result at least as
bad as -epsilon in all but finitely many cases.",2300
"But imagine that it is 99% likely that the bystander will survive the impact,
but 100% certain that the five people further down the track would die.
Perhaps the trolley is accelerating downhill, and currently it only has a 1%
chance of lethality, but by the time it reaches the five people at the bottom
of the hill, it has a 100% chance of lethality. Or perhaps the five people are
more fragile, or the bystander is well-armored. For simplicity, let’s also
suppose that the trolley cannot inflict any major injury other than death. At
this point, it seems plausible that it is permissible to push the bystander in
front of the trolley.",637
"But now let’s suppose the situation is repeated over and over, with new people
at the bottom of the track but the same unfortunate bystander. Eventually the
bystander dies, and the situation stops (maybe that death is what convinces
the railroad company to fix the brakes on their trolleys). We can expect about
500 people to be saved at this point. However, it seems that in the case where
the bystander wasn’t going to survive the impact, it would have been wrong to
push them even to save 500.",496
"Initially, I also thought the following was an appealing solution: It matters
whether it is the same bystander who is pushed in front of the trolley each
time or a different one. Pushing the same bystander repeatedly unjustly
imposes a likely-lethal burden on them, and that is wrong. But it would be
permissible to push a _different_ bystander each time onto the track, even
though it is still almost certain that eventually a bystander will die. The
problem with this solution is this. When the sad situation is repeated with
different bystanders, by adopting the policy of pushing the bystander, we are
basically setting up a lethal lottery for the bystanders—one of them will be
killed. But if we can do that, then it seems we could set up a lethal lottery
a different way: Choose a random bystander out of, say, 500, and then keep on
pushing that bystander. (Remember that the way the story was set up, death is
the only possible injury, so don’t think of that bystander as getting more and
more bruised; they are unscathed until they die.) But that doesn’t seem any
different from just pushing the same bystander without any lottery, because it
is pretty much random which human being will end up being the bystander.",1223
"It is wrong to push the bystander in front of the trolley in the original case
where doing so is fatal. After all, one is not intending the bystander’s
death, but only their absorption of kinetic energy. In [my 2013
paper](https://www.jstor.org/stable/42920164), I argued that this constitutes
wrongful lethal endangerment when the bystander does not consent, even if it
is not an intentional killing. But perhaps that judgment is wrong.",437
"It is wrong to push the bystander to save five, but not wrong to push them to
save five hundred. While this is a special case of threshold deontology, one
can make this move without embracing threshold deontology. One can say that no
matter how many are saved, it is wrong to intentionally kill the innocent
bystander, but lethal endangerment becomes permissible once the number of
people saved is high enough.",410
"Generally people think that if a trolley is heading for a bunch of people,
it’s wrong to push an innocent bystander in front of the trolley to stop it
before it kills the other people, with the innocent bystander dying from the
impact.",235
"While I think this argument is basically correct, it is also puzzling. Why is
it that it is so morally awful to knowingly violate a deontic constraint, but
a small risk of violation can be tolerated? My guess is it has to do with
where deontic constraints come from: they come from the fact that in certain
prohibited actions one is setting one’s will against a basic good, like the
life of the innocent. In cases where violation is very likely, one simply is
setting one’s will against the good. But when it is unlikely, one simply is
not.",540
"I think this leads to a very implausible consequence. Suppose you shouldn’t
violate a deontic constraint to save a million lives. But now imagine you’re
in a situation where you need to _ϕ_ to save ten thousand lives, and suppose
that the non-deontic-consequence badness of _ϕ_ ing is negligible as compared
to ten thousand lives. Further, you think it’s pretty likely that there is no
deontic constraint against _ϕ_ ing, but you’ve heard that a small number of
morally sensitive people think there is. You conclude that there is a 1%
chance that there is a deontic constraint against _ϕ_ ing. If we account for
the fact that you shouldn’t violate a deontic constraint to save a million
lives by setting a disvalue on violation of deontic constraints greater than
the disvalue of a million deaths, then a 1% risk of violating a deontic
constraint is worse than ten thousand deaths, and so you shouldn’t _ϕ_ because
of the 1% risk of violating a deontic constraint. But this is surely the wrong
result. One understands a person of principle refusing to do something that
clearly violates a deontic constraint to save lots of lives. But to refuse to
do something that has a 99% chance of not violating a deontic constraint to
save lots of lives, solely because of that 1% chance of deontic violation, is
very implausible.",1319
"**Objection** The above argument assumes that the disvalue of deaths varies
linearly in the number of deaths and that expected utility maximization is the
way to go.",165
"**Response:** Vary the case. Imagine that there is a ticking bomb that has a
99% chance of being defective and a 1% chance of being functional. If it’s
functional, then when the timer goes off a million people die. And now suppose
that the only way to disarm the bomb is to do something that has a 1% chance
of violating a deontic constraint, with the two chances (functionality of the
bomb and violation of constraint) being independent. It seems plausible that
you should take the 1% risk of violating a deontic constraint to avoid a 1%
chance of a million people dying.",572
"One strategy for accounting for deontology while allowing the tools of
decision theory to be used is to set such a high disvalue on violations of
deontic constraints that we end up having to obey the constraints.",212
"What we ought to conclude, I think, is that exemplar theories are bananas. :-)  
  
On a more serious note, one thing that I think a proponent of exemplar
theories could say in response is that a mere fictional story would not be
sufficiently inspirational. For example, consider the story of the Little
Engine That Could. This might inspire someone to persevere during a difficult
trial in life to some degree. But it likely wouldn't be a life-changing sort
of story. Such a person reading the story might say, ""Yes, that is all well
and good and is somewhat encouraging, but it isn't as if there was actually a
Little Engine that came to belief in itself and accomplished a seemingly
impossible task."" Or, perhaps a better example, consider the first Avengers
movie in which Tony Stark against all odds destroyed the Chitauri mothership,
nearly losing his life in the process. This might be somewhat inspirational,
for instance, to a soldier who finds himself going up against similarly dismal
odds. Nevertheless, it is likely that the soldier will also be somewhat
dismissive of the story as a source of inspiration because, after all, Tony
Stark is a fictional character who has his fictional Iron Man suit, something
that the soldier obviously does not have. What would be far more inspirational
to the soldier is a true story about the D-Day invasion and the bravery of the
soldiers who stormed the beaches of Normandy against dismal odds. If this line
of thought is right, then it seems that the exemplar theorist could insist
that the degree of inspiration necessary for salvation simply could not come
about unless the exemplar is real and not fictional. This would rule out the
monkey example. And, it could be further argued, the exemplar (or the cause
thereof) would have to be divine as only the divine could create a true story
that is sufficiently inspirational for salvation. Thus, we avoid Pelagianism.
How an exemplar theorist would proceed to spell all of this out, I have no
idea. But it is a line of argument they could take. I think a major issue,
however, that the exemplar theorist will inevitably run into is explaining why
it couldn't simply be the case that a fictional story could be sufficiently
inspirational for salvation so long as people *believed* it was true, which is
of course all that the monkey example involves. Perhaps it could be argued
that the story of the Gospel qua story could not have been produced but by
divine intervention and/or inspiration? I think that would be a difficult line
of argument to take, however.",2562
"I definitely agree that taking the story to be true is essential to its
effect. That's why I was imagining that the reader thought the monkey's story
was true.  
Maybe the exemplarist can say that the inspirational effect itself requires a
supernatural grace working in the heart to overcome our weakness, in addition
to the story. But then this grace had better come from the Cross, and the
story about this grace will not be exemplarist.",439
"For imagine that a monkey typing on a typerwriter at random wrote a fictitious
story of a life in morally relevant respects like that of Christ, and people
started believing that story. If Christ saves us by providing an inspiring
example, then we could have gotten the very same effect by reading that
fictitious story typed at random by a monkey and erroneously thinking the
story to be true.",394
"Such theories of salvation have the following unsavory consequence: they imply
that it would be possible for us to be saved by a monkey.",136
"If there are certain conditions that people have to live by in order to he
saved, and some written texts presents exactly those conditions, then I don't
see why people living by those conditions would not be saved.",214
"On “exemplar” theories of salvation, Christ’s work of the cross saves us by
providing a deeply inspiring example of love, sacrifice, or the like.",145
"Of course, that’s just a particularly vivid way of putting the standard
objection against exemplar theories that they are Pelagian. I have nothing
against monkeys except that they are creatures, and so that if it is possible
to be saved by a monkey, then it is possible to be saved by creatures, which
is Pelagianism.",317
"William:  
  
We are assuming determinism and I am saying it's ""in principle"" possible. Of
course, we may have to control nearly every particle's position prior to the
person's birth.",183
"If this is right, then, given determinism and compatibilism, it would be in
principle possible to produce a group of people who would economically
function just like slaves, but who would be fully free. Their higher-order
desires, purposes and values would be chosen through processes that the
compatibilist takes to be free, but these desires, purposes and values would
leave them freely giving all of their waking hours to producing phones for a
mega-corporation in exchange for a bare minimum of sustenance, and with no
possibility of choosing otherwise.",557
"The answer depends on whether we include among the compatibilist conditions on
freedom the condition that the agent’s actions are not intentionally
determined by another agent. If we include that condition, then Alice is not
free. But it is my impression that defenders of compatibilism these days
(e.g., Mele) have been inclining towards not requiring such a non-
determination-by-another-agent condition. So I will take it that there is no
such condition, and Alice is free.",476
"""freely giving all of their waking hours to producing phones for a mega-
corporation in exchange for a bare minimum of sustenance, and with no
possibility of choosing otherwise""  
  
One need not invoke `determinism` or `compatibilism` to assert that having
this happen consistently without lots of exceptions in a large group of
individuals is close to impossible. I doubt you could ever get this to work
reliably with a group of draft horses in all cases, starting with newborns and
following the group through training. At best you could select a few in a
large peer group that could remain performing to that specification for many
years.  
  
Biology makes things too unpredictable for such a production, free will or no.",726
"Alex  
  
Compatibilism is the position that persons do something because they are who
they are.  
It's more complex, of course, but that's what it comes down to.  
I ""choose"" to write this post because I am a person who likes to discuss these
things. My wife doesn't post here, because she is not interested in discussing
this.  
Now, imaging libetarian free will were true. Then, all of a sudden, I could
""choose"" to become a murderer or a rapist.  
I prefer to think that I am the kind of person who will never choose to rape
or murder.  
Yes, it would, in principle, be possible to produce a group of people who
would economically function just like slaves, but who would be fully free (in
the compatibilist sense). Those people would ""choose"" slavery because they
like being slaves. It's their decision based on who they are.  
You choose based on who you are, but you cannot choose who you are. That's
compatibilism, and you may not like it, but a libertarian is no better off.
Because if we have LFW, we ""choose"" on some other mysterious basis that we
have no more control over than over who we are.  ",1108
"Suppose determinism and compatibilism are true. Imagine that a clever alien
crafted a human embryo and the conditions on earth so as to produce a human,
Alice, who would end up living in ways that served the alien’s purposes, but
whose decisions to serve the alien had the right kind of connection with
higher-order desires, reasons, decision-making faculties, etc. so that a
compatibilist would count them as right. Would Alice decisions be free?",447
"If you have to control the position of every molecule, you are not really
using behavioral controls where reasons and motives matter. You have
determined the body's movements directly, without any need for motives.  
  
If you have decided to only determine the motives and tendencies, the biology
will still vary too much to allow the consistency the scenario requires as
outcome.",381
"The second approach is interesting. Most ethical systems start with a default
of permission, and then have prohibitions on top of that. But the second
system starts with a default of prohibitions, and then has permissions on top
of that.",237
"On the first approach, there are complex prohibitions against non-consensual
treatment in a number of areas of life, with details varying depending on the
area of life (e.g., the prohibitions are even more severe in sexual ethics
than in medicine). Thus, this is a picture where we start with a default
permission, and layer prohibitions on top of it.",351
"I don't think that we have autonomy rights against God.  
  
(I think there is more wrong in rape than ""just"" violation of autonomy: There
is violation of autonomy in an especially sacred kind of context.)",205
"The second approach raises this question. Given that the default prohibition
on other-affecting actions is grounded in autonomy, how could anything but the
other’s consent override that prohibition? I think one direction this question
points is towards something I’ve never heard explored: divine permission
ethics. God’s permission seems our best candidate for what could override an
autonomy-based prohibition. So we might get this picture of ethics. There is a
default prohibition on all other-affecting actions, followed by two
exceptions: when the affected person consents and when God permits.",599
"On the second, we start with a default autonomy-based prohibition on one
person doing anything that affects another. That, of course, ends up
prohibiting pretty much everything. But then we layer exceptions on that. The
first is a blanket exception for when the affected person consents in the
fullest way. And then we add lots and lots more exceptions, such as when the
the effect is insignificant, when one has a special right to the action, etc.",448
"Alex  
  
 _""Given that the default prohibition on other-affecting actions is grounded
in autonomy, how could anything but the other’s consent override that
prohibition?""_  
  
The answer is simple: nothing can override that prohibition, not even a
hypothetical god. Because if god could do it, that would mean this prohibition
is _not_ grounded in autonomy.  
  
Take, e.g. rape. Rape is, by definition, prohibited based on the autonomy of
the victim. It's impossible to consent to being raped and god giving someone
permission to rape me, would not remove my autonomy.",570
"Alex  
  
If we do not have autonome rights against God we don not really have autonome
rights at all.  
And whether they context is sacred it not is irrelevant. What is relevant is
consent. Consesual sex is not rape even though sex itself may be a sacred
context.",264
"How much is Alice left with, and what is the minimum she thinks she would have
borrowed? If she reasonably estimates that the minimum she borrowed is more
than she has left, all goes to Bob, no wrongs done. If she is still worried,
have Bob first promise that if the true amount is later revealed and she gave
him more than owed he will supply the excess to Carl.  
  
If there is money left after that minimum, and Alice worries that her choosing
a number is somehow ethically wrong (anyway, why?), let Bob and Carl negotiate
to decide on the number. That way Alice is not picking a wrong number.  
  
  ",605
"And now we have a puzzle. Whatever amount between Alice gives to Bob, she can
be extremely confident is either less or more than she borrowed, and in either
case she does wrong. Thus whatever Alice does, she is confident she is doing
wrong.",240
"What should Alice do? I think it’s intuitive that she should do something like
minimize the expected amount of wrong.",117
"But because of her promise to Carl, and because any amount above the owed debt
is not a necessity:",98
"Suppose Alice borrowed some money from Bob and promised to give it back in ten
years, and this month it is time to give it back. Alice’s friend Carl is in
dire financial need, however, and Alice promised Carl that at the end of the
month, she will give him any of her income this month that she hasn’t spent on
necessities. Paying a debt is, of course, a necessity.",365
It is wrong for Alice to give more to Bob than she borrowed.,60
It is wrong for Alice to give less to Bob than she borrowed.,60
"Now, suppose neither Alice nor Bob remember how much Alice borrowed. They just
remember that it was some amount of money between $300 and $500. Now,
obviously in light of her promise to Bob:",190
"None of this is meant to impugn _C_. I certainly think _C_ is true. But I
think the reasons for believing _C_ are metaphysical or philosophical rather
than inductive observation.",178
"For observations (a) and (b) to support _C_ , these observations have to be
more likely on _C_ than on _C_ ’s negation. But now we have two problems.
First, on the negation of _C_ it doesn’t seem like we can make any sense of
the probability that some item has or does not have a cause. Causeless events
have no probabilities. Second, even if somehow assign such a probability, it
is far from clear that the observations of (a) and (b) are more to be expected
on _C_ than on not _C_.",483
"Fr Kirby:  
  
That's very interesting. Maybe then the way to respond to my point about
insects is this: when we've had ""sufficient opportunity"" to observe an insect
to such a degree that *if* it had parents then we would have been able to
identify them, then invariably we have identified the parents. And similar
conditionals are true for other things.",354
"Another thought: I suspect that the inference to the existence of a cause is
on an epistemic par with an inference to the consistency of some event with
the laws of nature.  
  
For any of the unfathomably large number of episodes of motion I observe, how
on Earth do I know that they're actually consistent with the laws? Think of
the water falling from my shower head, the ambulance of an old man through a
doorway, or the slide of a coffee cup from the counter to my hand. Do I really
know that those motions were consistent with the laws instead of one of an
infinity of possible ways that could technically violate those laws? I don't
know the details of the motion, and I don't even know how to check if those
details - even if I knew them - were consistent with the laws. But I infer
that they are. This seems totally legitimate on whatever epistemic grounds
exist for the scientists who conclude what the laws are.  
  
Now, (a) and (b) become (a*) We know of many events that conform to the laws
and (b*) there are many events for which we have no idea if they conform to
the laws. All the same arguments seemingly can be run (with the exception of
the no probability argument) against the view that our nomic beliefs are
correct.  
  
It seems that the denial of our causal inferences are no worse off than our
nomic inferences.",1338
"There are a couple of issues with such an inference. First, let’s think about
the inductive evidence about causes globally. It seems to consist primarily in
these two observations:",180
"Alex  
  
Nothing can come into existence because ex nihilo nihil fit.  
But even if this were possible, in order to inductively infer that something
coming into existence must have a cause, one must actually observe something
coming into existence as well as its cause.  
It is not enough that we obeserve causes for every single insect and every
other animal or plant, because all we have observed in that case is
transitions from one type of being to another, not the coming into existence
of a brand new being.  
  ",519
"Your penultimate paragraph suggests a new argument:  
  
(1) We are justified in inferring the existence of a parental cause for any
insects known to exist  
(2) If (1) is true, then C is true  
(3) Therefore, C is true.  ",222
"I’m curious whether one can infer the causal principle _C_ that everything
that comes into existence has a cause inductively on the basis of our
observations of things with causes.",180
"It seems to me that while (a) and (b) are indeed insufficient to inductively
ground C, in accordance with Dr Pruss' arguments, another observation I will
call (c) tips the balance. Here it is:  
  
We consistently find causes for individual things that come to be when we have
sufficient opportunity to investigate their origins. In other words, the set
of (a)-type things consistently grows at the expense of the other set as
knowledge of the things increases.",461
"This could help furnish a response to Felipe Leon's pre-existing material
cause argument against creatio ex nihilo, which argues that we have the same
basis for believing all causation must involve a pre-existing material base as
we do for assuming that everything that comes into existence has a cause.  
  
On the other hand, in some of your writings you do appeal to inductive
arguments, namely that we would expect things to constantly pop into existence
without a cause if the causal principle were false, and so the orderliness of
nature is evidence against the possibility of things coming into existence.
Your point that we seem to reason from the causal principle to individual
cases of cause and effect is intriguing, and could maybe help justify both our
practices of causal reasoning and our obvious belief that things won't
suddenly start popping into existence uncaused.",884
"Yes, though I admit it might be difficult to define ""sufficient opportunity""
in practice without smuggling in implicit assumptions that risk reducing the
inductive argument to circularity. In other words, if what allows us to judge
the sufficiency of opportunity to find a cause is related to how ever much
effort it takes to successfully find such a cause, my (c) becomes ""We
consistently find causes for things that come to be when we have investigated
their origins up to the point when we find causes for them"", which is
tautological.  
  
The trick would be to define ""sufficient opportunity"" rigorously without
unintentionally sneaking in the epistemic assumptions we are trying to ground.
And, even if we succeed in doing so, I suspect that in the real world, both
the common folk and academics, especially in science, are accepting C in
practice at least, and without such a strictly valid and non-circular
grounding. To put it another way, I believe there is at least as much
faith/intuition as reason (in the narrow sense) subjectively underlying both C
and the confidence in nomic inferences to which ASBB refers.",1124
"It is worth noting that in terms of individuals, (b) vastly outnumbers (a).
Consider insects. Of the myriad insects that we come into contact daily, we
have found the causes of very few. Of course, we _assume_ that the others have
causes, causes that we suppose to be parent insects, but we haven’t _found_
the parents.",319
"there are many things that come into existence for which we have yet to find
causes.",84
"Second, I suspect that often when we claim to have found _y_ to be the cause
of _x_ , our reason for belief that _y_ is the cause of _x_ depends on our
assumption of _C_. Our best candidate for a cause of _x_ is _y_ , so we take
_y_ to be the cause. But I wonder how often this inference isn’t based on our
dismissing the possibility that _x_ just has no cause.",361
"Tom:  
  
I am OK with arguments from our expectations. Those are not inductive
arguments based on our observations of things having causes, but are _a
priori_.  
  
Regarding things popping into existence, I have come to feel the force of the
thought that no probabilities can reasonable be attached to such causeless
popping. But sometimes I argue concessively, granting that some probabilities
can be attached.",413
"So, either we trivialize PCT by insisting on the facts of our physical
universe that put a finite limit on our computations, or in our notion of
“physically computed” we allow for idealizations that make it possible to go
on forever. If we do allow for such idealizations, then my argument works:
generalized Molinism makes PCT unlikely to be true.",348
"Can there be determinism in some things and indeterminism in others?  
  
  ",76
"Fair enough. But if we say this, then the PCT becomes trivial. For given
finite life-spans of human beings and of any machinery in an expanding
universe with increasing entropy, only finitely many values of any given
function can be physically computed. And any function defined on a finite set
can, of course, be trivially computed by a Turing machine via a lookup-table.",372
"The physical Church-Turing (PCT) thesis says that anything that can be
physically computed can be computed by a Turing machine.",127
"If generalized Molinism—the thesis that for any sufficiently precisely
described counterfactual situation, there is a fact of the matter what would
happen in that situation—is true, and indeterminism is true, then PCT seems
very likely false. For imagine the function _f_ from the natural numbers to
{0, 1} such that _f_ ( _n_ ) is 1 if and only if the coin toss on day _n_
would be heads, were I to live forever and daily toss a fair coin—with
whatever other details need to be put in to get the ""sufficiently precisely
described"". But only countably many functions are Turing computable, so with
probability one, an infinite sequence of coin tosses would define a Turing
non-computable function. But _f_ is physically computable: I could just do the
experiment.",763
"Perhaps ""sufficiently precisely described"" includes the value of n. Then the
function is no longer infinite, since we stop at the time for n.",141
"But wait: I’m going to die, and even if there is an afterlife, it doesn’t seem
right to characterize whatever happens in the afterlife as _physical_
computation. So all I can compute is _f_ ( _n_ ) for _n_ < 30000 or so.",220
"If “ _ϕ_ ” is “moral obligation”, and we maintain moral realism, then (1) is
out. I think (3) and (4) are only possible options if we have a watered-down
moral realism. For on a robust moral realism, moral obligations really central
to our lives, and nothing else could play the kind of central role in our
lives that they do. On a robust moral realism, moral obligation is not one
thing among many that just as well or almost as well fit our linguistic usage.
Here is another way to put the point. On both (3) and (4), the question of
what exact content “ _ϕ_ ” has is a merely verbal question, like the question
of how much hair someone can have and still be bald: we could decide to use
“bald” differently, with no loss. But questions about moral obligation are not
merely verbal in this way.",795
"It sure seems like there is vagueness in moral obligation. For instance,
torture of the innocent is always wrong, making an innocent person’s life
mildly unpleasant for a good cause is not always wrong, and in between we can
run a Sorites sequence.",248
"So we need something else. If we deny (1)-(3), we have to say that ultimately
“moral obligation” is sharp, but of course we can’t help but admit that there
are Sorites sequences and we can’t tell where moral obligation begins and ends
in them. But we cannot explain our ignorance in the semantic way of standard
epistemicism. What we need is something like epistemicism, but where moral
obligation facts are uniquely distinguished from other facts—they have this
central overriding role in our lives—and yet there are moral facts that are
likely beyond human ken. One might want to call this fifth view “non-standard
epistemicism about vagueness” or “denial of vagueness”—whether we call it one
or the other may just be a verbal question. :-)",742
"Supervaluationism: there are a lot of decent candidates for the meaning of “
_ϕ_ ”, and no one of them is _the_ meaning.",120
"What view could a moral realist have about this? Here are four standard things
that people say about a vague term “ _ϕ_ ”.",122
Error theory: nothing is or could be _ϕ_ ; or maybe “ _ϕ_ ” is nonsense.,72
"Standard epistemicism: there are a lot of decent candidates for the meaning of
“$”, and one of them is _the_ meaning, but we don’t know which one, because we
don’t know the true semantic theory and the details of our linguistic usage.",234
"This means that given robust moral realism, of the standard views of vagueness
all we have available is non-classical logic. But non-classical logic is just
illogical (thumps table, hard)! :-)",192
"Non-classical logic: there are cases where attributions of “ _ϕ_ ” are neither
true nor false.",94
"In any case, I find it quite interesting that to save robust moral realism, we
need either non-classical logic or something that we might call “denial of
vagueness”.",165
"I suspect the looser structure is what we have in Aquinas’s Natural Law. At
the highest level we have the general law that the good is to be pursued and
the bad to be avoided. This is then specified into three laws about promoting
the goods of existence, species-specific life and reason. These three laws, I
think, are then further specified.",343
"That answer makes sense, but it requires committing yourself to saying that
there are non-normative facts. But see here about Aristotelianism and non-
normative facts: https://alexanderpruss.blogspot.com/2021/04/an-exercise-in-
vacuity.html",240
"Agreed. In mathematics and you hope physics we have deductive structure. But
as we move through chemistry to biology the ""laws"" become less and less tied
to underlying principles. You will not derive mammalian behavior from rules at
the level of cellular metabolism such as RNA transcription, for example.
Social sciences are even less tied to simpler structures. I suppose ethical
rules are in that category.  
  
Should we have expected ""Natural Law"" to be different from the rules in other
social sciences, such as jurisprudence, or is that a false expectation caused
by the use of the words ""natural"" and ""law"" because of their very different
meaning in the context of mathematics or physics?  ",698
"For physics, is ‘contingencies of arrangements of stuff’ enough? I would think
we would also need ‘contingencies of _kinds_ of stuff’. So if there were a
particle just like an electron but with a charge sqrt(2) times as big, the
laws of physics might still be the same but the behavior of matter would be
very different. If so, I’m not sure the moral laws are all that different. You
might not be able to derive all the moral laws pertaining to human animals
straight from the categorical imperative alone (or whatever other law you take
to be fundamental), but you can (can’t you?) derive it from a combination of
the categorical imperative and a sufficiently detailed understanding of the
nature of the human species. What would be the problem with saying that?",763
"There is thus a structure to the moral law, but it is not a deductive
structure. The higher level laws make the lower level laws _fitting_ , but do
not necessitate them.",169
"Pruss, for your response to Matthew -- is the idea that all facts are
normative but not all normative facts give us practical reason to pursue or
promote them?  ",161
"TreyTable:  
  
But what makes a particular form of love fitting to a particular lover and
beloved's nature may not be encompassed by a simple set of rules.  
  
Matthew:  
  
I think one would need not just the descriptive facts about the human species,
but the normative ones. And these would include normative facts about the
will, and those will include the moral facts.",374
"In One Body: An Essay in Christian Sexual Ethics, I recall you arguing for a
'strong ethics of love' such that all moral facts in some sense follow from
the fundamental duty to love (or even that they are this duty taking other
forms). It's been a while since I read that chapter, but that seems like a
tighter unificatory structure than you're posing here, so have your views
changed since then or is a strong ethics of love compatible with this looser
structure?",464
"Daryl:  
  
I was just thinking that Matthew's ""sufficiently detailed understanding of the
nature of the human species"" would require not just a descriptive but also a
normative understanding. For instance, it's important that not only do humans
tend to have hearts and lungs, but that they ought to have them.",310
"In ethics, a similar ideal has often manifested itself. While I have a hope
for the ideal being realized in physics, I have come to be more pessimistic
about the ideal in ethics. Instead, I think we can have a looser unificatory
structure. We can have a multilevel hierarchy of more general laws, and then
more specific laws that specify or implement the more general laws.",373
"In physics, we hope for the following unification: there is a small set of
simple laws, and all the rest of physics derives logically from these laws and
the contingencies of the arrangement of stuff.",200
"On any finite space _Ω_ with at least two points, no scoring rule satisfies
strict propriety for the credences with Normalization and Subadditivity and
level set integral prevision.",181
"And, finally, here is a written-up version of the proof: http://philsci-
archive.pitt.edu/21264/  
See Theorem 3 and Corollary 1 in the Appendix.",145
"If any non-probabilities are rationally admissible, then all non-probabilities
satisfying Normalization (whole space has credence 1) and Subadditivity ( _P_
( _A_ ) + _P_ ( _B_ ) ≤ _P_ ( _A_ ∪ _B_ ) when _A_ and _B_ are disjoint) are
rationally admissible with the appropriate prevision being given by a [level
set integral](http://alexanderpruss.blogspot.com/2019/11/expected-utility-and-
inconsistent.html) [correction: actually, I need
[LSI&uparrow](http://alexanderpruss.com/papers/InconsistentCredences.pdf), not
the version of LSI in the earlier blog post].",563
"A rationally appropriate scoring rule _s_ satisfies strict propriety for all
rationally admissible credences with an appropriate prevision: if _V_ is an
appropriate prevision then _V_ _u_ _s_ ( _u_ ) is better than _V_ _u_ _s_ (
_v_ ) whenever _u_ and _v_ are different rationally admissible credences.",302
"Correction: While I linked to a post describing the +- version of the level
set integral, the ""cute theorem"" I have proved is actually for the up-arrow
version of LSI given here:
http://alexanderpruss.com/papers/InconsistentCredences.pdf  
The up-arrow version is superior for decision-theoretic purposes, because it
commutes with positive affine transformations.  
  
The proof, of course, depends on the fact that ""strict propriety for the
credences with Normalization and Subadditivity"" is a much stronger condition
than the classic notion of strict propriety for probabilities. I'll post it
when I finish cleaning up the paper in which it sits.",648
"A number of comments from a commenter who has been banned have been deleted.
If a banned commenter wishes to be reinstalled, they should email me
explaining their plan for avoiding the sorts of things that led to the ban.",221
"Here’s an accuracy-theoretic argument for probabilism (the thesis that only
probabilities are rationally admissible credences) on finite spaces that does
not make any continuity assumptions on the scoring rule. I will assume all
credence functions take values on [0,1].",269
"I think the non-probabilist’s best way out is to deny strict propriety or to
deny that there is a rationally appropriate scoring rule. Both of these ways
out work just as well against more standard arguments for probabilism, and I
think both are good ways out.",260
"Technically speaking, the advantage of this argument over standard arguments
for probabilism is that it makes no assumptions of continuity.",139
"Is this a good argument? I find (2) somewhat plausible—it’s hard to think of a
less problematic weakening of the axioms of probability than from Additivity
to Subadditivity, and I have not been able to find a better prevision than the
level set integral one. Standard arguments for probabilism assume strict
propriety for all probabilities. But it seems to me that a non-probabilist
will find strict propriety for all probabilities plausible only insofar as
they find strict propriety for all admissible credences plausible. Thus (3) is
dialectically as good as the usual strict propriety assumption.",600
"I used to take it for granted that it’s reasonable to make epistemic utilities
be continuous functions of credences. But this is not so clear to me right
now. Consider a proposition really central to a person’s worldview, such as:",230
"I think a case can be made that if a proposition like that is in fact true,
then there is a discontinuous upward jump in epistemic utility as one goes
from assigning a credence less than 1/2 to assigning a credence more than 1/2.",229
"Hello, Dr. Pruss. It seems like you used a lot of ideas in your blog for this
lecture!  
I have a few questions. First, how is your book going? I saw you haven't
updated it in a while. Have you seen Joe Schmid's new book that is coming out?
It's about classical theism and existential inertia. I know you have a paper
about divine conservation coming up, so I would like to hear some arguments
against existential inertia. Moreover, there is a book with an essay by you in
it: Classical Theism by Routledge. In it, you argue for divine simplicity. Can
you tell me about some arguments in it?  
https://www.amazon.com/Existential-Inertia-Classical-Theistic-
Proofs/dp/3031193121/",678
"Alexander Pruss, “Three mysteries of the concrete: Causation, mind and
normativity”, Christian Philosophy 2022, online, Cracow, Poland, September,
2022.",152
"I think what we need is some careful way of computing proportionality in
Double Effect. Here is a thought. Start by saying in _both_ versions of the
case that the deaths of the four patients are _not_ the effects of the trolley
redirection. This was very intuitive, but seemed to cause a problem in the
delayed-surgeons version. However, there is a fairly natural way to reconstrue
things. Take it that leaving the trolley to go along the left track results in
the _good_ of saving the four patients. So far we’ve only shifted whether we
count the deaths of the four as an evil on the redirection side of the ledger
or the saving of the four as a good on the non-redirection side. This makes no
difference to the comparison. But now add one more move: don’t count goods
that result from evils in the ledger at all. This second move doesn’t affect
the delayed-surgeons case. For the good of saving lives in that case is not a
result of Alice’s death, and the proportionality calculation is unaffected. In
particular, in that case we still get the correct result that you should not
redirect the trolley, since the events relevant to proportionality are the
evil of Alice’s death and the good of saving four lives, and so preventing
Alice’s death is disproportionate. But in the organ case, the good of saving
lives _is_ a result of Alice’s death. So in that case, Double Effect’s
proportionality calculation does not include the lives saved, and hence, quite
correctly, we conclude that you _should_ redirect to save Alice’s life.",1529
"Among the results of redirecting the trolley, now, are the deaths of the four
who won’t be saved, and hence Double Effect does apply. To save one person at
the expense of four is disproportionate, and so it seems that one violates
Double Effect in saving the one. And in this case, a failure to save Alice
would not involve any complicity in anyone else’s evildoing.",366
"In my [previous
post](https://alexanderpruss.blogspot.com/2022/09/proportionality-in-double-
effect-and.html), I discuss cases where someone is doing an evil for the sake
of preventing significantly worse goods—say, murdering a patient to save four
others with the organs from the one—and note that a straightforward reading of
the Principle of Double Effect’s proportionality condition seems to forbid one
from stopping that evil. I offer the suggestion, due to a graduate student,
that failure to stop the evil in such cases implies complicity with the evils.",561
"I now think that complicity doesn’t solve the problem, because we can imagine
case where there is no relevant evildoer. Take a trolley problem where the
trolley is coming to a fork and about to turn onto the left track and kill
Alice. There is no one on the right track. So far this is straightforward and
doesn’t involve Double Effect at all—you should obviously redirect the
trolley. But now add that if Alice dies, four people will be saved with her
organs, and if Alice lives, they will die.",495
"And if the deaths count in this case, they should count in the original case
where Alice’s organs are needed. After all, in both cases the patients die of
their medical condition because the trolley redirection has prevented the only
possible way of saving them.",262
"Here’s another tempting response. In the original version of the story, if one
refrains from redirecting the trolley in light of the people needing Alice’s
organs, one is intending that Alice die as a means to saving the four, and
hence one is violating Double Effect. But this response would not save Double
Effect: it would make Double Effect be in conflict with itself. For if my
earlier argument that Double Effect prohibits redirecting the trolley stands,
and this response does nothing to counter it, then Double Effect both
prohibits redirecting and prohibits refraining from redirecting!",595
"It is tempting to say that the deaths of the four are due to their medical
condition and not the result of trolley redirection, and hence do not count
for Double Effect proportionality purposes. But now imagine that the four
people can be saved with synthetic organs, though only if the surgery happens
very quickly. However, the only four surgeons in the region are all on an
automated trolley, which is heading towards the hospital along the left track,
is expected to kill Alice along the way, but will continue on until it stops
at the hospital. If the trolley is redirected on the right path, it will go
far away and not reach the hospital in time.",653
"In _this_ case, it does seem correct to say that Double Effect forbids one
from redirecting the trolley—you should not stop the surgeons’ trolley even if
a person is expected to die from a trolley accident along the way. (Perhaps
you are unconvinced if the number of patients needing to be saved is only
four. If so, increase the number.) But for Double Effect to have this
consequence, the deaths of the of the patients in the hospital have to count
as effects of your trolley redirection.",490
"Maybe. But I am not sure. Maybe my initial intuition is wrong, and one should
not redirect the trolley in the organ case. What pulls me the other way is the
hungry bear case [here](http://alexanderpruss.blogspot.com/2020/11/reducing-
triple-effect-to-double-effect.html).",271
"Another option is to defend Alice with a lethal blow to Bob's head. Which then
allows you to save the other lives too.",118
"entirelyuseless:  
  
Yeah, but if you use lethal force to stop Bob when non-lethal force would do
the job, now it looks like you're murdering Bob.",147
"Suppose you are visiting a hospital and you see Bob, a nurse, sneaking into
Alice’s hospital room. Unnoticed, you look at what is going on, and you see
that Bob is about to add a lethal drug to Alice’s IV, a drug that would
undetectably kill Alice while leaving her organs intact. You recall with
horror that two days ago you had a conversation with Bob and he described to
you how compelling he finds the argument that it is sometimes obligatory to
kill one patient in order to provide organs to save multiple other patients,
when this can be done secretly. At the time, you unsuccessfully tried to
persuade Bob that the consequentialism behind the argument was implausible.
You happen to know that if Bob were to die right now, then four people could
be saved. You could now yell, push Bob away, and prevent Alice’s murder.",825
"Here is a Double Effect argument that you shouldn’t stop the murder. Your
action of pushing Bob away has two sets of effects: (a) Alice isn’t murdered
and (b) four patients who would be saved by Alice’s organs die. Of these, (a)
is an intended good and (b) is an unintended evil. So your action is an action
to which Double Effect is relevant: it is an action with two effects, an
intended good and an unintended evil. But Double Effect makes it a necessary
condition for the permissibility of an action that the evils not be
disproportionate to the goods. And here the evils _are_ disproportionate to
the goods. So you shouldn’t stop Bob, it seems.",649
"**Objection:** When it’s a matter of stopping Bob’s murder of Alice, you don’t
_cause_ the deaths of the patients who need Alice’s organs to live. The
patients die of whatever conditions they die of, rather than from your action.  
So those deaths don’t figure in the Double Effect proportionality calculus.",307
"What’s going on? Is it the case that when we consider the good of persuading
someone to act well, we should not count against that any goods that would
result from their acting badly? Is it—a graduate student suggested this to
me—that if I fail to persuade them to act well _in order_ to obtain the goods
that would result from their act badly, then I become _complicit_ in their bad
action? I think there is something to this idea. It may even apply in my
earlier case of not stopping Bob physically from the murder, but it seems
particularly plausible in the case of refraining to persuade.",592
"**Response:** Imagine that I could stop an ordinary murder, but to do that I
would have to park my car in a place that would block an ambulance from
getting to the scene of an unrelated accident, where a number of people would
die of their injuries if the ambulance were not to get there in time. When
considering my action of parking my car, I _do_ need to consider the deaths of
the people the ambulance would save, even though they die from their injuries
rather than from my action. If the number of people the ambulance would save
is large enough, I ought not block the ambulance’s path to prevent one murder.",614
"Now, one might question the proportionality judgment. Maybe while four deaths
are disproportional to one death, four _deaths_ are not disproportionate to
one _murder_? This is mistaken, however. For suppose you see an assassin
trying to murder someone with a long-range shot, and you see four innocent
people near the assassin. The only way you have to stop the assassin is with a
hand-grenade, which would kill the four innocents as well. It is clear that
four _deaths_ of innocents are disproportionate to the one murder: you should
not stop the murder by blowing up the assassin.",582
"Suppose you bite the bullet and agree that you shouldn’t stop Bob. Then I have
an even more problematic version. Go back to your disquieting conversation
with Bob about killing patients for their organs. Suppose that Bob disclosed
to you in the course of that conversation that it wasn’t a merely hypothetical
question, as you assumed, but that he was actually planning on acting on it.
It seems completely clear that you should try to persuade him out of this
murderous plan. But the exact same Double Effect argument seems to apply here:
There are two sets of effects of your persuading Bob not to do it—one person
isn’t murdered and a number of people die. The bad effects are
disproportionate to the good ones, so Double Effect seems to prohibit you from
persuading Bob out of his plan.",790
"Alex,  
  
If you do push Bob away merely to save Alice, all deaths are side-effects but
if you don't, formal cooperation lurks if you are refraining to benefit
transplant recipients. Maybe I'm missing something but this looks as if you
share Bob's plan - both his end (lives saved with Alice's organs) and his
means (Alice killed by Bob).  
  
In contrast, take another case: Police Officer Olly who omits to intervene to
stop a riot in a suburb, because doing so will merely drive the rioters into
the inner city area. Intervening would be futile overall in that it would
merely result in more rioting and homicides.  
  
Olly is not like another police officer, George, who intends that deaths occur
in the suburbs - say, as a warning to the inner city. Olly omits to protect
the suburb not to enable suburb homicides but simply because intervening would
do more harm than good. True, Olly plans to benefit the inner city by his non-
intervention, at least in the sense that he eschews what does them harm, but
he is not 'using' the suburb like Bob is using Alice or you seem to be using
Alice if you let Bob go ahead precisely so organ recipients can live.  
  
To make the transplant case more like Olly - imagine your non-intervention is
simply motivated by an intention that Bob not run amok in the children's ward.
Again, intervening is futile overall - Bob has powerful friends who work in
the children's ward and though you would save Alice, several children would be
killed for their organs.  
  
Here you share none of Bob's wrongful plans to achieve what you nonetheless
welcome in failing to intervene: the saving of lives with Alice's organs. You
are intending to save children, not intending to enable Bob to save adults by
killing Alice.  ",1756
"In any case, if I am right that it is right to persuade Bob out of his plan to
murder Alice, we really do need to understand the proportionality condition in
Double Effect very carefully. That condition seems to become significantly
context-sensitive. Double Effect is not a simple structural principle by any
means.",316
"Maybe though this second case is different from the first, in that it is one
of the basic tasks of a fellow human being to persuade others to act well—this
is a central part of our human communal interaction. So it may be that once we
take into account the good of persuading others to act well, and add that good
to the intended goods, now the four deaths are no longer disproportionate. But
now increase the numbers. Perhaps Alice has some weird mutation in her heart
tissue such that culturing her heart tissue would save a thousand lives. Now
the death of a thousand seems clearly disproportionate to preventing one
murder _and_ obtaining the goods of persuading others to act well. Imagine
that I had a choice between preventing an explosion that would completely
destroy a ship with a thousand people on board and persuading someone not to
commit an “ordinary” murder. I should prevent the sinking of the ship. Yet
even in the thousand patient case I have the intuition—admittedly, now
weaker—that I should try to persuade Bob not to murder Alice, or at least that
it is permissible to do so. Especially if Bob is my friend.",1130
"Helen:  
  
In the Bob and Alice case, it seems that if you don't stop Bob, you need not
have any plan besides ""Don't violate Double Effect!"" It seems you are
refraining from stopping Bob precisely because stopping Bob would violate
proportionality in Double Effect.",266
