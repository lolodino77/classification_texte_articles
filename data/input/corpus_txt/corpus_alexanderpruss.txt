What about the other direction? Can we reduce goods to reasons?

The simplest story would be that goods reduce to reasons to promote them.

But there seem to be goods that give no one a reason to promote them. Consider
the good fact that there exist (in the eternalist sense: existed, exist now,
will exist, or exist timelessly) agents. No agent can promote the fact that
there exist agents: that good fact is part of the agent’s thrownness, to put
it in Heideggerese.

Maybe, though, this isn’t quite right. If Alice is an agent, then Alice’s
existence is a good, but the fact that some agent or other exists isn’t a good
as such. I’m not sure. It seems like a world with agents is better for the
existence of agency, and not just better for the particular agents it has.
Adding _another_ agent to the world seems a lesser value contribution than
just ensuring that there is agency at all. But I could be wrong about that.

Another family of goods, though, are necessary goods. That God exists is good,
but it is necessarily true. That various mathematical theorems are beautiful
is necessarily true. Yet no one has reason to promote a necessary truth.

But perhaps we could have a subtler story on which goods reduce not just to
reasons to promote them, but to reasons to “stand for them” (taken as the
opposite of “standing against them”), where promotion is one way of “standing
for” a good, but there are others, such as celebration. It does not make sense
to promote the existence of God, the existence of agents, or the Pythagorean
theorem, but celebrating these goods makes sense.

However, while it might be the case that something is good just in case an
agent should “stand for it”, it does not seem right to think that it is good
_to the extent that_ an agent should “stand for it”. For the degree to which
an agent should stand for a good is determined not just by the magnitude of
the good, but the agent’s relationship to the good. I should celebrate my
children’s accomplishments more than strangers’.

Perhaps, though, we can modify the story in terms of goods-for- _x_ , and say
that _G_ is good-for- _x_ to the extent that _x_ should stand for _G_. But
that doesn’t seem right, either. I should stand for justice for all, and not
merely to the degree that justice-for-all is good-for-me. Moreover, there
goods that are good for non-agents, while a non-agent does not have a reason
to do anything.

I love reductions. But alas it looks to me like reasons and goods are not
reducible in either direction.

In 2018, the Belgians beat the Brazilians 2-1 in the 2018 World Cup soccer
quarterfinals. There are about 18 times as many Brazilians and Belgians in the
world. This raises a number of puzzles in value theory, if for simplicity we
ignore everyone but Belgians and Brazilians in the world.

An order of magnitude more people _wanted_ the Brazilians to win, and getting
what one wants is good. An order of magnitude more people would have felt
significant and appropriate _pleasure_ had the Brazilians won, and an
appropriate pleasure is good. And given both wishful thinking as well as
reasonable general presumptions about there being more talent available in a
larger population base, we can suppose that a lot more people _expected_ the
Brazilians to win, and it’s good if what one thinks is the case is in fact the
case.

You might think that the good of the many outweighs the good of the few, and
Belgians are few. But, clearly, the above facts gave very little moral reason
to the Belgian players to lose. One might respond that the above facts gave
lots of reason to the Belgians to lose, but these reasons were outweighed by
the great value of victory to the Belgian players, or perhaps the significant
intrinsic value of playing a sport as well as one can. Maybe, but if so then
just multiply both countries’ populations by a factor of ten or a hundred, in
which case the difference between the goods (desire satisfaction, pleasure and
truth of belief) is equally multiplied, but still makes little or no moral
difference to what the Belgian players should do.

Or consider this from the point of view of the Brazilian players. Imagine you
are one of them. Should the good of Brazil—around two hundred million people
caring about the game—be a crushing weight on your shoulders, imbuing
everything you do in practice and in the game with a great significance? No!
It’s still “just a game”, even if the value of the good is spread through two
hundred million people. It would be weird to think that it is a minor
pecadillo for a Belgian to slack off in practice but a grave sin for a
Brazilian to do so, because the Brazilian’s slacking hurts an order of
magnitude more people.

That said, I do think that the larger population of Brazil imbues the
Brazilians’ games and practices with _some_ not insignificant additional moral
weight than the Belgians’. It would be odd if the pleasure, desire
satisfaction and expectations of so many counted for _nothing_. But on the
other hand, it should make no significant difference to the Belgians whether
they are playing Greece or Brazil: the Belgians shouldn’t practice less
against the Greeks on the grounds that an order of magnitude fewer people will
be saddened when the Greeks lose than when Brazilians do.

However, these considerations seem to me to depend to some degree on which
decisions one is making. If Daniel is on the soccer team and deciding how hard
to work, it makes little difference whether he is on the Belgian or Brazilian
team. But suppose instead that Daniel is has two talents: he could become an
excellent nurse or a top soccer player. As a nurse, he would help relieve the
suffering of a number of patients. As a soccer player, in addition to the
intrinsic goods of the sports, he would contribute to his fellow citizens’
pleasure and desire satisfaction. In _this_ decision, it seems that the number
of fellow citizens _does_ matter. The number of people Daniel can help as a
nurse is not very dependent on the total population, but the number of people
that his soccer skills can delight varies linearly with the total population,
and if the latter number is large enough, it seems that it would be quite
reasonable for Daniel to opt to be a soccer player. So we could have a case
where if Daniel is Belgian he should become a nurse but if Brazilian then a
soccer player (unless Brazil has a significantly greater need for nurses than
Belgium, that is). But once on the team, it doesn’t seem to matter much.

The map from axiology to moral reasons is quite complex, contextual, and
heavily agent-centered. The hope of reducing moral reasons to axiology is very
slim indeed.

As an Aristotelian who believes in individual forms, I’m puzzled about cases
of species-level flourishing that don’t seem reducible to individual
flourishing. On a biological level, consider how some species (e.g., social
insects, slime molds) have individuals who do not reproduce. Nonetheless it is
important to the flourishing of the _species_ that the species include some
individuals that do reproduce.

We might handle this kind of a case by attributing to other individuals their
_contribution_ to reproduction of the species. But I think this doesn’t solve
the problem. Consider a non-biological case. There are things that are
achievements of the human species, such as having reached the moon, having
achieved a four minute mile, or having proved the Poincaré conjecture. It
seems a stretch to try to individualize these goods by saying that we all
contributed to them. (After all, many of us weren’t even alive in 1969.)

I think a good move for an Aristotelian who believes in individual forms is to
say that “No man or bee is an island.” There is an external flourishing in
virtue of the species at large: it is a part of _my_ flourishing that humans
landed on the moon. Think of how members of a social group are rightly proud
of the achievements of some famous fellow-members: we Poles are proud of
having produced Copernicus, Russians of having launched humans into space, and
Americans of having landed on the moon.

However, there is still a puzzle. If it is a part of every human’s good that
“I am a member of a species that landed on the moon”, does that mean the good
is multiplied the more humans there are, because there are more instances of
this external flourishing? I think not. External flourishing is tricky this
way. The goods don’t always aggregate summatively between people in the case
of external flourishing. If external flourishing were aggregated summatively,
then it would have been better if Russia rather than Poland produced
Copernicus, because there are more Russians than Poles, and so there would
have been more people with the external good of “being a citizen of a country
that produced Copernicus.” But that’s a mistake: it is a good that each Pole
has, but the good doesn’t multiply with the number of Poles. Similarly, if
Belgium is facing off Brazil for the World Cup, it is not the case that it
would be way better if the Brazilians won, just because there are a lot more
Brazilians who would have the external good of “being a fellow citizen with
the winners of the World Cup.”

Consider a situation where a _finite_ number _N_ of people independently make
a choice between _A_ and _B_ and some disastrous outcome happens if the number
of people choosing _B_ hits a threshold _M_. Suppose further that if you fix
whether the disaster happens, then it is better you to choose _A_ than _B_ ,
but the disastrous outcome outweighs all the benefits from all the possible
choices of _B_.

For instance, maybe _B_ is feeding an apple to a hungry child, and _A_ is
refraining from doing so, but there is an evil dictator who likes children to
be miserable, and once enough children are not hungry, he will throw all the
children in jail.

Intuitively, you should do some sort of expected utility calculation based on
your best estimate of the probability _p_ that among the _N_ − 1 people other
than you, _M_ − 1 will choose _B_. For if fewer or more than _M_ − 1 of them
choose _B_ , your choice will make no difference, and you should choose _B_.
If _F_ is the difference between the utilities of _B_ and _A_ , e.g., the
utility of feeding the apple to the hungry child (assumed to be fairly
positive), and _D_ is the utility of the disaster (very negative), then you
need to see if _p_ _D_ \+ _F_ is positive or negative or zero. Modulo some
concerns about attitudes to risk, if _p_ _D_ \+ _F_ is positive, you should
choose _B_ (feed the child) and if its negative, you shouldn’t.

If you have a uniform distribution over the possible number of people other
than you choosing _B_ , the probability that this number is _M_ − 1 will be 1/
_N_ (since the number of people other than you choosing _B_ is one of 0, 1,
..., _N_ − 1). Now, we assumed that the benefits of _B_ are such that they
don’t outweigh the disaster even if everyone chooses _B_ , so _D_ \+ _N_ _F_ <
0. Therefore (1/ _N_ ) _D_ \+ _F_ < 0, and so in the uniform distribution case
you shouldn’t choose _B_.

But you might not have a uniform distribution. You might, for instance, have a
reasonable estimate that a proportion _p_ of other people will choose _B_
while the threshold is _M_ ≈ _q_ _N_ for some fixed ratio _q_ between 0 and 1.
If _q_ is not close to _p_ , then facts about the binomial distribution show
that the probability that _M_ − 1 other people choose _B_ goes approximately
exponentially to zero as _N_ increases. Assuming that the badness of the
disaster is linear or at most polynomial in the number of agents, if the
number of agents is large enough, choosing _B_ will be a good thing. Of
course, you might have the unlucky situation that _q_ (the ratio of threshold
to number of people) and _p_ (the probability of an agent choosing _B_ ) are
approximately equal, in which case even for large _N_ , the risk that you’re
near the threshold will be too high to allow you to choose _B_.

But now back to infinity. In the interpersonal moral Satan’s Apple, we have
infinitely many agents choosing between _A_ and _B_. But now instead of the
threshold being a finite number, the threshold is an infinite cardinality (one
can also make a version where it’s a co-cardinality). And this threshold has
the property that other people’s choices can _never_ be such that your choice
will put things above the threshold—either the threshold has already been met
without your choice, or your choice can’t make it hit the threshold. In the
finite case, it depended on the numbers involved whether you should choose _A_
or _B_. But the exact same reasoning as in the finite case, but now without
_any_ statistical inputs being needed, shows that you should choose _B_. For
it literally cannot make any difference to whether a disaster happens, no
matter what other people choose.

In my previous post, I suggested that the interpersonal moral Satan’s Apple
was a reason to embrace causal finitism: to deny that an outcome (say, the
disaster) can causally depend on infinitely many inputs (the agents’ choices).
But the finite cases make me less confident. In the case where _N_ is large,
and our best estimate of the probability of another agent choosing _B_ is a
value _p_ not close to the threshold ratio _q_ , it still seems
counterintuitive that you should morally choose _B_ , and so should everyone
else, even though that yields the disaster.

But I think in the finite case one can remove the counterintuitiveness. For
there are mixed strategies that if adopted by everyone are better than
everyone choosing _A_ or everyone choosing _B_. The mixed strategy will
involve choosing some number 0 < _p_ best < _q_ (where _q_ is the threshold
ratio at which the disaster happens) and everyone choosing _B_ with
probability _p_ best and _A_ with probability 1 − _p_ best, where _p_ best is
carefully optimized allow as many people to feed hungry children without a
significant risk of disaster. The exact value of _p_ best will depend on the
exact utilities involved, but will be close to _q_ if the number of agents is
large, as long as the disaster doesn’t scale exponentially. Now our
statistical reasoning shows that when your best estimate of the probability of
other people choosing _B_ is _not_ close to the threshold ratio _q_ , you
should just straight out choose _B_. And the worry I had is that everyone
doing that results in the disaster. But it does not seem problematic that in a
case where your data shows that people’s behavior is not close to optimal,
i.e., their behavior propensities do not match _p_ best, you need to act in a
way that doesn’t universalize very nicely. This is no more paradoxical than
the fact that when there are criminals, we need to have a police force, even
though ideally we wouldn’t have one.

But in the infinite case, no matter what strategy other people adopt, whether
pure or mixed, choosing _B_ is better.

_"But now instead of the threshold being a finite number, the threshold is an
infinite cardinality (one can also make a version where it’s a co-
cardinality). And this threshold has the property that other people’s choices
can **never** be such that your choice will put things above the threshold —
either the threshold has already been met without your choice, or your choice
can’t make it hit the threshold."_  
  
Such a bad formulation.  
Rather than pointing out, what's "never" the case, one should rather point
out, what's always the case there. The case with such a threshold is, that
such a threshold is either met or not met with or without your choice. Or in
other words such a threshold is met with or without your choice or is not met
with or without your choice.  
So specifically and particularly you making a choice doesn't matter for the
conditions of such a threshold either being met or being not met. But what
matters for the conditions of such a threshold either being met or being not
met is the actual state of affairs of a specific and particular kind of set,
in which you might be contained or not contained.  
It doesn't matter, which particular and specific bricks are used to obtain a
specific and particular wall. But what matters for the wall is if the set of
all bricks making out that wall is corresponding to the set of all natural
numbers.  
As for you as a single and specifical or particular brick - well, you can now
choose between being a part of that infinte wall or being not a part of that
infinte wall - holding out terrorists, illigal immigrants AND legal
immigrants, such as your ancesters were at one point in time and history, OR
NOT doing that - you can give an apple to a child OR NOT do that.  
It’s your choice. You kinda have to make that choice and also have to leave
with the consequences resulting from that made choice of yours.

Now, we deontologists are used to situations where a disaster happens because
one did the right thing. That’s because consequences are not the only thing
that counts morally, we say. But in the moral interpersonal Satan’s Apple,
there seems to be no deontology in play. It seems weird to imagine that
disaster could strike because everyone did what was consequentialistically
right.

One way out is causal finitism: Satan’s Apple is impossible, because the
disaster would have infinitely many causes.

If causal finitism is the solution, then it is at least a little interesting
that the domain of moral obligations is smaller than the logically possible
even though it extends beyond the physically possible. (I’m taking it as given
that causal finitism doesn’t just follow from the PNC.)  
  
Actually, now that I think about it, is causal finitism a solution? Let's
grant that it is impossible for one effect to have infinitely many causes.
Assume I am ignorant about this fact. It surely isn’t impossible for me to
intend to do something that I mistakenly believe to be such a cause. And won’t
that mistaken belief generate a similar paradox?

Interesting. Mistaken belief can generate the belief that you are IN the
paradox, but it doesn't seem to generate the paradox itself. For it's not
going to be true that everyone doing the right thing (feeding hungry children)
results in disaster, just that we think it will.

BTW, I suspect that there are a lot of moral paradoxes in situations which are
metaphysically impossible. Suppose you have the power to change the past. You
read about the Holocaust. Should you travel back in time and make sure
Hitler's parents never meet? On the one hand, if you do that, you prevent the
Holocaust. On the other hand, you will bring about the nonexistence of pretty
much all the people you know and care about (and not just for you, but for
most other people around you), because pretty much no one from the post-WWII
generations would have existed had WWII not happened. What, then, is the
ethics of changing past events? Moral paradoxes abound. And one can always
make your move: What if you think you CAN change the past?

This morning, however, I noticed that one can also take the idea of
discounting small probabilities more literally and still get the exact same
results as by trimming utility functions. Specifically, given a probability
function _P_ and a probability discount threshold _ϵ_ , we form a credence
function _P_ _ϵ_ by letting _P_ _ϵ_ ( _A_ ) = _P_ ( _A_ ) if _ϵ_ ≤ _P_ ( _A_ )
≤ 1 − _ϵ_ , _P_ _ϵ_ ( _A_ ) = 0 if _P_ ( _A_ ) < _ϵ_ and _P_ _ϵ_ ( _A_ ) = 1
if _P_ ( _A_ ) > 1 − _ϵ_. This discounts close-to-zero probabilities to zero
and raises close-to-one probabilities to one. (We shouldn’t forget the second
or things won't work well.)

If _U_ _ϵ_ is the “trimmed” utility function from my previous post, then LSI↑
_P_ _ϵ_ ( _U_ ) = _E_ ( _U_ 2 _ϵ_ ), so the two approaches are equivalent.

Fubini's theorem applies to expected values defined with respect to a measure.
The credence function P_e is not a measure in general, because in general it
fails finite additivity. Thus, the standard Lebesgue integral with respect to
P_e is undefined. I don't know what a "block integral" is.  
  
The point of level-set integrals for me is that they allow one to define a
fairly well-behaved expectation or prevision with respect to credence
assignments that are not probabilities because instead of additivity they only
satisfy monotonicity (P(A) is less than or equal to P(B) if A is a subset of
B).

Ah, "block" is my term. :-)  
  
Here's the background for why I am interested in expected values with respect
to non-probabilities. The credences or degrees of belief of real human beings
are unlikely to be consistent. In particular, they are unlikely to satisfy the
axioms of probability, especially additivity. At the same time, real human
beings need a way of making predictions. Mathematical expectation is out,
because that requires at least a finitely-additive measure (normally Lebesgue
integrals are defined with respect to a countably-additive measure but they
can also be defined with respect to a finitely-additive one). So we need some
other method for making predictions or generating expectations when the
credences do not satisfy the axioms of probability.

Suppose throughout this post that _ϵ_ > 0 counts as our threshold of “very
small probabilities”. No doubt _ϵ_ < 1/100.

In this post I want to offer a precise and friendly amendment to the solution
of neglecting small probabilities. But first why we need an amendment.
Consider a game where an integer _K_ is randomly chosen between  − 1 and _N_
for some large fixed positive _N_ , so large that 1/(2+ _N_ ) < _ϵ_ , and you
get _K_ dollars. The game is clearly worth playing. But if you discount
“possibilities that have very small probabilities”, you are left with
_nothing_ : every possibility has a very small probability!

Perhaps this is uncharitable. Maybe the idea is not that we discount to zero
_all_ possibilities with small probabilities, but that we discount such
possibilities until the total discount hits the threshold _ϵ_. But while this
sounds like a charitable interpretation of the suggestion, it leaves the
theory radically underdetermined. For _which_ possibilities do we discount? In
my lottery case, do we start by discounting the possibilities at the low end (
− 1, 0, 1, ...) until we have hit the threshold? Or do we start at the high
end ( _N_ , _N_ − 1, _N_ − 2, ...) or somewhere in the middle?

Here is my friendly proposal. Let _U_ be the utility function we want to
evaluate the value of. Let _T_ be the smallest value such that _P_ ( _U_ > _T_
) ≤ _ϵ_ /2. (This exists: _T_ = inf { _λ_ : _P_ ( _U_ > _λ_ ) ≤ _ϵ_ /2}.) Let
_t_ be the largest value such that _P_ ( _U_ < _t_ ) ≤ _ϵ_ /2 (i.e., _t_ = sup
{ _λ_ : _P_ ( _U_ < _λ_ ) ≤ _ϵ_ /2}). Take _U_ and replace any values bigger
than _T_ with _T_ and any values smaller than _t_ with _t_ , and call the
resulting utility function _U_ _ϵ_. We now replace _U_ with _U_ _ϵ_ in our
expected value calculations. (In the lottery example, we will be trimming from
both ends at the same time.)

The result is a precise theory (given the mysterious threshold _ϵ_ ). It
doesn’t neglect all possibilities with small probabilities, but rather it
trims low-probability outliers. The trimming procedure respects the fact that
often utility functions are defined up to positive affine transformations.

Moreover, the trimming procedure can yield an answer to what I think is the
biggest objection to small-probability discounting, namely that in a long
enough run—and everyone should think there is a non-negligible chance of
eternal life—even small probabilities can add up. If you are regularly offered
the same small chance of a gigantic benefit during an eternal future, and you
turn it down each time because the chance is negligible, you’re almost surely
missing out on an infinite amount of value. But we can apply the trimming
procedure at the level of choice of policies rather than of individual
decisions. Then if small chances are offered often enough, they won’t all be
trimmed away.

If at each time you are choosing between a finite number of betting portfolios
fixed in advance, with the betting portfolio in each decision being tied to a
set of events wholly independent of all the later or earlier events or
decisions, with the overall outcome being just the sum or aggregation of the
outcomes of the betting portfolios, and with the utility of each portfolio
well-defined given your information, then you should at each time maximize
utility.

In Satan’s Apple, for instance, the overall outcome is not just the sum of the
outcomes of the individual decisions to eat or not to eat, and so Satan’s
Apple is not a counterexample to (1). In fact, few of the paradoxes of
infinite sequences of decisions are counterexamples to (1).

I don’t know if there is something particularly significant about a paradox
violating (1). I think there is, but I can’t quite put my finger on it. On the
other hand, (1) is such a complex principle that it may just seem _ad hoc_.

Yup, in the story, taking all the even-numbered slices, or all the prime-
numbered slices, or all the power-of-two-numbered slices will get you kicked
out of paradise.

If so, then I guess, that any and every finite amount of slices will do for
Eve, as long as she doesn't go for any amount of slices with cardinality equal
to the cardinality of the set of all natural numbers. If she is ought to
maximise her utility AND there is no certain bound or limit to that
maximisation of a finite amount of slices of Satan's apple, then go figure,
what such a "maximum" in this case might be.  
 **As for me I will take an arbitrary amount of percentage below 100% of that
pie, I mean, of that _"Satan's apple"_ with an arbitrary finite amount of
slices.**  
Thank you very much.

Suppose someone offers you, at no cost whatsoever, something of specified
positive value. However small that value, it seems irrational to refuse it.

But what if someone offers you a random amount of positive value for free.
Strict dominance principles say it’s irrational to refuse it. But I am not
completely sure.

Imagine a lottery where some positive integer _n_ is picked at random, with
all numbers equally likely, and if _n_ is picked, then you get 1/ _n_ units of
value. Should you play this lottery for free?

The expected value of the lottery is zero with respect to any finitely-
additive real-valued probability measure that fits the description (i.e.,
assign equal probablity to each number). And for any positive number _x_ , the
probability that you will get less than _x_ is one. It’s not clear to me that
it’s worth going for this.

If you like infinitesimals, you might say that the expected value of the
lottery is infinitesimal and the probability of getting less than some
positive number _x_ is 1 − _α_ for an infinitesimal _α_. That makes it sound
like a better deal, but it’s not all that clear.

Of course, infinite fair lotteries are dubious. So I don’t set much store by
this example.

Professor Pruss,  
  
Here's a theological/philosophical question that I thought you might be
interested in. Speaking to the multitudes, John the Baptist says that "God is
able from these stones to raise up children to Abraham" (Luke 3:8). Setting
aside any questions of historicity (e.g. whether Abraham was a historical
figure, and so on), it can be safely assumed that John the Baptist (and those
to whom he was speaking) regarded the Judeans as literal, biological
descendants of Abraham. So it seems that, if taken at face value, he is saying
that God could turn the stones into literal, biological descendants of
Abraham. I wonder how this might bear on, for instance, essentiality of
origins.  
  
Of course, I think the solution is to avoid this sort of strict literalism,
but either way, it's fun to think about.

True. Even still, one wonders what it would mean for God to turn a stone into
a child of Abraham; it wouldn't be a literal biological descendent, nor would
it have undergone a conversion. I suppose just creating a person and declaring
them to be under the Abrahamic covenant could suffice?  
  
Pointless overthinking, of course.

Suppose Alice is blind to the intrinsic value of friendship and Bob can see
the intrinsic value of friendship. Bob then told Alice that friendship is
intrinsically valuable. Alice justifiedly trusts Bob in moral matters, and so
Alice concludes that friendship has intrinsic value, even though she can’t
“see” it. Alice and Bob then both pursue friendship for its own sake.

But there is a difference: Bob pursues friendship because of the particular
ineffable “thick” kind of value that friendship has. Alice doesn’t know what
“thick” kind of value friendship has, but on the basis of Bob’s testimony, she
knows that it has some such value or other, and that it is a great and
significant value. As long as Alice knows what kinds of actions friendship
requires, she can pursue friendship without that knowledge, though it’s
probably more difficult for her, perhaps in the way that it is more difficult
for a tone-deaf person to play the piano, though in practice the tone-deaf
person could learn what kinds of finger movements result in aesthetically
valuable music without grasping that aesthetic value.

The Aristotelian tradition makes the grasp of the particular thick kind of
value involved in a virtuous activity be a part of the full possession of that
virtue. On that view, Alice cannot have the full virtue of friendship. There
is something she is missing out on, just as the tone-deaf pianist is missing
out on something. But she is not, I think, less praiseworthy than Bob. In fact
Alice’s pursuit of friendship involves the exercise of a virtue which Bob’s
does not: the virtue of faith, as exhibited in Alice’s trust in Bob’s
testimony about the value of friendship.

Suppose you pursue truth for its own sake. As we learn from Aristotle, it does
not follow that you don’t pursue truth for the sake of something else. For the
most valuable things are both intrinsically and instrumentally valuable, and
so they are typically pursued both for their own sake and for the sake of
something else.

What if you pursue something, but not for the sake of something else. Does it
follow that you pursue the thing for its own sake? Maybe, but it’s not as
clear as it might seem. Imagine that you eat fiber for the sake of preventing
colon cancer. Then you hear a study that says that fiber doesn’t prevent colon
cancer. But you continue to eat fiber, out of a kind of volitional inertia,
without any reason to do so. Then you are pursuing the consumption of fiber
not for the sake of anything else. But merely losing the instrumental reason
for eating fiber doesn’t give you a non-instrumentally reason. Rather, you are
now eating fiber irrationally, for no reason.

Perhaps it is impossible to do something for no reason. But even if it is
impossible to do something for no reason, it is incorrect to _define_ pursuing
something for its own sake as pursuing it not for the sake of something else.
For that you _pursue something for its own sake_ states something positive
about your pursuit, while that you _don’t pursue it for the sake of anything
else_ states something negative about your pursuit. There is a kind of valuing
of the thing for its own sake that is needed to pursue the thing for its own
sake.

It is tempting to say that you pursue a thing for its own sake provided that
you pursue it because of the intrinsic value you take it to have. But that,
too, is incorrect. For suppose that a rich benefactor tells you that they will
give you a ton of money if you gain something of intrinsic value today. You
know that truth is valuable for its own sake, so you find out something. In
doing so, you find out the truth _because_ the truth is intrinsically
valuable. But your pursuit of that truth is entirely instrumental, despite
your reason being the intrinsic value.

Hence, to pursue a thing for its own sake is not the same as to pursue it
because it has intrinsic value. Nor is it to pursue it not for the sake of
something else.

I suspect that pursuing a thing for its own sake is a primitive concept.

1) Maybe seeking something for its own sake is a combination of both? Not
seeking it for the sake of something else, and also seeking it because of the
intrinsic value it has?  
  
2) As for the example of seeking the truth (which has intrinsic value, as
specified) for the money you'll be given, I think the usage of reason in _"But
your pursuit of that truth is entirely instrumental, despite your reason being
the intrinsic value."_ is a bit incomplete, since most people would use the
word "reason" to describe the actual goal they have in mind for which seeking
a true fact is purely instrumental.  
  
The intrinsic value of the truth then is kinda like any other property any
other thing might have that has utility - the intrinsic value is subordinated
and viewed in the light of the use it has for giving you money.  
  
You might as well be talking about seeking the proper tools to rob a bank with
a vast sum of money.

Wesley:  
  
1\. But you can seek something for its own sake while seeking it for the sake
of something else as well.  
  
2\. So, this is the weird thing about my example: the non-instrumental value
is being instrumentally pursued. (It kind of reminds me of Frege's infamous
"The concept horse is not a concept".) But the point remains that the non-
instrumental value is indeed a goal one has, just as when one is seeking to
rob a bank, the obtaining of the tools is a goal one has. Sure, you can use
"goal" or "reason" in such a way as to indicate the ultimate goal which one
non-instrumentally pursues, but then the account of non-instrumental pursuit
becomes circular: you non-instrumentally pursue X iff X is your non-
instrumentally pursued goal  
  
By the way, one can combine my truth and "volitional inertia" examples.
Suppose that a rich eccentric is paying me each time I get something of
intrinsic value. I am greedy and generally lacking in virtue, so I pursue all
sorts of things of intrinsic value solely for the sake of money. Then the
eccentric withdraws the offer. Out of volitional inertia, I continue to pursue
the things of intrinsic value, and do so because they have intrinsic value,
but I don't suddenly come to pursue them for their own sake. So in this
example, I pursue something because of its intrinsic value, and for no other
reason, and yet I do not pursue it for its own sake.  
  
I still think there is no way out of these cases other than to make the
concept of pursuit of a thing for its own sake primitive.

If there is a primitive notion in the vicinity, wouldn't it just be the three-
place predicate "x pursues y for the sake of z"? From here, we can analyze "x
pursues y for its own sake" as "x pursues y for the sake of y," and we can
analyze "x pursues y for the sake of something else" as "for some z, x pursues
y for the sake of z & z is not y."  
  
(Maybe there would be Frege-puzzle problems with this proposal, e.g., where y
= z but the agent doesn't know this, and pursues y for the sake of z?)

Brian:  
  
That's an option, but it seems to me that pursuing y for the sake of y is
different from pursuing y for its own sake, in the same way that x knowing
themselves is not the same thing as x knowing x, and similarly for other kinds
of reflexive actions. For x to play chess by themselves is not the same as for
x to play chess with x. The game is essentially different because when you
play chess by yourself you know what you're planning. (One could imagine a
case where Brian plays chess with Brian, without it being Brian playing chess
by himself, by supposing time-travel.) The Frege puzzles capture a part of the
difference, but I am not sure they capture all of it.

Here's another reason to think there is a difference. If I achieve x for the
sake of y, then y is a final cause of x. But if I achieve x for its own sake,
then x is not its own final cause. So to achieve x for its own sake is not the
same as to achieve x for the sake of x. And what goes for achievement probably
goes for pursuit.  
  
Now, you might say that if I achieve x for the sake of y AND x and y are
distinct, then y is a final cause of x. But now it looks like there is a
serious structural difference between achieving x for its own sake and
achieving x for the sake of y: in the latter case we have final causation and
in the former we don't. But now it seems "x for the sake of y" claims are
disjunctive in nature.

1) You can indeed seek something for its own sake while also seeking it for
the sake of something else, but that implies there are two motives properly
distinct from the other; and one could then perhaps say that what defines the
motive of seeking something for its own sake is to not seek it for the sake of
something else AND to seek it for the intrinsic value it has. This motive,
having such a structure, would still be properly distinct from the other
motive which DOES seek something for the sake of something else.  
  
2) So about seeking a thing of intrinsic value instrumentally, I think this
just reifies (or is that the wrong word to use?) or reduces the intrinic value
of a thing to just a means - you could literally just replace it and have the
rich man tell you he's gonna give you much money if you find something
completely red today.  
  
The redness in this case, just like the intrinsic value in the other, is just
an identifier that you're looking for in order to gain something else. So I
think there's a confusion of meaning going on when someone says they pursue X
because of the intrinsic value it has. One could take this in an instrumental
sense, or one could instead take this in a sense similar to how one loves
others for their own sake, or oneself for one's own sake.  
  
When one seeks the good of another person for the other's own sake, I guess
one is thereby recognising the intrinsic axiology or value-ness of the person
and doing the action on the basis of that.  
  
One sees the value of the other and recognises that benefitting the other
person itself, taking the person as the end because they're valuable simply as
such (axiologically I guess?) is good. So benefitting them is just
intrinsically worth seeking of itself, with the end being the person, and the
grounds being the value & worth of the person properly distinct from any other
end.  
  
  
3) As for achieving X for the sake of Y, I think the person doing the
achieving is also crucial. For the person wanting to achieve X for the sake of
Y, Y is the final cause of **their achieving** X, not X by itself simpliciter.  
  
So it seems one could say that, for the person wanting to achieve X, if he
wanted to do this for its own sake, he'd be taking X as the final cause of the
very achieving itself, or the seekig to achieve. There's no problem in taking
X as the final cause of itself then, since it's not about a final cause
inhering in X itself.  
  
  
4) I'd also love to know the difference between seeking X for X's sake and
seeking it for its own sake, because those two seem identical to me - what is
"its own sake" in regards to X? How could it not be, well.....X itself? Since
the "own" is self-referential to X?  
  

A typical human being has much more intrinsic value than any 80 kg arrangement
of atoms.

If materialism is true, a typical human being is an 80 kg arrangement of
atoms.

P1 seems to beg the question, no? If materialism (which I'm taking to mean
"objects have no parts in addition to their material/atomic parts") is true,
then P1 would be like saying "a typical human being has much more intrinsic
value than any human-sized object"....

I think materialism is false, and I’m not sure what to think about premise 1.
What kind of value does my body (the arrangement of atoms) have on a
hylomorphic view? Does it mainly have instrumental value? In general, if W is
a whole with intrinsic value, do its parts (the xs) mainly have instrumental
value, since they are for the sake of W? Or does the intrinsic value of the
whole bleed into all of the parts?

On reflection, it is easy enough to get around my worry just by eliminating
the word ‘much’ from the first premise. I think the argument would go through
just as well. But I’m still puzzled about how to think of intrinsic value in
parts.

Kratsch:  
  
Unless otherwise specified, or contextually required, "if ... then ..." in my
arguments is a material conditional. No claim is made that it *follows* from
materialism that a human is an 80 kg arrangement of atoms.

Alexander:  
  
Sure. "If X, then Y." in your arguments is a material conditional, which is
logically equivalent to "Not X or Y." by material implication and also
logically equivalent to "It's not, that X and not Y." by basically De Morgan's
law.  
Further some material conditionals are true as some material conditionals are
not true.  
So is your material conditional _"If materialism is true, a typical human
being is an 80 kg arrangement of atoms."_ or "Materialism is not true or a
typical human being is an 80 kg arrangement of atoms." or "It's not, that
materialism is true and a typical human being is not an 80 kg arrangement of
atoms."?!?  
Is it justified or substantiated in any given way?!?  
I don't know and I don't see that being here is the case or made to be the
case.  
  
On the other hand my material conditional "If any human is an arrangement of
atoms, then materialism must be necessarily true." is self-evidently true as
the material conditional "If a drawn quadrilateral is a square, then that
drawn quadrilateral is also a rectangle." is self-evidently true.  
  
Also where exactly is ¬Y - a typical human being is not an 80 kg arrangement
of atoms - in your argument here?  
Your premise 1 _“A typical human being has much more intrinsic value than any
80 kg arrangement of atoms.”_ doesn't appear to constitute such a claim and
statement by itself.  
Otherwise how are you exactly concluding from those two premises of yours,
that ¬X is the case - that materialism is not true?!?  
Or is your argument supposed to be not a “Denying the consequent” argument?  
If so, what kind of an argument is it then?!?

The justification is empirical: The material aspect of the human being is
scientifically known to be an 80 kg atomic arrangement. If materialism is
true, the material aspect is the only aspect. So, if materialism is true, the
human being is an 80kg atomic arrangement.

what about emergent properties? ex. atoms, neurons, Brians, consciousness.
Similar to other parts for what makes a human being

If they are merely weakly emergent, I don't see them making the value large
enough to contradict 1. It's still just an arrangement of atoms, a really cool
one, admittedly.  
  
If strongly emergent, then it's hard to say if we still have materialism.

Pruss: I suspect I just don't know what "Materialism" means (which I already
suspected, and now I'm more convinced). I'm not even entirely sure what
"material aspect" means in a statement like "the material aspect of a human
being is... an 80kg atomic arrangement"....  
  
Does the Materialist have to believe the following (which I'll call "M1")?  
  
 _The only accurate statements about a human being are statements that
describe the particular arrangement of atoms in question._  
  
If so, then the materialist surely cannot think that statements about, say,
enzyme activity or blood pressure or DNA transcription are true of humans
either, can she?

1\. The material aspect of the typical human being is an 80 kg atomic
arrangement. (Known by science.)  
2\. If materialism is true, a typical human being is identical with its
material aspect. (By definition of materialism)  
3\. So, materialism is false or a typical human being is identical with its
material aspect. (From 2 by definition of material conditional)  
4\. So, materialism is false or a typical human being is identical with an 80
kg atomic arrangement. (From 1 and 3)  
5\. So, if materialism is true, a typical human being is identical with an 80
kg atomic arrangement. (From 4 by definition of material conditional)  
  
Which step do you dispute?

Michael:  
  
I assume that the typical materialist thinks that statements about enzyme
activity and the like are statements about how atoms are arranged.  
  
Imagine a perfect computer simulation of the behavior of the atoms in a human
body. Either that simulation would include a simulation of enzyme activity or
not. If it does not, then we have weird top-down laws that ensure that the
microphysical laws have exceptions. I am open to that possibility but the
typical materialist is not. But if automatically the simulation of the
behavior of the atoms includes a simulation of enzyme activity, then the
materialist has a very good case that enzyme activity just is behavior of
atoms.

I think the main problem with this argument is the supposition that there can
be such a thing as "intrinsic value", and it is independent of whether
materialism is true or not. All values are by definition subjective (because
they admit no justification, empirical or otherwise). They are not something
humans come to know, but rather, humans make (conscious or subconscious)
decisions to evaluate things according to their subjective perspective,
emotions and preferences, and then project the values they generate onto
entities.

@Aron Bean Isn't that just begging the question that values can't be
"justified"? In what sense - just because it's not empirical doesn't mean
there can't be other forms of justification. How do we rule out other forms of
justification? And even if one can't justify this universally to others, that
doesn't mean the justification isn't true. For example, one knows one's own
existence immediately and uniquely through one's personal self-awareness, yet
this type of justification isn't subjective and unjustifiable just because
it's inherently inaccessible to others.

@Aron Bean Also it's kinda weird to say that there can be **no such thing** as
intrinsic value...and any intrinsic value is just us evaluating things with a
subjective perspective and projecting it to them. It's weird to think we
**actually have** the ability to conceptualise something as simple and
foundational as the idea of intrinsic value...all the while such a thing
literally can't exist. Not just doesn't, but as a whole the realm of reality
doesn't and even can't have such a thing in principle...  
  
Because if the idea is by definition subjective, then we should be aware of
this. Just as we know other subjective things as subjective, like preferences,
because we know what a preference is, and know it doesn't inhere in all things
even without knowing other persons with different preferences.  
  
Yet stangely most if not all see intrinsic value not as something in the same
category as preference, but as something found out and known in reality
itself.

Alex  
  
You beg the question in your argument.  
Your premise 1 is only true if materialisme is false, but it is false if
materialism is true. Because in that case, a typical human being has just as
much intrinsic value as the arrangement of atoms because he is thé arrangement
of atoms.  
Intrinsic values depend on how things (can) behave, not on their constituants.  
And this particular arrangement of atoms behaves like a human being, hence has
the intrinsic value of a human being.

If all values are subjective, there is no objective reason to do or believe
anything, because every reason expresses the value of the thing it is a reason
for.

Pruss: Does the materialist at least grant that the vocabulary of atomic
physics is insufficient to say everything that can truthfully be said? For
example, statements about enzymes catalyzing particular reactions (or, worse
yet, being "life-sustaining") are not sayable in the vocabularly of atomic
physics.

Alexander R Pruss: "there is no objective reason to do or believe anything"  
  
You cannot believe anything at will. Nor are your choices to do something are
ever free, even if they seem to be so. All your beliefs and choices to act are
predetermined by your genetic makeup and past experiences, which express
themselves in the current emotional/cognitive (that is, biochemical) state of
your brain. This hypothesis is simpler than to suppose some immaterial stuff,
whose interaction with material things, including the brain, would be beyond
comprehension.  
Also note that being rational is not somehow "inherently better" than being
irrational or arational. Rather, it's just that rationality is the kind of
attitude that pays off most of the time in the long run. And even this
"paying-off" translates to things that support the survival of the individual,
so it can be expressed in value-neutral terms.  
  
"every reason expresses the value of the thing it is a reason for"  
This is false.  
For example, if you know that p, and also know that "if p, then q", then this
knowledge, together with knowledge of the rule of inference "modus ponens" may
be a reason for you to believe (and, also know) that q. But there is nothing
that expresses the "value of q" in the state of knowing p, "if p, then q", or
in knowing "modus ponens", nor in its application. They are just propositions,
syntactic structures with semantic interpretation according to classical
logic. And there are many other alternative systems of logic, even some where
modus ponens is not a theorem.

Wesley C,  
  
"How do we rule out other forms of justification?" I don't want to rule out
other justifications to start with, that's why I wrote "empirical or
otherwise".  
"And even if one can't justify this universally to others, that doesn't mean
the justification isn't true."  
I don't accept any justification that is not universal. This is a
contradiction in terms. A justification must be repeatable and (in principle)
universally accessible to all.  
"For example, one knows one's own existence immediately and uniquely through
one's personal self-awareness."  
No, you doesn't know that, although this is admittedly tricky. To know is not
an "achievement verb" expressing an instantaneous event, but a "state verb",
which means that it is a state of an organism, and has a certain temporal
duration.  
Knowing, and also self-awareness and self-perception for that matter,
presuppose the correctness of memory, and because memory is fallible, there is
a chance (meaning that you cannot rule it out) that you are mistaken in
believing (and therefore you don't know) that you exist.

@Aron 1) Wow, you just buried yourself with your own arguments. If we can't
even be sure we ourselves exist, and all knowledge / perception / thinking
could just be false or irrational or even non-existent, then golly there can't
be such a thing as justification either.  
  
Certainly not individual but even less universal - other people could just not
exist as well, or be illusions, or whatever. Even if other people existed,
universal consensus or being convinced somethign is justified could also just
as well be false or non-existent.  
  
You should thereby become an absolute skeptic of everything.  
  
  
2) As for self-awareness depending on memory...every single memory you have
right now could just be false...but you'd still be aware you have those
memories. All your beliefs could be false & illusory, yet you'd still have
those beliefs.  
  
So unless the Principle of Non-contradiction is false...we can be absolutely
sure we have the memories / beliefs / experiences we actually have.  
  
You either have memories / beliefs / thoughts / experiences or you don't.  
  

On Thomistic accounts of transsubstantiation, the accidents of bread and wine
continue to exist even when the substance no longer does (having been turned
into the substance of Christ’s body and blood). This seems problematic.

Here is an analogy that occurred to me. Consider a magnet. It’s not crazy to
think of the magnet’s magnetic field as an accident of the magnet. But the
magnetic field extends spatially beyond the magnet. Thus, it exists in places
where the magnet does not.

Now, according to four-dimensionalism, time is rather like space. If so, then
an accident existing _when its substance does not_ is rather like an accident
existing _where its substance does not_. Hence to the four-dimensionalist, the
magnet analogy should be quite helpful.

Actually, if we throw relativity into the mix, then we can get an even closer
analogy, assuming still that a magnet’s field is an accident of the magnet.
Imagine that the magnet is annihilated. The magnetic field disappears, but
gradually, starting near the magnet, because all effects propagate at most at
the speed of light. Thus, even when the magnet is destroyed, for a short
period its magnetic field still exists.

That said, I don’t know if the magnet’s field is an accident of it. (Rob Koons
in conversation suggested it might be.) But it’s comprehensible to think of it
as such, and hence the analogy makes Thomistic transsubtantiaton
comprehensible, I think.

But where in space is the substance of the magnet? I would have thought that
it is where it acts, and since the magnetic field is how the magnet acts qua
magnet, it could not extend beyond the substance. The reason it feels like the
magnetic field extends beyond the magnet is that it acts in more than one way
(in the way it acts on the hand when it is held and in the way it acts on
magnetic metals).

Imagine that there is only one substance in the world, a magnet. It has a
magnetic field extending around it, beyond the magnet, no?  
  
(Of course, one could count the magnetic field as a separate substance. But
it's not clear that that's the right view.)

No, I don’t think so. I mean, I think that in most contexts, it would be fine
to _say_ that there is a single, cube-shaped lodestone (1×1×1) and a field
that extends beyond it. But I have real doubts that this way of talking works
here.  
  
Here is an analogy. The question of where I am could be taken to be asking
either where my principal activity takes place or else where all of my
activities take place. According to the first way, I am where my brain is.
According to the second way, I am where my entire body is. But it is the
latter, holistic answer, that is more fundamental.  
On this analogy, the cube-shaped lodestone is like the brain; its magnetic
field is like the whole body. The substance as a whole has one small,
localized activity and another activity that is more spread out. The answer to
the question, “Where is the magnet?” depends on which activity you have in
mind, but the more fundamental version of the question concerns all of its
activities rather than some of its limited, localized activities.  
  
What am I missing? How else does a substance get its ‘where’?

Whenever you gain a true belief, you gain a false belief.

You believe a conjunction if and only if you believe the conjuncts.

There is now some false belief _q_ that you have. (By (3))

Before you gained the belief _p_ you didn’t believe the conjunction of _p_ and
_q_. (By (4))

So, you just gained the belief in the conjunction of _p_ and _q_. (By (5) and
(7))

So, you just gained a false belief. (By (8) and (9))

Hi Professor Pruss. My apologies if this is off topic, but I wanted to ask a
question about the Eucharist. Specifically, what do you think of the claim
that it is metaphysically impossible for accidents to exist in the absence of
the substance of which they are accidents? Also, do you have any particular
objections to the consubstantiation view common among Anglo-Catholics
(including myself)?

I am an eternalist. I think it's OK for the accidents of a substance to be
located at a time where the substance does not exist. In one sense this isn't,
however, a case of the accidents existing without the substance, because when
the accidents exist presently, the substance exists, too, albeit pastly.  
  
As for consubstantiation, here are some worries.  
  
1\. When Jesus says "This is my body", it seems like he is pointing to the
visible thing, namely bread. If there is bread there, then he is pointing at
the bread. Thus, if there is bread there, he is making the incorrect or at
least non-literal statement that that thing, the bread, is his body. But the
Tradition likes to take Jesus's words here literally.  
  
2\. According to Scripture and Tradition, we eat Christ's body and drink his
blood. But on a consubstantiation view, it's not clear that this is the right
way to describe it. It seems that what we really eat and drink is the co-
present bread and wine, and the body and blood just happens to come along with
it. Here's my image of consubstantiation. Suppose that magnetic fields are
substances. Then where there is a magnet, we have something like
consubstantiation: there are two substances, a magnet and a magnetic field, in
the same place (I am talking of the magnetic field inside the magnet, not the
one that extends outside of it). But suppose now you foolishly eat the magnet
(DON'T DO IT; children have died from eating two magnets and having them pinch
through intenstines). I don't think it's correct to say that you eat both
substances. It seems that what you eat is the magnet, and the magnetic field
comes along for the ride.

I agree with your eternalism; still, I think this particular worry might
remain. It seems that the idea of a substance's accidents existing at a time
at which the substance itself does not exist pushes against the very same
intuitions that might have bothered us to begin with. In other words, it seems
that the problem can be restated in eternalist terms.  
  
Thanks for the two points on consubstantiation; they're both interesting, and
I'll have to give them more thought.

I don't know that it does. The main worry is that accidents depend on their
substance. But dependence can be cross-temporal, at least if eternalism is
true. See today's post, too.

Abstract: Scoring rules measure the accuracy or epistemic utility of a
credence assignment. A significant literature uses plausible conditions on
scoring rules on finite sample spaces to argue for both probabilism—the
doctrine that credences ought to satisfy the axioms of probabilism—and for the
optimality of Bayesian update as a response to evidence. I prove a number of
formal results regarding scoring rules on infinite sample spaces that impact
the extension of these arguments to infinite sample spaces. A common condition
in the arguments for probabilism and Bayesian update is strict propriety: that
according to each probabilistic credence, the expected accuracy of any other
credence is worse. Much of the discussion needs to divide depending on whether
we require finite or countable additivity of our probabilities. I show that in
a number of natural infinite finitely additive cases, there simply do not
exist strictly proper scoring rules, and the prospects for arguments for
probabilism and Bayesian update are limited. In many natural infinite
countably additive cases, on the other hand, there do exist strictly proper
scoring rules that are continuous on the probabilities, and which support
arguments for Bayesian update, but which do not support arguments for
probabilism. There may be more hope for accuracy-based arguments if we drop
the assumption that scores are extended-real-valued. I sketch a framework for
scoring rules whose values are nets of extended reals, and show the existence
of a strictly proper net-valued scoring rules in all infinite cases, both for
f.a. and c.a. probabilities. These can be used in an argument for Bayesian
update, but it is not at present known what is to be said about probabilism in
this case.

Comments from a user egregiously failing in the civility required in academic
discussion have been deleted and the user has been banned. My responses to
these comments have been deleted as well out of fairness to the user. I
should, however, note for the sake of anybody who read my comments that in one
of my comments I incorrectedly stated that the logarithmic score is not
additive, and the user was right to call me out on it, but did so in a manner
that was uncivil, and failures of civility are not tolerated.  
  
(Specifically, for a subset A of Omega, let s_A(c,t)=0 unless A is a singleton
and t=1. Then let s_{w}(c,1)=log c({w}). Then the logarithmic score of c is
the sum of s_A(c,1_A(w)) as A ranges over the subsets of Omega, and hence is
additive in my sense. I was, however, correct that the logarithmic score is
not strictly proper when we allow non-probability credences, since it ony
depends on the credences at singletons.)

My usual story about how to reconcile libertarianism with the Principle of
Sufficient Reason is that when we choose, we choose on the basis of
incommensurable reasons, some of which favor the choice we made and others
favor other choices. Moreover, this is a kind of constrastive explanation.

This story, though it has some difficulties, is designed for choices between
options that promote significantly different goods—say, whether to read a book
or go for a walk or write a paper.

But a different kind of situation comes up for choices of a point on a
spectrum. For instance, suppose I am deciding how much homework to assign, how
hard a question to ask on an exam, or how long a walk to go for. What is going
on there?

Well, here is a model that applies to a number of cases. There are two
incommensurable goods one better served as one goes in one direction in the
spectrum and the other better served as one goes in the other direction in the
spectrum. Let’s say that we can quantify the spectrum as one from less to more
with respect to some quantity _Q_ (amount of homework, difficulty of a
question or length of a walk), and good _A_ is promoted by less of _Q_ and
incommensurable good _B_ is promoted by more of _Q_. For instance, with
homework, _A_ is the student’s having time for other classes and for non-
academic pursuits and _B_ is the student’s learning more about the subject at
hand. With exam difficulty, _A_ may be avoiding frustration and _B_ is giving
a worthy challenge. With a walk, _A_ is reducing fatigue and _B_ is increasing
health benefits. (Note that the claim that _A_ is promoted by less _Q_ and _B_
is promoted by more _Q_ may only be correct within a certain range of _Q_. A
walk that is too long leads to injury rather than health.)

So, now, suppose we choose _Q_ = _Q_ 1. Why did one choose that? It is odd to
say that one chose _Q_ on account of reasons _A_ and _B_ that are opposed to
each other—that sounds inconsistent.

Here is one suggestion. Take the choice to make _Q_ equal to _Q_ 1 to be the
conjunction of two (implicit?) choices:

Now, we can explain choice (a) in terms of (a) serving good _A_ better than
the alternative, which would be to make _Q_ be bigger than _Q_ 1. And we can
explain (b) in terms of (b) serving good _B_ better than the alternative of
making _Q_ be smaller.

Here is a variant suggestion. Partition the set of options into two ranges _R_
1, consisting of options where _Q_ < _Q_ 1 and _R_ 2, where _Q_ > _Q_ 1. Why
did I choose _Q_ = _Q_ 1? Well, I chose _Q_ over all the choices in _R_ 1
because _Q_ better promotes _B_ than anything in _R_ 1, and I chose _Q_ over
all the choices in _R_ 2 because _Q_ better promotes _A_ than anything in _R_
1.

On both approaches, the apparent inconsistency of citing opposed goods
disappears because they are cited to explain different contrasts.

Note that nothing in the above explanatory stories requires any commitment to
there being some sort of third good, a good of balance or compromise between
_A_ and _B_. There is no commitment to _Q_ 1 being the best way to position
_Q_.

I like to illustrate the evidential force of simplicity by noting that for
about two hundred years people justifiably believed that the force of gravity
was _G_ _m_ 1 _m_ 2/ _r_ 2 even though _G_ _m_ 1 _m_ 2/ _r_ 2 + _ϵ_ fit the
observational data better if a small enough but non-zero _ϵ_. A minor point
about this struck me yesterday. There is doubtless some _p_ ≠ 2 such that _G_
_m_ 1 _m_ 2/ _r_ _p_ would have fit the observational data _better_. For in
general when you make sufficiently high precision measurements, you never find
_exactly_ the correct value. So if someone bothered to collate all the
observational data and figure out exactly which _p_ is the best fit (e.g.,
which one is exactly in the middle of the normal distribution that best fits
all the observations), the chance that that number would be 2 up to the
requisite number of significant figures would be vanishingly small, even if
_in fact_ the true value is _p_ = 2. So simplicity is not merely a tie-
breaker.

Note that our preference for simplicity here is actually infinite. For if we
were to collate the data, there would not just be _one_ real number that fits
the data better than 2 does, but a _range_ _J_ of real numbers that fits the
data better than 2. And _J_ contains uncountably many real numbers. Yet we
rightly think that 2 is more likely than the claim that the true exponent is
in _J_ , so 2 must be infinitely more likely than most of the numbers in _J_.

Ought implies can. Most people can’t do Bayesian reasoning correctly. So
Bayesian reasoning is not how they ought to reason. In particular, a reduction
of epistemic ought to the kinds of probability fcts that are involved in
Bayesian reasoning fails.

I suppose the main worry with this argument is that perhaps only an ought
governing voluntary activity implies can. But the epistemic life is in large
part involuntary. An eye ought to transmit visual information, but some eyes
cannot—and that is not a problem because seeing is involuntary.

However, it is implausible to think that we humans ought to do something that
nobody has been able to do until recently and even now only a few can do, and
only in limited cases, even if the something is involuntary.

If Bayesian reasoning isn’t how we ought to reason, what’s the point of it? I
am inclined to think it is a useful tool for figuring out the truth in those
particular cases to which it is well suited. There are different tools for
reasoning in different situations.

Maybe the relevant ought facts are like this: Even if we can't reason in
Bayesian way, we can acquire that ability, and we ought to. So we ought to do
something such that, if we do it, then we ought to reason in a Bayesian way.  
  
I can imagine someone saying something like, if we ought to phi, and phi-ing
implies that we ought to psi, then we ought psi.  
  
Consider something as plain as it being the case that I ought to place the
item on the shelf (I promised to, or I work at a grocery store). But I can't,
since I haven't picked up the item, and so how can I place the item on the
shelf? Clearly, we say that I can place the item, because I can pick it up
first.  
  
I realise as I type that this example isn't exactly what I started with, so
maybe this example illustrates the following principle:  
  
Principle: If you can and ought do something X, such that by doing X, you can
do something Y, and the ability to do Y is sufficient for it being the case
that you _ought_ to do Y, then you _can_ do Y and you ought to do Y.  
  
In the item-shelving case, X is pick up the item and Y is place the item on
the shelf. In the epistemology case, X is acquire Bayesian reasoning skills
and Y is reasoning in a Bayesian way. Of course, this only applies to those
who can learn, which is probably most adults.  
  
I have no idea how plausibly I find this. I'm just playing around with
possibilities.

Even if you acquire the basic mathematical skills, keeping track of
probabilities and conditionalizing on all the evidence is simply beyond our
capabilities. I am constantly receiving vast amounts of data. I just can't
conditionalize on it. All I can do is to pick out some small subset of the
data that seems relevant, and conditionalize on that. Take the lab scientist
who sees an instrument display "3.445". Maybe, though even that is a stretch,
they can conditionalize on the instrument displaying "3.445". But that's such
a small part of their evidence: there is, for instance, the particular pattern
of lights and shadows playing over the instrument display, the flow of air
from the vents, etc. Sure, one normally approximates by assuming all that
other stuff is independent of what one cares about in the experiment. But the
fact remains that one is failing to conditionalize on all one's data.

Could it be that the epistemic responsibility is to "go where the evidence
points", and that Bayesianism is just the most rigorous form of that? It would
be like saying that we ought to measure carefully when cutting the pieces to
build someone's house, but that we can only do as well as our available
instruments let us, and that that is sufficient. Bayesian reasoning as such
may not be an "available instrument" for most of us, but we ought to
approximate it as much as we can.  
  
I think Steven Pinker just wrote a book in which he equates rationality with
something like Bayesianism. I haven't read it yet, but it's on my list!

Suppose a trolley is heading towards five people, and you can redirect it
towards one. But the trolley needs to go up a hill before it can roll down it
to hit the five people, and your best estimate of its probability of making it
up the hill is 1/4. On the other hand, if you redirect it, it’s a straight
path to the one person, who is certain to be killed. Do you redirect? Expected
utilities:  − 1.25 lives for not redirecting and  − 1 lives for redirecting.

Or suppose you are driving a fire truck to a place where five people are about
to die in a fire, and you know that you have a 1/4 chance of putting out the
fire and saving them if you get there in time. Moreover, there is a person
sleeping on the road in front of the only road to the fire, and if you stop to
remove the person from the road, it will be too late for the five. Do you
brake? Expected utilities:  − 5 lives for braking and  − 1 − 3.75 = − 4.75
lives for continuing to the fire and running over the person on the road.

I think you shouldn’t redirect and you should brake. There is something
morally obnoxious about certainly causing death for a highly uncertain benefit
_when the expected values are close_. This complicates the proportionality
condition in the Principle of Double Effect even more, and provides further
evidence against expected-value utilitarianism.

###  The Law of Large Numbers and infinite run payoffs

In discussions of maximization of expected value, the Law of Large Numbers is
sometimes invoked, at times—especially by me—off-handedly. According to the
Strong Law of Large Numbers (SLLN), if you have an infinite sequence of
independent random variables _X_ 1, _X_ 2, ... satisfying some conditions
(e.g., in the Kolmogorov version ∑ _n_ ( _σ_ _n_ 2/ _n_ 2) < ∞, where _σ_ _n_
2 is the variance of _X_ _n_ ), then with probability one, the average of the
random variables converges to the average of the mathematical expectations of
the random variables. The thought is that in that case, if the expectation of
each _X_ _n_ is positive, it is rationally required to accept the bet
represented by _X_ _n_.

Here I want to make a minor observation. The fact that the SLLN applies to
some sequence of independent random variables is itself not sufficient to make
it rational to bet in each case according to the expectations in an infinite
run. Let _X_ _n_ be 2 _n_ / _n_ with probability 1/2 _n_ and − 1/(2 _n_ ) with
probability 1 − 1/2 _n_. Then

_E_ _X_ _n_ = (1/2 _n_ )(2 _n_ / _n_ ) − 1/(2 _n_ )(1−1/2 _n_ ) = (1/ _n_
)(1−(1/2)(1−1/2 _n_ )).

Clearly _E_ _X_ _n_ > 0. So in individual decisions based on expected value,
each _X_ _n_ will be a required bet.

Now, just as in my previous post, almost surely (i.e., with probability one)
only finitely many of the bets _X_ _n_ will have the positive payoff. Thus,
with a finite number of exceptions, our sequence of payoffs will be the
sequence  − 1/2, − 1/4, − 1/6, − 1/8, .... Therefore, almost surely, the
average of the first _n_ payoffs converges to zero. Moreover, the average of
the first _n_ mathematical expectations converges to zero. Hence the variables
_X_ 1, _X_ 2, ... satisfy the Strong Law of Large Numbers. But what is the
infinite run payoff of accepting all the bets? Well, given that almost surely
there are only a finite number of _n_ such that the payoff of bet _n_ is not
of the form − 1/(2 _n_ ), it follows that almost surely the infinite run
payoff differs by a finite amount from  − 1/2 − 1/4 − 1/6 − 1/8 = − ∞. Thus
the infinite run payoff is negative infinity, a disaster.

Hence even when the SLLN applies, we can have cases where almost surely there
are only finitely many positive payments, infinitely many negative ones, and
the negative ones add up to  − ∞.

In the above example, while the variables satisfy the SLLN, they do not
satisfy the conditions for the Kolmogorov version of the SLLN: the variances
grows exponentially. It is somewhat interesting to ask if the variance
condition in the Kolmogorov Law is enough to prevent this pathology. It’s not.
Generalize my example by supposing that _a_ 1, _a_ 2, ... is a sequence of
numbers strictly between 0 and 1 with finite sum. Let _X_ _n_ be 1/( _n_ _a_
_n_ ) with probability _a_ _n_ and  − 1/(2 _n_ ) with probability 1 − _a_ _n_.
As before, the expected value is positive, and by Borel-Cantelli (given that
the sum of the _a_ _n_ is finite) almost surely the payoffs are  − 1/(2 _n_ )
with finitely many exceptions, and hence the there is a finite positive payoff
and an infinite negative one in the infinite run.

But the variance _σ_ _n_ 2 is less than _a_ _n_ /( _n_ _a_ _n_ )2 \+ 1 = (1/(
_n_ 2 _a_ _n_ )) + 1. If we let _a_ _n_ = 1/ _n_ 2 (the sum of these is
finite), then each variance is at most 2, and so the conditions of the
Kolmogorov version of the SLLN are satisfied.

The last example (with a_n = 1/n^2) is very neat. I had been trying to think
of something similar. :-)  
  
The Peköz paper I mentioned in the other post has, in addition to the variance
condition [sum of (nth variance/n^2 finite)], the condition that all the
individual expectations are greater than some strictly positive constant. In
the example, this is violated - the nth expectation is about 1/n. So again,
there’s no formal contradiction. Of course, this is no surprize.

If you assume that the nth expectation is bigger than c>0, and the Strong Law
of Large Numbers applies, then of course almost surely the person who accepts
all the bets will eventually be better off than the person who rejects all the
bets, and the difference between the two will grow without bound. And the
variance condition is sufficient for the Strong Law.  
  
Do you think this is true: If someone thinks the above result is a good reason
to accept rather than reject all the bets, then they should also think that in
my case we have good reason to reject rather than accept all the bets?

Yes, I’d say that, if, in the case of nth expectation greater than c>0,
someone takes SLLN (if it applies) as a reason to accept all the bets, then in
your example they should refuse to accept all the bets – if they reason on the
basis of a ‘with probability 1’ result in one case, they should also do so in
the other. That said, you should take care to note exactly what the various
authors are actually arguing.  
  
Speaking for myself, I don’t think that any result about an actual infinity of
bets, or even just about limits of finite sequences of bets, is in itself a
good reason to do anything. (Though, of course, such results can give useful
hints.) What matters is the likely position when the game ends, as, in the
real world, it must.  
  
In your example, the distribution of partial sums has progressively increasing
variance and skewness. Roughly (if I’m thinking straight), variance of the nth
partial sum grows like n, 3rd moment grows like (n^2)/2. The normalized 3rd
moment (i.e. with the outcome divided by its s.d. to make the variance 1)
grows like (n^(1/2))/2. If I were really offered this sequence of bets, with
the option of choosing in advance how many to accept, I’d feel that for large
n, things would get pretty hairy, way too hairy to justify accepting on the
basis of the positive expectation, which only grows like ln(n)/2. So I’d
choose a smallish n I felt comfortable with.

I still feel that the fact that in my examples, almost surely, at some
*finite* point in time the expected utility non-maximizer overtakes the
expected utility maximizer, and after that the gap just increases, seems
significant. But I can't put my finger on what exactly is significant about
it.

Here’s an odd phenomenon. Someone tells you something. You know it’s false,
but their telling it to you raises the probability of it.

For instance, suppose at the beginning of a science class you are
teachingabout your studnts about significant figures, and you ask a student to
tell you the mass of a textbook in kilograms. They put it on a scale
calibrated in pounds, look up on the internet that a pound is exactly
0.45359237 kg, and report that the mass of the object is 1.496854821 kg.

Now, you know that the classroom scale is not accurate to ten significant
figures. The chance that the student’s measurement was right to ten
significant figures is tiny. You _know_ that the student’s statement is wrong,
assuming that it _is_ in fact wrong.

Nonetheless, even though you know the statement is wrong, it raises the
probability that the textbook’s mass is 1.496854821 kg (to ten significant
figures). For while most of the digits are garbage, the first couple are
likely close. Before you you heard the student’s statement, you might have
estimated the mass as somewhere between one and two kilograms. Now you
estimate it as between 1.45 and 1.55 kg, say. That raises the probability that
in fact, up to ten significant figures, the mass is 1.496854821 kg by about a
factor of ten.

So, you know that what the student says is false, but your credence in the
content has just gone up by a factor of ten.

Of course, some people will want to turn this story into an argument that you
don’t know that the student’s statement is wrong. My preference is just to
make this statement another example of why _knowledge_ is an unhelpful
category.

On reflection, the phenomenon in the first sentence of the post isn't odd at
all. Typically if someone tells you something, that is evidence for what they
tell you, even if you know it's not true.

Alex  
  
If the first digits are likely close, what the student says is not completely
wrong. It is inaccurate.  
The reason you learn something from it is because you already have knowledge
about the book's probable weight. Suppose you ask me about the distance
between the earth and the moon and I say it's 400 000 km. That's wrong, but it
is a better answer than, say, 4 million km. Suppose that before you asked me,
you estimated the distance as between 100 000 and 1 million, then now you
estimate it between 300 000 and 500 000.  
The reason you can estimate it is becasue you have a certain confindence in my
claims. Even though you know I cannot have measured the distance accurately
enough to know it's 400 000 km, you are still confident that I at least know
something about it.  
Now compare this to a situation in which I simply tell you a random distance.
The only thing you learn from this is that I am not capable of or willing to
make a genuine effort.  

Even if you know that I am telling you a random distance, you still learn from
it. For your knowledge of such facts as that I am telling you a random
distance is never certain. It may look like I'm just making it up at random,
but there is a chance that my statement is guided by the truth. (There is also
a chance that my statement is guided by falsehood. But I think that, absent
special evidence about me having reason to positively deceive you, that chance
is smaller.) Or I may be filtering particularly ridiculous random answers
(e.g., you ask me how many miles it is from Waco to Los Angeles, and I google
"random number", and get 4; but that's too ridiculous, so I just say 100).

Alex  
  
Suppose you want to go to a place P. There is only one road that leads to P,
namely the road to the right.  
Now you ask me which way you should go and I tell you that the left road is
the correct one, which is the wrong way.  
What do you learn from this?

My claim was only that typically you learn something in favor of p by being
told that p is true. There are, of course, exceptions (e.g., if you know that
someone is going to be lying, in which case their saying something is evidence
that they disbelieve it, which in turn is evidence against it).  
  
That said, that an intelligent person believes a clear and explicit
contradiction may be some very slight evidence against the law of
noncontradiction.

Suppose Alice deserves a punishment of degree _d_ , and Bob and Carl each
impose on her a different punishment of degree _d_. Who unjustly punished
Alice?

If one punishment came before the other, we can say that the second punishment
was unjust, since it was the punishment of a person who no longer deserved
punishment. But what if the two punishments are simultaneous?

Maybe we can say that each of Bob and Carl contributed to an unjust
punishment. But what each contributed was just! Still, I think the
contribution story seems best to me.

The contribution story does seem intuitively correct, and I think we can make
sense of the fact that two just punishments combine into an unjust punishment.
If Alice deserves a punishment to degree d, then it seems Alice must have done
something which harmed someone else proportionally to degree d. This is
because the degree of punishment deserved must be proportional to the degree
of harm done. Thus, if both Bob and Carl simultaneously impose punishments of
degree d on Alice, then each has imposed punishments that are separately
proportional to the harm done, but are jointly disproportional to the harm
done. It is this disproportionality that renders the joint punishment unjust.  
  
I wonder if this suggests that punishment can only properly come from one
source (where this source may be either one individual or a collective)?
Consider the following equivalent, but slightly more specified case. A
teenager breaks into a church donation box and steals the money inside. Upon
finding out about this theft, the teen's parents separately and unbeknownst to
the other donates money to the church from the teen's bank account equal to
the amount stolen plus some amount X that fulfills the requirements of
punishment (e.g. covering secondary harms like the broken offering box and
serving as a deterrent for future theft). Similar to the previous case, each
punishment is proportional to the harm done and therefore just. Additionally,
these punishments are jointly unjust as, combined, they are clearly
disproportional to the harm done.  
  
Notice in this case it seems the problem is that the parents did not act as
one unit. They independently imposed two punishments for one bad act. These
punishments combine to one joint punishment that is issued from the collective
parents. So while individually neither parent gave an unjust punishment, they
failed as members of the actual punishing entity to properly coordinate and
issue just punishment.  
  
It's also interesting to consider an opposite case. Start with the previous
case, only this time each parent independently impose punishments that are
half of what is deserved. In this case, each punishment is individually less
than what justice calls for (and is thus unjust to the victims), but they are
jointly just. As such, the parents jointly and accidentally punished their
child justly. However, it seems neither is praiseworthy because they
individually issued unjust punishments.

Alex (Pruss)  
  
Bob's punishment is not just if Bob knows about Carl's punishment and vice
versa.  
the only way to have a just punishment in this case is by cooperating. That
means that Bob, as soon as he knows about Carl's punishment, should talk to
Carl and together they can impose a just punishment.  
If Carl and Bob ezch get to impose their punishment it is not a punishment of
degree d, but a punishment of degree (d+d) and a punishment of degree (d+d) is
unjust in the case of Alice.

Suppose that I uniformly randomly choose a number _x_ between 0, inclusive,
and 1, exclusive. I then look at the bits _b_ 1, _b_ 2, ... after the binary
point in the binary expansion _x_ = 0. _b_ 1 _b_ 2.... Each bit has equal
probability 1/2 of being 0 or 1, and the bits are independent by the standard
mathematical definition of independence.

Now, what I said is actually underspecified. For some numbers have two binary
expansions. E.g., 1/2 can be written as 0.100000... or as 0.011111... (compare
how in decimal we have 1/2 = 0.50000... = 0.49999...). So when talked of “the”
binary expansion, I need to choose one of the two. Suppose I do the intuitive
thing, and consistently choose the expansion that ends with an infinite string
of zeroes over the expansion that ends with an infinite string of ones.

This fine point doesn’t affect anything I said about independence, given the
standard mathematical definition thereof. But there is an intuitive sense of
independence in which we can now see that the bits are _not_ independent. For
instance, while each bit can be 1 on its own, it is impossible to have all the
bits be 1 (this is actually impossible regardless of how I decided on choosing
the expansion, because _x_ = 1 is excluded), and indeed impossible to have all
the bits be 1 from some point on. There is a very subtle dependence between
the bits that we cannot define within classical probability, a dependence that
would be lacking if we tossed an infinite number of "really" independent fair
coins.

Suppose every day for eternity you will be offered a gamble, where on day _n_
≥ 1 you can choose to pay half a unit of utility to get a chance of 2− _n_ at
winning 2 _n_ units of utility.

At each step, the expected winnings are 2 _n_ ⋅ 2− _n_ = 1 unit of utility,
and at the price of half a unit, it looks a good deal.

**Objection:** All this has to do with aggregating an infinite number of
payments, or traversing an infinite future, and hence is just another paradox
of infinity.

**Response:** Actually the crucial point can be made without aggregating
infinitely many payments. Suppose you adopt the policy of accepting the
gamble. Then, with probability one, there will come a day _M_ after which you
never win again. By day _M_ , you may well have won some (maybe very large)
finite amount. But after that day, you will keep on paying to play and never
win again. After some further finite number of days, your losses will overtake
your winnings, and after that you will just fall further and further behind
every day. This unhappy fate is almost sure if you always accept the gamble,
and hence if you adopt expected utility maximization in individual decisions
as your policy. And the unhappiness of this fate does not depend on
aggregation of infinitely many utilities.

**Question:** What if the game ends after a fixed large finite number of
steps?

**Response:** In any finite number of steps, of course the expected winnings
are higher than the price you pay. But nonetheless as the number of steps gets
large, the chance at those expected winnings shrinks. Imagine that the game
goes on for 200 days, the game on day 100 has finished, and you’re now
choosing your policy for the next 100 days. The expected utility of playing
for the next 100 days is 50 units. However, assuming you accept this policy,
the probability that you will win anything over the next 100 days is less than
2−100, and if you don’t win anything, you lose 50 units of utility. So it
doesn’t seem crazy to think that the no-playing policy is better, even though
it has worse expected utility. In fact, it seems like quite a reasonable thing
to neglect that tiny probability of winning, less than 2−100, and refuse to
play. And knowing that the expected utility reasoning when extended for
infinite time leads to disaster (infinite loss!) should make one feel better
about the decision to violate expected utility maximization.

**Final remark:** It is worth considering what happens in interpersonal cases,
too. Suppose infinitely many people numbered 1, 2, 3, ... are given the
opportunity to play the game, with person _n_ being given the opportunity of
winning 2 _n_ units with probability 2− _n_. If everyone goes for the game,
then almost surely a finite number of people will win a finite amount while an
infinite number pay the half-unit price. That’s disastrous: an infinite price
is being paid for a finite benefit.

“… and suggests a limitation of the argument here.”  
  
From a formal point of view, I think the issue is that the sequence of gambles
is not ‘well-behaved’ in the sense of Zhao’s footnote 14. I can’t be sure,
because Zhao does not spell this out, but refers to _Stephen Ross “Adding
Risks: Samuelson’s Fallacy of LargeNumbers Revisited.” Journal of Financial
and Quantitative Analysis, 34:323–339, 1999_ , which is gated. (SUPPORT OPEN
ACCESS!) Zhao says _The requirement is meant to rule out improbable cases like
those where one decision has stakes that swamp all others, … ._ In this case,
the last gamble is always about the size of all the previous ones together.

I guess I've tended to think that it's precisely in cases of rare large stakes
gambles that it makes sense to depart from expected utility. For small
repeatable gambles, of course we have central limit theorem or law of large
numbers considerations.  
By the way, we don't need anything as radical as exponential growth. Barely
more than linear growth is enough. My point goes through with n (log n)^2 as
the nth prize with probability the reciprocal of that.

As I said, I can’t access Ross. But this paper [Erol A. Peköz: Samuelson's
Fallacy of Large Numbers and Optional Stopping. Journal of Risk and Insurance,
March 2002], which builds on it, states a similar result.  
  
Peköz requires the condition than Σ((Nth variance)/N^2) is finite. I’m
guessing the Ross’s condition may be similar. With even linear growth of
prizes and reciprocal linear probabilities, the sum doesn’t converge. So it
won’t converge with N (log N)^2 growth (and reciprocal probabilities) either.  
  
  
For what little it’s worth, I share your doubts about EU for rare high-stakes
gambles. My intent is to account for the apparent discrepancy between Zhao’s
remarks and yours.

None of that suggests that there is anything wrong with Zhao and the others in
a narrow formal sense – given their conditions, their formal results hold. Of
course, the philosophical implications and practical relevance are a different
matter. The same applies to your examples.  
  
  
Against Zhao and the others, one could say this: it’s great that, given their
conditions, choosing to accept every time ‘eventually’ becomes favoured, but
is ‘eventually’ likely to be in your lifetime? It depends on the specifics.  
  
Against your examples, one could say that they require you and the other party
to have unlimited money and unlimited time to gamble with it. What matters is
the likely conditions when time or money run out.  
  
I’m doubtful about the applicability of standard decision theory for one-0ff
high stakes choices, but I’m not sure that any of these cases are decisive.  
  
Our intuitions about sequences of fair (favourable, unfavourable) bets are
reflected in the martingale (super-martingale, sub-martingale) optional
stopping theorems. But these theorems have conditions which can be violated in
quite ordinary setups. A simple example: repeated triple-or-nothing on fair
coin flips. Each bet has positive expectation, but if you accept them all, you
will lose you initial stake with probability 1.  
  
You don’t need exponential growth to get this sort of thing. A simple example
is textbook Gambler’s Ruin. A fair coin is flipped. You win $1 on Heads, lose
$1 on Tails. You play repeatedly against the house until either you go broke,
or the house does. You start with $M, the house with $N. Your chance of ruin
is M/(M+N), of ruining the house is N/(M+N). Your expected final fortune is of
course the $M you started with.  
  
But what if the house has unlimited money? Then you will be ruined, and suffer
a loss of $M, with probability 1.

Ian:  
  
I am trying to argue against the thesis that you should take the bets with
positive expectation. Gambler's Ruin doesn't affect that because the bets have
zero expectation.  
  
I also have a weak intuition that cases where what goes on in each wager is
independent of what goes on in the others are more compelling. Triple-or-
nothing doesn't have this independence: once ruined, you get nothing.
Gambler's Ruin has a changing fortune.  
  
Another thing that makes my case particularly compelling to me is the
interpersonal version, where each person faces a single wager, all the wagers
completely independent, and yet if everyone maximizes their expected utility,
with probability one, the result is disastrous--infinitely many paying and
finitely many winning. It's like a tragedy of the commons, but with no
interaction between the agents' decisions, no weird undefined probabilities,
just everyone doing ordinary expected value maximization.

It's also interesting to think about whether one's intuitions would be
different in a reverse case. On day n, if you take the gamble, you are sure to
get 1/2 unit and have a 1/2^n chance of losing 2^n. By expected utilities, you
should refuse. But if you always accept, then almost surely you lose only a
finite amount and gain an infinite amount.

What worries me about this is the actual infinity of people and the unbounded
bets. Suppose there are N people. It’s clear that for large N, most people are
likely to lose small amounts. This is balanced by the very small probability
that the last few people win very large amounts. To some people’s intuition
(including mine) this does not seem like a good outcome. But I think that an
_argument_ for this has to be based on this finite case.

Unbounded bets, while difficult to handle in decision theory, don't seem
metaphysically problematic. Suppose you have a friend you love as yourself but
who is currently "scheduled" to have a headache for eternity, while you are
currently "scheduled" to live forever without headache. Each time you win x
units, your friend gets x days off from headache. Each time you lose x units,
you get x days of headache. Specify that you don't get used to the headaches.
(If you think it's metaphysically impossible not to be getting used to
headaches, suppose your and your friend's memory of the previous day's
headache or lack thereof is wiped each day.)

Well, here is one way to look at headache setup…  
  
If you make only a finite number of bets, you and your friend together are
certain to suffer an infinite number of headache days. If you accept all the
bets, it’s possible that you might win them all. Then you and your friend will
suffer no headaches. (I’m assuming that the headache-free days you win for
your friend are taken sequentially without gaps.) Of course, this outcome has
probability zero. But isn’t the _possibility_ of no headaches, even at
probability zero, to be preferred to the _certainty_ of an infinite number?
:-). And note, this sort of ‘reasoning’ applies even if the expected value of
each bet is negative. :-)  
  
Hmm… This line of thought gives zero value to any merely finite change. But if
you take the actual infinity seriously, and you compare by counting headache
days, I’m not even sure that that is wrong. Maybe it’s better to stick with
the original version with positive and negative payoffs.

Ian:  
  
If Causal Finitism is false, you could tweak the situation to make sure you
can't just win all the bets. For instance, you could run the story in a
supertask, make the payoffs come after the end of the supertask, and if you
"won" all the bets (or even infinitely many of the bets), you lose all the
benefits. This does not affect the statistical independence of all the events,
because winning all the bets has zero probability, and changing things on a
zero-probability set doesn't affect independence. But it does affect
"intuitive" independence.

Generally people think that if a trolley is heading for a bunch of people,
it’s wrong to push an innocent bystander in front of the trolley to stop it
before it kills the other people, with the innocent bystander dying from the
impact.

But imagine that it is 99% likely that the bystander will survive the impact,
but 100% certain that the five people further down the track would die.
Perhaps the trolley is accelerating downhill, and currently it only has a 1%
chance of lethality, but by the time it reaches the five people at the bottom
of the hill, it has a 100% chance of lethality. Or perhaps the five people are
more fragile, or the bystander is well-armored. For simplicity, let’s also
suppose that the trolley cannot inflict any major injury other than death. At
this point, it seems plausible that it is permissible to push the bystander in
front of the trolley.

But now let’s suppose the situation is repeated over and over, with new people
at the bottom of the track but the same unfortunate bystander. Eventually the
bystander dies, and the situation stops (maybe that death is what convinces
the railroad company to fix the brakes on their trolleys). We can expect about
500 people to be saved at this point. However, it seems that in the case where
the bystander wasn’t going to survive the impact, it would have been wrong to
push them even to save 500.

There are at least two non-consequentialist ways out of this puzzle.

It is wrong to push the bystander to save five, but not wrong to push them to
save five hundred. While this is a special case of threshold deontology, one
can make this move without embracing threshold deontology. One can say that no
matter how many are saved, it is wrong to intentionally kill the innocent
bystander, but lethal endangerment becomes permissible once the number of
people saved is high enough.

Initially, I also thought the following was an appealing solution: It matters
whether it is the same bystander who is pushed in front of the trolley each
time or a different one. Pushing the same bystander repeatedly unjustly
imposes a likely-lethal burden on them, and that is wrong. But it would be
permissible to push a _different_ bystander each time onto the track, even
though it is still almost certain that eventually a bystander will die. The
problem with this solution is this. When the sad situation is repeated with
different bystanders, by adopting the policy of pushing the bystander, we are
basically setting up a lethal lottery for the bystanders—one of them will be
killed. But if we can do that, then it seems we could set up a lethal lottery
a different way: Choose a random bystander out of, say, 500, and then keep on
pushing that bystander. (Remember that the way the story was set up, death is
the only possible injury, so don’t think of that bystander as getting more and
more bruised; they are unscathed until they die.) But that doesn’t seem any
different from just pushing the same bystander without any lottery, because it
is pretty much random which human being will end up being the bystander.

One strategy for accounting for deontology while allowing the tools of
decision theory to be used is to set such a high disvalue on violations of
deontic constraints that we end up having to obey the constraints.

I think this leads to a very implausible consequence. Suppose you shouldn’t
violate a deontic constraint to save a million lives. But now imagine you’re
in a situation where you need to _ϕ_ to save ten thousand lives, and suppose
that the non-deontic-consequence badness of _ϕ_ ing is negligible as compared
to ten thousand lives. Further, you think it’s pretty likely that there is no
deontic constraint against _ϕ_ ing, but you’ve heard that a small number of
morally sensitive people think there is. You conclude that there is a 1%
chance that there is a deontic constraint against _ϕ_ ing. If we account for
the fact that you shouldn’t violate a deontic constraint to save a million
lives by setting a disvalue on violation of deontic constraints greater than
the disvalue of a million deaths, then a 1% risk of violating a deontic
constraint is worse than ten thousand deaths, and so you shouldn’t _ϕ_ because
of the 1% risk of violating a deontic constraint. But this is surely the wrong
result. One understands a person of principle refusing to do something that
clearly violates a deontic constraint to save lots of lives. But to refuse to
do something that has a 99% chance of not violating a deontic constraint to
save lots of lives, solely because of that 1% chance of deontic violation, is
very implausible.

While I think this argument is basically correct, it is also puzzling. Why is
it that it is so morally awful to knowingly violate a deontic constraint, but
a small risk of violation can be tolerated? My guess is it has to do with
where deontic constraints come from: they come from the fact that in certain
prohibited actions one is setting one’s will against a basic good, like the
life of the innocent. In cases where violation is very likely, one simply is
setting one’s will against the good. But when it is unlikely, one simply is
not.

**Objection** The above argument assumes that the disvalue of deaths varies
linearly in the number of deaths and that expected utility maximization is the
way to go.

**Response:** Vary the case. Imagine that there is a ticking bomb that has a
99% chance of being defective and a 1% chance of being functional. If it’s
functional, then when the timer goes off a million people die. And now suppose
that the only way to disarm the bomb is to do something that has a 1% chance
of violating a deontic constraint, with the two chances (functionality of the
bomb and violation of constraint) being independent. It seems plausible that
you should take the 1% risk of violating a deontic constraint to avoid a 1%
chance of a million people dying.

On “exemplar” theories of salvation, Christ’s work of the cross saves us by
providing a deeply inspiring example of love, sacrifice, or the like.

Such theories of salvation have the following unsavory consequence: they imply
that it would be possible for us to be saved by a monkey.

For imagine that a monkey typing on a typerwriter at random wrote a fictitious
story of a life in morally relevant respects like that of Christ, and people
started believing that story. If Christ saves us by providing an inspiring
example, then we could have gotten the very same effect by reading that
fictitious story typed at random by a monkey and erroneously thinking the
story to be true.

Of course, that’s just a particularly vivid way of putting the standard
objection against exemplar theories that they are Pelagian. I have nothing
against monkeys except that they are creatures, and so that if it is possible
to be saved by a monkey, then it is possible to be saved by creatures, which
is Pelagianism.

If there are certain conditions that people have to live by in order to he
saved, and some written texts presents exactly those conditions, then I don't
see why people living by those conditions would not be saved.

What we ought to conclude, I think, is that exemplar theories are bananas. :-)  
  
On a more serious note, one thing that I think a proponent of exemplar
theories could say in response is that a mere fictional story would not be
sufficiently inspirational. For example, consider the story of the Little
Engine That Could. This might inspire someone to persevere during a difficult
trial in life to some degree. But it likely wouldn't be a life-changing sort
of story. Such a person reading the story might say, "Yes, that is all well
and good and is somewhat encouraging, but it isn't as if there was actually a
Little Engine that came to belief in itself and accomplished a seemingly
impossible task." Or, perhaps a better example, consider the first Avengers
movie in which Tony Stark against all odds destroyed the Chitauri mothership,
nearly losing his life in the process. This might be somewhat inspirational,
for instance, to a soldier who finds himself going up against similarly dismal
odds. Nevertheless, it is likely that the soldier will also be somewhat
dismissive of the story as a source of inspiration because, after all, Tony
Stark is a fictional character who has his fictional Iron Man suit, something
that the soldier obviously does not have. What would be far more inspirational
to the soldier is a true story about the D-Day invasion and the bravery of the
soldiers who stormed the beaches of Normandy against dismal odds. If this line
of thought is right, then it seems that the exemplar theorist could insist
that the degree of inspiration necessary for salvation simply could not come
about unless the exemplar is real and not fictional. This would rule out the
monkey example. And, it could be further argued, the exemplar (or the cause
thereof) would have to be divine as only the divine could create a true story
that is sufficiently inspirational for salvation. Thus, we avoid Pelagianism.
How an exemplar theorist would proceed to spell all of this out, I have no
idea. But it is a line of argument they could take. I think a major issue,
however, that the exemplar theorist will inevitably run into is explaining why
it couldn't simply be the case that a fictional story could be sufficiently
inspirational for salvation so long as people *believed* it was true, which is
of course all that the monkey example involves. Perhaps it could be argued
that the story of the Gospel qua story could not have been produced but by
divine intervention and/or inspiration? I think that would be a difficult line
of argument to take, however.

I definitely agree that taking the story to be true is essential to its
effect. That's why I was imagining that the reader thought the monkey's story
was true.  
Maybe the exemplarist can say that the inspirational effect itself requires a
supernatural grace working in the heart to overcome our weakness, in addition
to the story. But then this grace had better come from the Cross, and the
story about this grace will not be exemplarist.

Suppose determinism and compatibilism are true. Imagine that a clever alien
crafted a human embryo and the conditions on earth so as to produce a human,
Alice, who would end up living in ways that served the alien’s purposes, but
whose decisions to serve the alien had the right kind of connection with
higher-order desires, reasons, decision-making faculties, etc. so that a
compatibilist would count them as right. Would Alice decisions be free?

The answer depends on whether we include among the compatibilist conditions on
freedom the condition that the agent’s actions are not intentionally
determined by another agent. If we include that condition, then Alice is not
free. But it is my impression that defenders of compatibilism these days
(e.g., Mele) have been inclining towards not requiring such a non-
determination-by-another-agent condition. So I will take it that there is no
such condition, and Alice is free.

If this is right, then, given determinism and compatibilism, it would be in
principle possible to produce a group of people who would economically
function just like slaves, but who would be fully free. Their higher-order
desires, purposes and values would be chosen through processes that the
compatibilist takes to be free, but these desires, purposes and values would
leave them freely giving all of their waking hours to producing phones for a
mega-corporation in exchange for a bare minimum of sustenance, and with no
possibility of choosing otherwise.

That's not freedom. I conclude, of course, that compatibilism is false.

Alex  
  
Compatibilism is the position that persons do something because they are who
they are.  
It's more complex, of course, but that's what it comes down to.  
I "choose" to write this post because I am a person who likes to discuss these
things. My wife doesn't post here, because she is not interested in discussing
this.  
Now, imaging libetarian free will were true. Then, all of a sudden, I could
"choose" to become a murderer or a rapist.  
I prefer to think that I am the kind of person who will never choose to rape
or murder.  
Yes, it would, in principle, be possible to produce a group of people who
would economically function just like slaves, but who would be fully free (in
the compatibilist sense). Those people would "choose" slavery because they
like being slaves. It's their decision based on who they are.  
You choose based on who you are, but you cannot choose who you are. That's
compatibilism, and you may not like it, but a libertarian is no better off.
Because if we have LFW, we "choose" on some other mysterious basis that we
have no more control over than over who we are.  

"freely giving all of their waking hours to producing phones for a mega-
corporation in exchange for a bare minimum of sustenance, and with no
possibility of choosing otherwise"  
  
One need not invoke `determinism` or `compatibilism` to assert that having
this happen consistently without lots of exceptions in a large group of
individuals is close to impossible. I doubt you could ever get this to work
reliably with a group of draft horses in all cases, starting with newborns and
following the group through training. At best you could select a few in a
large peer group that could remain performing to that specification for many
years.  
  
Biology makes things too unpredictable for such a production, free will or no.

William:  
  
We are assuming determinism and I am saying it's "in principle" possible. Of
course, we may have to control nearly every particle's position prior to the
person's birth.

If you have to control the position of every molecule, you are not really
using behavioral controls where reasons and motives matter. You have
determined the body's movements directly, without any need for motives.  
  
If you have decided to only determine the motives and tendencies, the biology
will still vary too much to allow the consistency the scenario requires as
outcome.

There are two ways of thinking about the ethics of consent.

On the first approach, there are complex prohibitions against non-consensual
treatment in a number of areas of life, with details varying depending on the
area of life (e.g., the prohibitions are even more severe in sexual ethics
than in medicine). Thus, this is a picture where we start with a default
permission, and layer prohibitions on top of it.

On the second, we start with a default autonomy-based prohibition on one
person doing anything that affects another. That, of course, ends up
prohibiting pretty much everything. But then we layer exceptions on that. The
first is a blanket exception for when the affected person consents in the
fullest way. And then we add lots and lots more exceptions, such as when the
the effect is insignificant, when one has a special right to the action, etc.

The second approach is interesting. Most ethical systems start with a default
of permission, and then have prohibitions on top of that. But the second
system starts with a default of prohibitions, and then has permissions on top
of that.

The second approach raises this question. Given that the default prohibition
on other-affecting actions is grounded in autonomy, how could anything but the
other’s consent override that prohibition? I think one direction this question
points is towards something I’ve never heard explored: divine permission
ethics. God’s permission seems our best candidate for what could override an
autonomy-based prohibition. So we might get this picture of ethics. There is a
default prohibition on all other-affecting actions, followed by two
exceptions: when the affected person consents and when God permits.

Alex  
  
 _"Given that the default prohibition on other-affecting actions is grounded
in autonomy, how could anything but the other’s consent override that
prohibition?"_  
  
The answer is simple: nothing can override that prohibition, not even a
hypothetical god. Because if god could do it, that would mean this prohibition
is _not_ grounded in autonomy.  
  
Take, e.g. rape. Rape is, by definition, prohibited based on the autonomy of
the victim. It's impossible to consent to being raped and god giving someone
permission to rape me, would not remove my autonomy.

I don't think that we have autonomy rights against God.  
  
(I think there is more wrong in rape than "just" violation of autonomy: There
is violation of autonomy in an especially sacred kind of context.)

Alex  
  
If we do not have autonome rights against God we don not really have autonome
rights at all.  
And whether they context is sacred it not is irrelevant. What is relevant is
consent. Consesual sex is not rape even though sex itself may be a sacred
context.

###  Having to do what one thinks is very likely wrong

Suppose Alice borrowed some money from Bob and promised to give it back in ten
years, and this month it is time to give it back. Alice’s friend Carl is in
dire financial need, however, and Alice promised Carl that at the end of the
month, she will give him any of her income this month that she hasn’t spent on
necessities. Paying a debt is, of course, a necessity.

Now, suppose neither Alice nor Bob remember how much Alice borrowed. They just
remember that it was some amount of money between $300 and $500. Now,
obviously in light of her promise to Bob:

It is wrong for Alice to give less to Bob than she borrowed.

But because of her promise to Carl, and because any amount above the owed debt
is not a necessity:

It is wrong for Alice to give more to Bob than she borrowed.

And now we have a puzzle. Whatever amount between Alice gives to Bob, she can
be extremely confident is either less or more than she borrowed, and in either
case she does wrong. Thus whatever Alice does, she is confident she is doing
wrong.

What should Alice do? I think it’s intuitive that she should do something like
minimize the expected amount of wrong.

How much is Alice left with, and what is the minimum she thinks she would have
borrowed? If she reasonably estimates that the minimum she borrowed is more
than she has left, all goes to Bob, no wrongs done. If she is still worried,
have Bob first promise that if the true amount is later revealed and she gave
him more than owed he will supply the excess to Carl.  
  
If there is money left after that minimum, and Alice worries that her choosing
a number is somehow ethically wrong (anyway, why?), let Bob and Carl negotiate
to decide on the number. That way Alice is not picking a wrong number.  
  
  

I’m curious whether one can infer the causal principle _C_ that everything
that comes into existence has a cause inductively on the basis of our
observations of things with causes.

There are a couple of issues with such an inference. First, let’s think about
the inductive evidence about causes globally. It seems to consist primarily in
these two observations:

we have found causes for many things that come into existence, but

there are many things that come into existence for which we have yet to find
causes.

It is worth noting that in terms of individuals, (b) vastly outnumbers (a).
Consider insects. Of the myriad insects that we come into contact daily, we
have found the causes of very few. Of course, we _assume_ that the others have
causes, causes that we suppose to be parent insects, but we haven’t _found_
the parents.

For observations (a) and (b) to support _C_ , these observations have to be
more likely on _C_ than on _C_ ’s negation. But now we have two problems.
First, on the negation of _C_ it doesn’t seem like we can make any sense of
the probability that some item has or does not have a cause. Causeless events
have no probabilities. Second, even if somehow assign such a probability, it
is far from clear that the observations of (a) and (b) are more to be expected
on _C_ than on not _C_.

Second, I suspect that often when we claim to have found _y_ to be the cause
of _x_ , our reason for belief that _y_ is the cause of _x_ depends on our
assumption of _C_. Our best candidate for a cause of _x_ is _y_ , so we take
_y_ to be the cause. But I wonder how often this inference isn’t based on our
dismissing the possibility that _x_ just has no cause.

None of this is meant to impugn _C_. I certainly think _C_ is true. But I
think the reasons for believing _C_ are metaphysical or philosophical rather
than inductive observation.

This could help furnish a response to Felipe Leon's pre-existing material
cause argument against creatio ex nihilo, which argues that we have the same
basis for believing all causation must involve a pre-existing material base as
we do for assuming that everything that comes into existence has a cause.  
  
On the other hand, in some of your writings you do appeal to inductive
arguments, namely that we would expect things to constantly pop into existence
without a cause if the causal principle were false, and so the orderliness of
nature is evidence against the possibility of things coming into existence.
Your point that we seem to reason from the causal principle to individual
cases of cause and effect is intriguing, and could maybe help justify both our
practices of causal reasoning and our obvious belief that things won't
suddenly start popping into existence uncaused.

Your penultimate paragraph suggests a new argument:  
  
(1) We are justified in inferring the existence of a parental cause for any
insects known to exist  
(2) If (1) is true, then C is true  
(3) Therefore, C is true.  

Another thought: I suspect that the inference to the existence of a cause is
on an epistemic par with an inference to the consistency of some event with
the laws of nature.  
  
For any of the unfathomably large number of episodes of motion I observe, how
on Earth do I know that they're actually consistent with the laws? Think of
the water falling from my shower head, the ambulance of an old man through a
doorway, or the slide of a coffee cup from the counter to my hand. Do I really
know that those motions were consistent with the laws instead of one of an
infinity of possible ways that could technically violate those laws? I don't
know the details of the motion, and I don't even know how to check if those
details - even if I knew them - were consistent with the laws. But I infer
that they are. This seems totally legitimate on whatever epistemic grounds
exist for the scientists who conclude what the laws are.  
  
Now, (a) and (b) become (a*) We know of many events that conform to the laws
and (b*) there are many events for which we have no idea if they conform to
the laws. All the same arguments seemingly can be run (with the exception of
the no probability argument) against the view that our nomic beliefs are
correct.  
  
It seems that the denial of our causal inferences are no worse off than our
nomic inferences.

Alex  
  
Nothing can come into existence because ex nihilo nihil fit.  
But even if this were possible, in order to inductively infer that something
coming into existence must have a cause, one must actually observe something
coming into existence as well as its cause.  
It is not enough that we obeserve causes for every single insect and every
other animal or plant, because all we have observed in that case is
transitions from one type of being to another, not the coming into existence
of a brand new being.  
  

Tom:  
  
I am OK with arguments from our expectations. Those are not inductive
arguments based on our observations of things having causes, but are _a
priori_.  
  
Regarding things popping into existence, I have come to feel the force of the
thought that no probabilities can reasonable be attached to such causeless
popping. But sometimes I argue concessively, granting that some probabilities
can be attached.

It seems to me that while (a) and (b) are indeed insufficient to inductively
ground C, in accordance with Dr Pruss' arguments, another observation I will
call (c) tips the balance. Here it is:  
  
We consistently find causes for individual things that come to be when we have
sufficient opportunity to investigate their origins. In other words, the set
of (a)-type things consistently grows at the expense of the other set as
knowledge of the things increases.

Fr Kirby:  
  
That's very interesting. Maybe then the way to respond to my point about
insects is this: when we've had "sufficient opportunity" to observe an insect
to such a degree that *if* it had parents then we would have been able to
identify them, then invariably we have identified the parents. And similar
conditionals are true for other things.

Yes, though I admit it might be difficult to define "sufficient opportunity"
in practice without smuggling in implicit assumptions that risk reducing the
inductive argument to circularity. In other words, if what allows us to judge
the sufficiency of opportunity to find a cause is related to how ever much
effort it takes to successfully find such a cause, my (c) becomes "We
consistently find causes for things that come to be when we have investigated
their origins up to the point when we find causes for them", which is
tautological.  
  
The trick would be to define "sufficient opportunity" rigorously without
unintentionally sneaking in the epistemic assumptions we are trying to ground.
And, even if we succeed in doing so, I suspect that in the real world, both
the common folk and academics, especially in science, are accepting C in
practice at least, and without such a strictly valid and non-circular
grounding. To put it another way, I believe there is at least as much
faith/intuition as reason (in the narrow sense) subjectively underlying both C
and the confidence in nomic inferences to which ASBB refers.

The physical Church-Turing (PCT) thesis says that anything that can be
physically computed can be computed by a Turing machine.

If generalized Molinism—the thesis that for any sufficiently precisely
described counterfactual situation, there is a fact of the matter what would
happen in that situation—is true, and indeterminism is true, then PCT seems
very likely false. For imagine the function _f_ from the natural numbers to
{0, 1} such that _f_ ( _n_ ) is 1 if and only if the coin toss on day _n_
would be heads, were I to live forever and daily toss a fair coin—with
whatever other details need to be put in to get the "sufficiently precisely
described". But only countably many functions are Turing computable, so with
probability one, an infinite sequence of coin tosses would define a Turing
non-computable function. But _f_ is physically computable: I could just do the
experiment.

But wait: I’m going to die, and even if there is an afterlife, it doesn’t seem
right to characterize whatever happens in the afterlife as _physical_
computation. So all I can compute is _f_ ( _n_ ) for _n_ < 30000 or so.

Fair enough. But if we say this, then the PCT becomes trivial. For given
finite life-spans of human beings and of any machinery in an expanding
universe with increasing entropy, only finitely many values of any given
function can be physically computed. And any function defined on a finite set
can, of course, be trivially computed by a Turing machine via a lookup-table.

So, either we trivialize PCT by insisting on the facts of our physical
universe that put a finite limit on our computations, or in our notion of
“physically computed” we allow for idealizations that make it possible to go
on forever. If we do allow for such idealizations, then my argument works:
generalized Molinism makes PCT unlikely to be true.

Perhaps "sufficiently precisely described" includes the value of n. Then the
function is no longer infinite, since we stop at the time for n.

Can there be determinism in some things and indeterminism in others?  
  
  

William  
  
Yes, that's possible, but it doesn't save molinism.

It sure seems like there is vagueness in moral obligation. For instance,
torture of the innocent is always wrong, making an innocent person’s life
mildly unpleasant for a good cause is not always wrong, and in between we can
run a Sorites sequence.

What view could a moral realist have about this? Here are four standard things
that people say about a vague term “ _ϕ_ ”.

Error theory: nothing is or could be _ϕ_ ; or maybe “ _ϕ_ ” is nonsense.

Non-classical logic: there are cases where attributions of “ _ϕ_ ” are neither
true nor false.

Supervaluationism: there are a lot of decent candidates for the meaning of “
_ϕ_ ”, and no one of them is _the_ meaning.

Standard epistemicism: there are a lot of decent candidates for the meaning of
“$”, and one of them is _the_ meaning, but we don’t know which one, because we
don’t know the true semantic theory and the details of our linguistic usage.

If “ _ϕ_ ” is “moral obligation”, and we maintain moral realism, then (1) is
out. I think (3) and (4) are only possible options if we have a watered-down
moral realism. For on a robust moral realism, moral obligations really central
to our lives, and nothing else could play the kind of central role in our
lives that they do. On a robust moral realism, moral obligation is not one
thing among many that just as well or almost as well fit our linguistic usage.
Here is another way to put the point. On both (3) and (4), the question of
what exact content “ _ϕ_ ” has is a merely verbal question, like the question
of how much hair someone can have and still be bald: we could decide to use
“bald” differently, with no loss. But questions about moral obligation are not
merely verbal in this way.

This means that given robust moral realism, of the standard views of vagueness
all we have available is non-classical logic. But non-classical logic is just
illogical (thumps table, hard)! :-)

So we need something else. If we deny (1)-(3), we have to say that ultimately
“moral obligation” is sharp, but of course we can’t help but admit that there
are Sorites sequences and we can’t tell where moral obligation begins and ends
in them. But we cannot explain our ignorance in the semantic way of standard
epistemicism. What we need is something like epistemicism, but where moral
obligation facts are uniquely distinguished from other facts—they have this
central overriding role in our lives—and yet there are moral facts that are
likely beyond human ken. One might want to call this fifth view “non-standard
epistemicism about vagueness” or “denial of vagueness”—whether we call it one
or the other may just be a verbal question. :-)

In any case, I find it quite interesting that to save robust moral realism, we
need either non-classical logic or something that we might call “denial of
vagueness”.

In physics, we hope for the following unification: there is a small set of
simple laws, and all the rest of physics derives logically from these laws and
the contingencies of the arrangement of stuff.

In ethics, a similar ideal has often manifested itself. While I have a hope
for the ideal being realized in physics, I have come to be more pessimistic
about the ideal in ethics. Instead, I think we can have a looser unificatory
structure. We can have a multilevel hierarchy of more general laws, and then
more specific laws that specify or implement the more general laws.

I suspect the looser structure is what we have in Aquinas’s Natural Law. At
the highest level we have the general law that the good is to be pursued and
the bad to be avoided. This is then specified into three laws about promoting
the goods of existence, species-specific life and reason. These three laws, I
think, are then further specified.

There is thus a structure to the moral law, but it is not a deductive
structure. The higher level laws make the lower level laws _fitting_ , but do
not necessitate them.

Agreed. In mathematics and you hope physics we have deductive structure. But
as we move through chemistry to biology the "laws" become less and less tied
to underlying principles. You will not derive mammalian behavior from rules at
the level of cellular metabolism such as RNA transcription, for example.
Social sciences are even less tied to simpler structures. I suppose ethical
rules are in that category.  
  
Should we have expected "Natural Law" to be different from the rules in other
social sciences, such as jurisprudence, or is that a false expectation caused
by the use of the words "natural" and "law" because of their very different
meaning in the context of mathematics or physics?  

In One Body: An Essay in Christian Sexual Ethics, I recall you arguing for a
'strong ethics of love' such that all moral facts in some sense follow from
the fundamental duty to love (or even that they are this duty taking other
forms). It's been a while since I read that chapter, but that seems like a
tighter unificatory structure than you're posing here, so have your views
changed since then or is a strong ethics of love compatible with this looser
structure?

For physics, is ‘contingencies of arrangements of stuff’ enough? I would think
we would also need ‘contingencies of _kinds_ of stuff’. So if there were a
particle just like an electron but with a charge sqrt(2) times as big, the
laws of physics might still be the same but the behavior of matter would be
very different. If so, I’m not sure the moral laws are all that different. You
might not be able to derive all the moral laws pertaining to human animals
straight from the categorical imperative alone (or whatever other law you take
to be fundamental), but you can (can’t you?) derive it from a combination of
the categorical imperative and a sufficiently detailed understanding of the
nature of the human species. What would be the problem with saying that?

TreyTable:  
  
But what makes a particular form of love fitting to a particular lover and
beloved's nature may not be encompassed by a simple set of rules.  
  
Matthew:  
  
I think one would need not just the descriptive facts about the human species,
but the normative ones. And these would include normative facts about the
will, and those will include the moral facts.

Pruss, for your response to Matthew -- is the idea that all facts are
normative but not all normative facts give us practical reason to pursue or
promote them?  

Daryl:  
  
I was just thinking that Matthew's "sufficiently detailed understanding of the
nature of the human species" would require not just a descriptive but also a
normative understanding. For instance, it's important that not only do humans
tend to have hearts and lungs, but that they ought to have them.

###  A strict propriety argument for probabilism without any continuity
assumptions

Here’s an accuracy-theoretic argument for probabilism (the thesis that only
probabilities are rationally admissible credences) on finite spaces that does
not make any continuity assumptions on the scoring rule. I will assume all
credence functions take values on [0,1].

A rationally appropriate scoring rule _s_ satisfies strict propriety for all
rationally admissible credences with an appropriate prevision: if _V_ is an
appropriate prevision then _V_ _u_ _s_ ( _u_ ) is better than _V_ _u_ _s_ (
_v_ ) whenever _u_ and _v_ are different rationally admissible credences.

On any finite space _Ω_ with at least two points, no scoring rule satisfies
strict propriety for the credences with Normalization and Subadditivity and
level set integral prevision.

Is this a good argument? I find (2) somewhat plausible—it’s hard to think of a
less problematic weakening of the axioms of probability than from Additivity
to Subadditivity, and I have not been able to find a better prevision than the
level set integral one. Standard arguments for probabilism assume strict
propriety for all probabilities. But it seems to me that a non-probabilist
will find strict propriety for all probabilities plausible only insofar as
they find strict propriety for all admissible credences plausible. Thus (3) is
dialectically as good as the usual strict propriety assumption.

I think the non-probabilist’s best way out is to deny strict propriety or to
deny that there is a rationally appropriate scoring rule. Both of these ways
out work just as well against more standard arguments for probabilism, and I
think both are good ways out.

Technically speaking, the advantage of this argument over standard arguments
for probabilism is that it makes no assumptions of continuity.

A number of comments from a commenter who has been banned have been deleted.
If a banned commenter wishes to be reinstalled, they should email me
explaining their plan for avoiding the sorts of things that led to the ban.

I used to take it for granted that it’s reasonable to make epistemic utilities
be continuous functions of credences. But this is not so clear to me right
now. Consider a proposition really central to a person’s worldview, such as:

I think a case can be made that if a proposition like that is in fact true,
then there is a discontinuous upward jump in epistemic utility as one goes
from assigning a credence less than 1/2 to assigning a credence more than 1/2.

Alexander Pruss, “Three mysteries of the concrete: Causation, mind and
normativity”, Christian Philosophy 2022, online, Cracow, Poland, September,
2022.

I now think that complicity doesn’t solve the problem, because we can imagine
case where there is no relevant evildoer. Take a trolley problem where the
trolley is coming to a fork and about to turn onto the left track and kill
Alice. There is no one on the right track. So far this is straightforward and
doesn’t involve Double Effect at all—you should obviously redirect the
trolley. But now add that if Alice dies, four people will be saved with her
organs, and if Alice lives, they will die.

Among the results of redirecting the trolley, now, are the deaths of the four
who won’t be saved, and hence Double Effect does apply. To save one person at
the expense of four is disproportionate, and so it seems that one violates
Double Effect in saving the one. And in this case, a failure to save Alice
would not involve any complicity in anyone else’s evildoing.

It is tempting to say that the deaths of the four are due to their medical
condition and not the result of trolley redirection, and hence do not count
for Double Effect proportionality purposes. But now imagine that the four
people can be saved with synthetic organs, though only if the surgery happens
very quickly. However, the only four surgeons in the region are all on an
automated trolley, which is heading towards the hospital along the left track,
is expected to kill Alice along the way, but will continue on until it stops
at the hospital. If the trolley is redirected on the right path, it will go
far away and not reach the hospital in time.

In _this_ case, it does seem correct to say that Double Effect forbids one
from redirecting the trolley—you should not stop the surgeons’ trolley even if
a person is expected to die from a trolley accident along the way. (Perhaps
you are unconvinced if the number of patients needing to be saved is only
four. If so, increase the number.) But for Double Effect to have this
consequence, the deaths of the of the patients in the hospital have to count
as effects of your trolley redirection.

And if the deaths count in this case, they should count in the original case
where Alice’s organs are needed. After all, in both cases the patients die of
their medical condition because the trolley redirection has prevented the only
possible way of saving them.

Here’s another tempting response. In the original version of the story, if one
refrains from redirecting the trolley in light of the people needing Alice’s
organs, one is intending that Alice die as a means to saving the four, and
hence one is violating Double Effect. But this response would not save Double
Effect: it would make Double Effect be in conflict with itself. For if my
earlier argument that Double Effect prohibits redirecting the trolley stands,
and this response does nothing to counter it, then Double Effect both
prohibits redirecting and prohibits refraining from redirecting!

I think what we need is some careful way of computing proportionality in
Double Effect. Here is a thought. Start by saying in _both_ versions of the
case that the deaths of the four patients are _not_ the effects of the trolley
redirection. This was very intuitive, but seemed to cause a problem in the
delayed-surgeons version. However, there is a fairly natural way to reconstrue
things. Take it that leaving the trolley to go along the left track results in
the _good_ of saving the four patients. So far we’ve only shifted whether we
count the deaths of the four as an evil on the redirection side of the ledger
or the saving of the four as a good on the non-redirection side. This makes no
difference to the comparison. But now add one more move: don’t count goods
that result from evils in the ledger at all. This second move doesn’t affect
the delayed-surgeons case. For the good of saving lives in that case is not a
result of Alice’s death, and the proportionality calculation is unaffected. In
particular, in that case we still get the correct result that you should not
redirect the trolley, since the events relevant to proportionality are the
evil of Alice’s death and the good of saving four lives, and so preventing
Alice’s death is disproportionate. But in the organ case, the good of saving
lives _is_ a result of Alice’s death. So in that case, Double Effect’s
proportionality calculation does not include the lives saved, and hence, quite
correctly, we conclude that you _should_ redirect to save Alice’s life.

Suppose you are visiting a hospital and you see Bob, a nurse, sneaking into
Alice’s hospital room. Unnoticed, you look at what is going on, and you see
that Bob is about to add a lethal drug to Alice’s IV, a drug that would
undetectably kill Alice while leaving her organs intact. You recall with
horror that two days ago you had a conversation with Bob and he described to
you how compelling he finds the argument that it is sometimes obligatory to
kill one patient in order to provide organs to save multiple other patients,
when this can be done secretly. At the time, you unsuccessfully tried to
persuade Bob that the consequentialism behind the argument was implausible.
You happen to know that if Bob were to die right now, then four people could
be saved. You could now yell, push Bob away, and prevent Alice’s murder.

Here is a Double Effect argument that you shouldn’t stop the murder. Your
action of pushing Bob away has two sets of effects: (a) Alice isn’t murdered
and (b) four patients who would be saved by Alice’s organs die. Of these, (a)
is an intended good and (b) is an unintended evil. So your action is an action
to which Double Effect is relevant: it is an action with two effects, an
intended good and an unintended evil. But Double Effect makes it a necessary
condition for the permissibility of an action that the evils not be
disproportionate to the goods. And here the evils _are_ disproportionate to
the goods. So you shouldn’t stop Bob, it seems.

Now, one might question the proportionality judgment. Maybe while four deaths
are disproportional to one death, four _deaths_ are not disproportionate to
one _murder_? This is mistaken, however. For suppose you see an assassin
trying to murder someone with a long-range shot, and you see four innocent
people near the assassin. The only way you have to stop the assassin is with a
hand-grenade, which would kill the four innocents as well. It is clear that
four _deaths_ of innocents are disproportionate to the one murder: you should
not stop the murder by blowing up the assassin.

Suppose you bite the bullet and agree that you shouldn’t stop Bob. Then I have
an even more problematic version. Go back to your disquieting conversation
with Bob about killing patients for their organs. Suppose that Bob disclosed
to you in the course of that conversation that it wasn’t a merely hypothetical
question, as you assumed, but that he was actually planning on acting on it.
It seems completely clear that you should try to persuade him out of this
murderous plan. But the exact same Double Effect argument seems to apply here:
There are two sets of effects of your persuading Bob not to do it—one person
isn’t murdered and a number of people die. The bad effects are
disproportionate to the good ones, so Double Effect seems to prohibit you from
persuading Bob out of his plan.

Maybe though this second case is different from the first, in that it is one
of the basic tasks of a fellow human being to persuade others to act well—this
is a central part of our human communal interaction. So it may be that once we
take into account the good of persuading others to act well, and add that good
to the intended goods, now the four deaths are no longer disproportionate. But
now increase the numbers. Perhaps Alice has some weird mutation in her heart
tissue such that culturing her heart tissue would save a thousand lives. Now
the death of a thousand seems clearly disproportionate to preventing one
murder _and_ obtaining the goods of persuading others to act well. Imagine
that I had a choice between preventing an explosion that would completely
destroy a ship with a thousand people on board and persuading someone not to
commit an “ordinary” murder. I should prevent the sinking of the ship. Yet
even in the thousand patient case I have the intuition—admittedly, now
weaker—that I should try to persuade Bob not to murder Alice, or at least that
it is permissible to do so. Especially if Bob is my friend.

What’s going on? Is it the case that when we consider the good of persuading
someone to act well, we should not count against that any goods that would
result from their acting badly? Is it—a graduate student suggested this to
me—that if I fail to persuade them to act well _in order_ to obtain the goods
that would result from their act badly, then I become _complicit_ in their bad
action? I think there is something to this idea. It may even apply in my
earlier case of not stopping Bob physically from the murder, but it seems
particularly plausible in the case of refraining to persuade.

In any case, if I am right that it is right to persuade Bob out of his plan to
murder Alice, we really do need to understand the proportionality condition in
Double Effect very carefully. That condition seems to become significantly
context-sensitive. Double Effect is not a simple structural principle by any
means.

**Objection:** When it’s a matter of stopping Bob’s murder of Alice, you don’t
_cause_ the deaths of the patients who need Alice’s organs to live. The
patients die of whatever conditions they die of, rather than from your action.  
So those deaths don’t figure in the Double Effect proportionality calculus.

**Response:** Imagine that I could stop an ordinary murder, but to do that I
would have to park my car in a place that would block an ambulance from
getting to the scene of an unrelated accident, where a number of people would
die of their injuries if the ambulance were not to get there in time. When
considering my action of parking my car, I _do_ need to consider the deaths of
the people the ambulance would save, even though they die from their injuries
rather than from my action. If the number of people the ambulance would save
is large enough, I ought not block the ambulance’s path to prevent one murder.

Another option is to defend Alice with a lethal blow to Bob's head. Which then
allows you to save the other lives too.

Alex,  
  
If you do push Bob away merely to save Alice, all deaths are side-effects but
if you don't, formal cooperation lurks if you are refraining to benefit
transplant recipients. Maybe I'm missing something but this looks as if you
share Bob's plan - both his end (lives saved with Alice's organs) and his
means (Alice killed by Bob).  
  
In contrast, take another case: Police Officer Olly who omits to intervene to
stop a riot in a suburb, because doing so will merely drive the rioters into
the inner city area. Intervening would be futile overall in that it would
merely result in more rioting and homicides.  
  
Olly is not like another police officer, George, who intends that deaths occur
in the suburbs - say, as a warning to the inner city. Olly omits to protect
the suburb not to enable suburb homicides but simply because intervening would
do more harm than good. True, Olly plans to benefit the inner city by his non-
intervention, at least in the sense that he eschews what does them harm, but
he is not 'using' the suburb like Bob is using Alice or you seem to be using
Alice if you let Bob go ahead precisely so organ recipients can live.  
  
To make the transplant case more like Olly - imagine your non-intervention is
simply motivated by an intention that Bob not run amok in the children's ward.
Again, intervening is futile overall - Bob has powerful friends who work in
the children's ward and though you would save Alice, several children would be
killed for their organs.  
  
Here you share none of Bob's wrongful plans to achieve what you nonetheless
welcome in failing to intervene: the saving of lives with Alice's organs. You
are intending to save children, not intending to enable Bob to save adults by
killing Alice.  

Helen:  
  
In the Bob and Alice case, it seems that if you don't stop Bob, you need not
have any plan besides "Don't violate Double Effect!" It seems you are
refraining from stopping Bob precisely because stopping Bob would violate
proportionality in Double Effect.

entirelyuseless:  
  
Yeah, but if you use lethal force to stop Bob when non-lethal force would do
the job, now it looks like you're murdering Bob.

Some people think that a constituent (whole or partial) of consent is some
sort of inner mental act of agreement with the thing one consents to. Here is
an argument against this:

A request or command does not require an inner mental act of agreement.

So, consent does not require an inner mental act of agreement.

(One can also qualify the requests, commands and consents as valid in all the
premises, and the argument remains sound, I think.)

That said, consent does require _some_ inner component, as does request or
command. Consent requires a relevant communicative act to be performed
_intentionally_. Similarly, to request or command something is not just to
utter some sounds (or make some gestures, etc.), but to do so intending to be
taken as requesting or commanding.

Alex  
  
I am not sure about your first premise. Why would anyone request or command
something they don't agree with?

I’m having a hard time seeing what is being denied here.  
Suppose I request that you “bring me a cup of coffee” and thereby consent to
your bringing me a cup of coffee. Do we need to ask a further question about
whether I have also _agreed_ to your bringing me a cup of coffee? What would
that further question mean?

Matthew:  
  
As I understand the opposite view, consent requires some sort of attitude of
okayness about the thing one is consenting to. On some versions of the view,
the attitude is necessary and sufficient (and the communicative act is just
evidence of the attitude), and on others, it is necessary.  
  
Walter:  
  
You may think it's your duty to command something but hope that the command
will be disobeyed. It's easy to imagine examples.  
  
Or you are trying to embarrass a bartender by ordering an obscure drink you
don't want and which you hope they won't be able to prepare. Nonetheless, if
the bartender can prepare said drink, you've consented to it.

Some people think that an outcome of an action foreseen with practical
certainty is also intended. If so, then pretty much every case where someone
writes “pun not intended” is a case where what they write is false. For one
foresees with practical certainty that by disseminating the message one is
punning.

I sometimes say "no pun intended" when I don't see one there. Just in case.  
  
No Pun Intended.

Alex  
  
If someone writes 'no pun intented' then they mean that when they were writing
the words they were not intending the pun, IOW,. they did not foresee with
practical certainty that what they we're writing could be seen as a pun.

Walter:  
  
I think not always. Sometimes one writes something and there is no way,
without excessive awkwardness, of expressing something without a pun. You're
writing a history piece about how many scientists in the 19th century came
from the nobility, and then you need to mention some experiments about noble
gases. What can you do?

Alex  
  
'Sometimes' is not the same as 'in pretty much every case.'

Yeah, but in most of the remainder of the cases, even though I didn't foresee
that I would be punning by writing the text, once I noticed the pun, I foresaw
that I would be punning by "disseminating" the text (say, by clicking on
"Publish").

Yes, but in that case, the pun is intended., and what 'no pun intended'
actually means is, 'When I originally wrote these words, I did not intend them
as a pun.'  
Let's say you come to visit me and I prepare a meal for you. When the meal is
ready, I realize that, instead of salt, I accidently used a toxic powder. Yet
I still give you the meal(obviously, I don't eat).  
Would you say I did not intend to poison you?

On Mill-Ramsey-Lewis accounts of laws of nature, the laws are the propositions
that best balance informativeness and brevity (in a language that cuts nature
precisely at the joints).

Now, the laws of nature include constants, such as the fine-structure constant
whose current best measured value is 1/137.035999206. Now, we might be lucky,
and it might turn out that the fine-structure constant will have some neat and
elegant precise value. There is a history of speculation that it has such a
value—for a while, there was hope it was exactly 1/137, and then other guesses
took over. But suppose we don’t get so lucky. Suppose it just is some messy
number with no simple expression. That should, after all, be a serious
possibility.

In that case, the exact value of the fine-structure constant cannot be a part
of the Mill-Ramsey-Lewis “world in a nutshell” system of laws, since the
system would then be infinitely long, and we lose our hope of defining laws in
terms of brevity.

So that moves us to the second option, which is that the laws are of the form
∃ _α_ _F_ ( _α_ ) and _F_ ( _α_ ) includes some constraints on _α_ , such as
that it lies between 1/137.04 and 1/137.03. These constraints are sufficiently
tight to generate the nomic implications we need for chemistry and biology.
But while this result seems a better fit for science, it is metaphysically
very strange. For it is very strange to think that the laws allow the fine-
structure constant to have any of an infinite number of values, but these
values _must_ lie in a narrow range.

Furthermore, the exact narrow range for _α_ would be determined by fine
details (I am not sure if the pun is intended) of exactly how informativeness
and brevity are balanced in the definition of the laws.

The same issue comes up for other constants in the laws of nature. Either
Mill-Ramsey-Lewis laws do not include anything about the values of constants
or else they include oddly specific, but not completely specific, ranges.

That said, I think this falls in the general category of speculative arguments
about what God would be expected to create, alongside such arguments as that
we would expect God to create a multiverse, or Leibniz’s idea that we would
expect a world that is infinitely nested in both the macro and the micro
directions. Such arguments need to be extremely tentative.

Intriguing thought (could this affect whether chairs are logical objects? I
wonder ;-)

Why do you say that God has made all things in His image? In Scripture only
men are said to be made in the image of God. Depending on how we take "image
of God" we might be warranted in applying it to angels. (I think not.)  
  
Without that premise, your speculative argument seems even weaker, at least
from a Christian perspective.  
  
What do you think?

God is the Good Itself. Everything God made is good, and hence an image of the
Good Itself.

There is something attractive about an ontology where all the properties are
powers, but it seems objectionable.

First, a power is partly defined by the properties it can produce. But if
these in turn are powers, then we have a vicious regress or circularity.

At the same time, mental properties do not seem to be purely powers: they seem
to have a categorical qualitative character that is not captured by the power
to produce something else.

What is attractive about a pure powers ontology is the conceptual simplicity,
and the fact that categorical properties seem really mysterious.

There is, however, a modification we can make to a pure powers ontology that
gets us out of the problem. There are two kinds of properties: powers and
qualia. The mysteriousness objection does not apply to qualia, because we
_experience_ them. On this ontology, powers bottom out in the ability to
produce qualia.

For this to avoid implausible anthropocentrism, we need panpsychism—only then
will there be enough qualia outside of living things for the powers of
fundamental physics to bottom out in. So we have an interesting motivation for
panpsychism: it yields an attractive ontology for reasons that have nothing to
do with the usual concerns in the philosophy of mind.

It’s worth noting that this ontology is similar to Leibniz’s. Leibniz had two
kinds of properties: appetitions and perceptions. The appetitions are
(deterministic) powers. Perceptions are similar to qualia, but not quite the
same, because (a) perceptions need not be conscious, and (b) perceptions are
always representational. Unfortunately, the representational aspect leads to a
regress or circularity problem, much as the power powers ontology did, since
representationality will define a perception in terms of other appetitions and
perceptions.

Suppose that determinism is true and Alice is about to roll a twenty-sided die
to determine which of twenty innocent prisoners to murder. There is nothing
you can do to stop her. You are in Alice’s field of view. Now, a die roll,
even if deterministic, is very sensitive to the initial conditions. A small
change in Alice’s throw is apt to affect the outcome. And any behavior of
yours is apt to affect Alice’s throw. You frown, and Alice becomes slightly
tenser when she throws. You smile, and Alice pauses a little wondering what
you’re smiling about, and then she throws differently. You turn around not to
watch, and Alice grows annoyed or pleased, and her throw is affected.

So it’s quite reasonable to think that whatever you do has a pretty good
chance, indeed close to a 95% chance, of changing which of the prisoners will
die. In other words, with about 95% probability, each of your actions is akin
to redirecting a trolley heading down a track with one person onto a different
track with a different person.

The Alice case is highly contrived. But if determinism is true, then it is
very likely that many ordinary actions affect who lives and who dies. You talk
for a little longer to a colleague, and they start to drive home a little
later, which has a domino effect on the timing of people’s behaviors in
traffic today, which then slightly affects when people go to sleep, how they
feel when they wake up, and eventually likely affects who dies and who does
not die in a car accident. Furthermore, minor differences in timing affect the
timing of human reproducive activity, which is likely to affect which sperm
reaches the ovum, which then affects the personalities of people in the next
generation, and eventually affects who lives and who dies. Thus, if we live in
a deterministic world, we are constantly “randomly” (as far as we are
concerned, since we don’t know the effects) redirectly trolleys between paths
with unknown numbers of people.

Hence, if we live in a deterministic world, then we are all the time in
trolley situations. If we think that trolley redirection is morally wrong,
then we will be morally paralyzed all the time. So, in a deterministic world,
we better think that it’s OK to redirect trolleys.

Of course, science (as well as the correct theology and philosophy) gives us
good reason to think we live in an indeterministic world. But here is an
intuition: when we deal with the external world, it shouldn’t make a
difference whether we have real randomness or the quasi-randomness that
determinism allows. It really shouldn’t matter whether Alice is flipping an
indeterministic die or a deterministic but unpredictable one. So our
conclusions should apply to our indeterministic world as well.

Trolley problems test the intuition that actively causing harm is worse than
passively failing to prevent it. Should you intervene and cause one death, or
stand aside and permit five?  
  
I’m not seeing any such issue in the Alice case. Granted, anything you do (or
choose not to do) could change which prisoner gets shot. But nothing you can
do can change the probability (as judged by you, before the event, knowing
everything relevant that it is possible for you know) of any particular
prisoner being shot – it’s 1/20, whatever you do. There is a moral issue – you
are inadvertently and inescapably involved in a murder – but no issue of moral
choice.

It seems like Alex has illustrated here that the problem of evil is even worse
than we thought.  
We are stuck in a world filled with evil, and we cannot do anything about it.  
This doesn't sound like the creation of a perfectly good God  

Walter:  
  
I think we already knew we were in a world filled with evil we can't knowingly
do much about. Does it add much to that that we have some inscrutable effects
on the evils? Are such inscrutable effects morally relevant?

Ian:  
  
I think the following three problems are morally equivalent:  
  
1\. A one-one trolley where the two people are strangers hidden behind
curtains and they are already on the tracks.  
  
2\. A one-one trolley where the two people will be dropped on the track
moments after your decision time, and the choice of which person will go on
which track was already made by means of a deterministic coin toss you know
nothing about.  
  
3\. A one-one trolley where the two people will be dropped on the track
moments after your decision time, and the choice of which person will go on
which track will be made by means of a deterministic coin toss you know
nothing about.  
  
Now, in cases 2 and 3, it's still true that "nothing you can do can change the
probability (as judged by you, before the event, knowing everything relevant
that it is possible for you know) of any particular [person] being [killed by
the trolley -- it's [1/2], whatever you do." So if you think that the Alice
case doesn't raise a "moral choice", you should think the randomized one-one
trolley in 2 and 3 doesn't raise a moral choice. But I don't see any moral
difference between 1 and 2. It surely makes no difference whether the
strangers are already on the tracks, if there is a fact of the matter as to
which one will be where.

Alex  
  
If what we do or don't do makes no real difference, there is no objective
morailty.  
And maybe _you_ know we are in a world filled with evil we can't knowingly do
much about, but I am not so sure about it. _My_ morailty is based on the idea
that I can do something about it.

As I see it, the point of trolley problems is to test our intuitions about
intervention. In the Alice case, you can’t not intervene, but there is no
intervention that could change your expectations (before the event) about the
outcome. So any intuitions you may have about intervention are irrelevant.  
  
In cases 2 and 3 (unlike in the Alice case) you can choose to intervene or
not, but (as in the Alice case) your choice will not change your expectations.
People who think that intervention is in itself bad (other things being equal)
will not intervene. Those who don’t will be indifferent.  
  
In case 1, your choice will change your expectations – you can choose to save
either ‘the stranger on the main track’ or ‘the stranger on the side track’.
But since they are both strangers, you are indifferent between these outcomes.
The conclusion is the same as for cases 2 and 3, _but the reason is
different_.  
  
Some interesting questions. Would it make a difference to case 1 if there were
no curtains, and you could see both people as individuals, albeit strangers?
What if you recognized one person (maybe she is your daughter) but not the
other? What if you recognized both people? These cases seem to raise issues
that don’t apply to similarly modified versions of 2 and 3.

Ian:  
  
"In case 1, your choice will change your expectations – you can choose to save
either ‘the stranger on the main track’ or ‘the stranger on the side track’."  
  
In cases 2 and 3, you can do pretty much the same thing, except that it's "the
stranger who has been selected by the coin toss to be on the main track" or
"the stranger who has been selected by the coin toss to be on the side track".  
  
In the Alice case, you've got a 95% chance of saving "the stranger who will
die if you don't frown".

Walter:  
  
I said that the world is filled with evil we can do nothing about, but not
that the world is filled ONLY with such evil. There is also a lot of evil we
CAN do something about.

Alex  
  
We can intend to do something about some evils, but we can never be sure we
actually do something about thema.  
Say we see somebody in who is about to drown the middle of a pond, we can save
him, but who is to say drowning is evil?  
Maybe that same man is a serial killer and as a result of me saving him, 10
people will be killed  
  

  
Uh, hellooooo!  
Alice doesn't live here any more.  
  
  
  
.

I’m getting convinced that pain, or even physical pain, is a category that
does not cut nature at the joints. Consider that the taste of mouldy bread is
more unpleasant than a typical vaccination jab, but the jab is physically
painful while the taste is not. So neither are all physical unpleasantnesses
pains, nor is it even the case that pains are distingushed from other
unpleasantnesses by intensity. (That said, it is likely true that among
physical sensations, the very most unpleasant ones are all pains.)

So, pains seem to be a subtype of displeasures. Is it a subtype that cuts
nature at the joints? If we could say that pain just is tactile displeasure,
then that would help. But not all tactile displeasure is pain. If I have a
calloused hand and I move it against a fuzzy cloth and feel the callouses
catching on the cloth, that’s definitely unpleasant—but not the least painful.
So only some tactile unpleasantnesses are pain.

What unifies the tactile unpleasantnesses that are pains? Is there a common
feel that all the pains have and that the other unpleasantnesses don’t? I
doubt it. A burning pain and a dull ache feel quite different, and what they
have in common appear to be (a) their tactile nature and (b) their
unpleasantness. But (a) and (b) do not distinguish pains from other tactile
unpleasantnesses.

This point is even clearer if we do not limit ourselves to physical pain. For
the pain of embarrassment is, if anything, closer to disgusting taste than to
stabbing pain.

All this suggests to me that pain is not a useful philosophical category.
Unpleasantness or displeasure _is_ a useful category. Specific types of
unpleasantness, some of which are pains, are also useful categories. But pain
as such is not.

"pain is not a useful philosophical category"  
  
I am curious here. I would tend to call pain a "symptom" which is in this case
a kind of body signal, with pain usually but not always a distress signal. But
you are utilizing the term "pain" in another way here, I think.  
  
What does it mean for a thing such as a pain to be useful in philosophical
discourse? Is it useful in creating statements that can have some sort of
quantifiable ethical value that can be balanced versus other ethical
categories? What are other uses of such things as a "useful philosophical
category"?

William:  
  
Pain is what you feel when you hurt. :-)  
  
Why might it be useful? Well, you might think there is a moral presumption
against pain (i.e., presumptively you shouldn't cause it but you should
relieve it). Or you might be interested in the philosophy of mind and try to
figure out what functional states underlie or define pain. Or you might think
that a theodicy for pain is specifically called for.  
  
And my suggestion is that in all these cases, we would get something more
illuminating if we used a broader category than pain, even if the statements
about pain are correct.  
  
Compare this. It is true to say that it is wrong to torture Poles. But it is
not very illuminating. It is much more illuminating to say that it is wrong to
torture humans. For it is wrong to torture Poles because it is wrong to
torture humans. To focus the discussion of torture on why it's wrong to
torture Poles would not be useful.

So "pain" is too specific for the uses you have given, since it can be
replaced by generic moral value in one context and generic sensation in
another. I suppose that being more specific than that aids in visualizing the
scenario but might mislead if it led to a too-specific objection. Thanks.

Suppse that I had a device that would cause a mild but sensible vibration in
the nasal membranes of the person I pointed it at. Absent consent or a
significant reason, it would be wrong to use this device on a stranger.

But the same is not true if we replace nasal membranes with the tympanic
membrane: we routinely vibrate the tympanic membranes of strangers with
neither consent nor significant reason, say when we ask a stranger on the
street for directions.

In both cases one is inducing a physical change of arrangement of body parts
in the other person without their consent. We may suppose that hedonically
there is no difference: perhaps the vibration and the speech are both mildly
unpleasant. The case can be tweaked so that the impact on autonomy is greater
in either case (e.g., the unwilling listener may identify themselves as the
sort of person who doesn’t listen to arguments) or so that it is equal.

It is tempting to say that we have a default consent to hearing others out.
But default consents can be withdrawn, and we are permitted to vibrate
tympanic membranes even _against_ the express directions of their possessor.
If during an argument someone says “I don’t want to hear another word!” it is
not morally wrong to respond verbally nonetheless.

This implies that the need for consent does not supervene on hedonic or
autonomy facts. It depends on details of the intervention that go beyond
these.

The fact that in my thought experiment an apparatus is used in the nasal but
not the aural case is not relevant. If one speaks through a speech generating
device, as famously Hawking did, one is no less permitted to vibrate
strangers’ tympanic membranes with the speech. And it would be just as wrong
to go up to strangers and blow air into their nostrils in order to vibrate
their nasal membranes as to use a device.

The difference, I think, is that it is a part of the proper function of the
tympanic membrane to receive speech from random strangers, whether one
consents to this or not, while the nasal membranes have no such proper
function. It is as if our human nature gives permission to others to speak to
us, but does not give such a permission for nasal membrane vibration.

I think this is difficult to account for in anything other than natural law or
divine command ethics.

It occurs to me that natural law has an alternate way to capture this: instead
of it being an issue of proper function, it could be an issue of flourishing.
Maybe nasal autonomy is a part of our flourishing but not aural autonomy?

I think the issue might be the nature of the contact being social vs. non-
social which matters. Imagine a similar device which caused a stranger to have
their ear membranes tingled in a way such that they hear the sounds of someone
saying "Excuse me sir, could you tell which way Main Street is?", even without
anyone making that utterance. It would be immoral to use that device. However,
it's fine to stimulate nasal membranes of strangers, even on a crowded bus
when you've just come back from a heavy workout at the gym.  
  
It seems that membrane stimulations which result from normal human social
interactions are fine, and non-social stimulations are what cause trouble. I
suspect that normal deontology and probably utilitarianism can tell a story
about this.

Good point about normal social interaction. But note the "normal". Here I
think we need something like human nature to explain that. For mere
statistical or socially defined normalcy will not do. Imagine a society where
commoners do not speak to nobles. It's nonetheless morally permissible. I want
to say it's normal for any human to be able to speak to any other within
earshot (subject to reasonable constraints, such as not waking the sleeping
without good reason).

I really do not see what the issue is here.  
"Normal" is explained by the way human beings evolved and still do evolve.
Humans have evolved to be social beings. They might also have evolved in
another way, as completely solitary beings who absolutely do not want any
"membranes" tingled by others.  
In that case, I think it would be morally wrong to deliberately stimulate any
of its membranes.  
No need to throw in vague notions like natural law or divine command here.

I think "normal function" may be a sufficient concept (teleological or not). A
normal function of the eardrum is to facilitate communication, which may be
obtained at various times as not always anticipated, so that allowing others
to communicate to us at diverse occasions via vibrations in our ears is
ordinary human function. Whereas the nose has its own function that may not
include being vibrated (might it bleed if vibrated in some ways?).  
  
  
  

Walter:  
  
Evolutionary accounts of normalcy don't work: there are too many
counterexamples. :-) But that's a long story.  
  
But even if they work, it would be odd to think that there would be moral
principles about how we should treat people that depend on what happened
millions of years ago. In other words, it seems quite irrelevant to the
question of the morality of vibrating someone's nasal membranes what the
evolutionary pressures for the development of these membranes were millions of
years ago. That's ancient history.  
  
William:  
  
The fact that it is a normal function of some organ to be sensitive to
unexpected stimulation does not suffice to make it right to provide that
unexpected stimulation. It's also a normal function of our cheek skin to be
sensitive to pressure at times that we do not anticipate, but it does not
follow that a stranger can go up to us and pat us on the cheek without
permission.  
  
So one needs reference to normalcy not just on the patient side but on the
agent side. And there, I think, we run into some problems. First, it doesn't
seem normal to engage strangers in off-topic conversation, but it's not it's
immoral. Second, it is difficult to see why, apart from a natural law or
divine command ethics, we would think that there is a strong default
permission to do what is normal.

Alex  
  
Evolutionary accounts of normalcy do work if one realizes that normalcy
evolves  
  
  
That also answers your second objection.

It's probably impossible to separate the normal in biology from the normative
when it comes to humans. Evolutionary accounts attempt to explain the
normative as a kind of fitness, but the normativity of fitness itself tends to
then be an unexplainable given.  
  

William  
  
Fitness isn't normative. It's better for survival, that's all.

Walter:  
  
If you explain why a human state or action is good by pointing out how it
increased tribal fitness in the past, but then you say fitness is "better for
survival, that's all", where did the goodness go in my explanation?  

William  
  
  
Where have I said that a human action is good? I was talking about normalcy,
not about goodness.  
So, what increased fitness in the past was normal in the past and may or may
not be normal now.

Walter:  
  
I fully agree with what you say within the limits you have set, but I think it
deprives us of any traction within the conversation about determining whether
or not a given stimulus application done by one person to another is good or
not. Which I though was the point of the OP.  
  

William  
  
I think the OP confuses normalcy with moral acceptability.  
'If during an argument someone says “I don’t want to hear another word!” it is
not morally wrong to respond verbally nonetheless'.  
Responding verbally is a 'normal' thing. As Alex puts it, we routinely do it.
We don't routinely vibrate someone's nasal membranes.  
But, if we analyse both cases, and we arrive at "deliberately doing something
to a person that this person doesn't like and doesn't consent to without
having good reason to do so", then if one thinks that moral wrongness exists,
this is clearly morally wrong. It's just that one thing is routinely done
while the other isn't.  
It may be that vibrating someone's nasal membranes is worse than responding
verbally when anaother person doesn't want it, but that is a gradual
difference.  
Raping someone is worse than vibrating someone's nasal membranes, but that
doesn't make vibrating nasal membranes right.  
  

  
Alex  
  
"The difference, I think, is that it is a part of the proper function of the
tympanic membrane to receive speech from random strangers, whether one
consents to this or not, while the nasal membranes have no such proper
function".  
Proper function are explained by evolution, so we can alter this statement to,
"The difference, I think, is that the tympanic membrane **evolved to receive
speech** from random strangers, whether one consents to this or not, while the
nasal membranes **did not evolve to have that function**."

William:  
  
But our skin evolved to receive non-consensual painful inputs from random
strangers, too (it is evolutionarily very useful to notice if random stranger
is punching you in the back), but it does not follow that it is permissible to
provide such inputs (apart from special circumstances).

Alex  
  
I think you were responding to me  
Anyway, the skin did not evolve to receive non-consensual painful imputs from
random strangers.  
That is merely a side effect, it's not a proper functions.  
My point is that proper functions are explained by evolution, by which I mean
that the 'evolutionary advantage' of the tympatic membrane is that it can
receive information, while the evolutional advantage' of the skin ( or the
nasal membrane) lies elsewhere.

I meant the skin with its touch sensors. These surely did evolve to receive a
very wide range of inputs. Ancient people who did not feel anything when hit
were not likely to survive a sneak attack.

Alex  
  
But in that case, the proper function of the skin, the nasal membrane and the
tympatic membrane are the same: receiving information, that sometimes Involves
the sensation of pain or unpleasantness.  
That means that human nature cannot explain thé difference, unless it's only a
matter of gradation.  
We feel that one 'intrusion' is worse than the other, probably because we are
more used to the other intrusion.  
  

Walter:  
  
Right!  
  
So the quick sketch of a natural law story at the end of my post was wrong:
the difference does not simply lie in the proper functions of the two
membranes.  
  
That has become clearer and clearer to me as I've been responding to
commments.  
  
The bigger point I was trying to make is that one cannot give a "Kantian"
derivation of the difference between the permissible and impermissible
behaviors from general principles about autonomy. One needs something else,
something about the unnaturalness of vibrating the nasal membranes of non-
consenting strangers.

Alex  
  
Whether something is permissible or not is subject to evolution.  
I think if you want to make a case for 'naturalness' as a condition for
perrmissibilty, I think you will have to come up with a clearer example,
because vibrating someone's tympatic membrane without consult and without a
serious reason may be permissible, but IMO it is definitely morally wrong.  
Or do you think purposely annoying People is not wrong?  
  
  

I’ve been thinking a bit about the afterlife for non-human animals. The first
thought is that there is a relevant difference between human and non-human
animals in terms of flourishing. There is something deeply incomplete about
the eighty or so years a human lives. The incompleteness of our earthly life
is a qualitative incompleteness: it is not just that we have not had enough
pieces of cake or run enough miles. Typically, whole areas of virtue are
missing, and our understanding of the world is woefully incomplete, so that
one of the most important things one learns is how little one knows. The story
of the life is clearly unfinished, even if life has gone as well as it is
reasonable to expect, and flourishing has not been achieved. Not so for non-
human animals. When things have gone as well as it is reasonable to expect,
the animal has lived, played and reproduced, and the story is complete.

If we think of the form of an entity as specifying the proper shape of its
life, we have good reason to think that the human form specifies the proper
shape of life as eternal, or at least much longer than earthly life. But there
is little reason to think that form of an animal’s life specifies the length
of life as significantly longer than the typical observed life-span of in its
species.

If we accept the thesis which I call “Aristotelian optimism”, namely that
things tend to fulfill their form or nature, we have good reason to think
there is more to human life than our earthly life, but not so for non-human
animals. In the case of humans, this line of argument should worry typical
atheistic Aristotelian ethicists, because it would push them to reject
Aristotelian optimism, which I think is central to ensuring knowledge of the
forms in Aristotle’s system.

By the way, there may be an exception in the above argument for animals whose
flourishing consists in relationships with humans. For there its flourishing
might be incomplete if it cannot be a companion to the human over its infinite
life-span. So there is some reason to think that species that are domesticated
for human companionship, like dogs and to a lesser extent cats and horses
(where companionship is less central to flourishing), might have an afterlife.

I'd be curious to hear what you think about the following cases.  
  
I: Five baby birds are pushed out of their nests and fall to their deaths by
one of their siblings.  
  
II: A chicken lives a life of torment in a factory farm without any
opportunity to reproduce or enjoy the goods that a chicken should enjoy.  
  
As I understand it, in some species, I type scenarios are the norm rather than
the exception. And, as I understand it, II type scenarios are the norm for
chickens. If that is right, then would the baby birds and the chickens need an
afterlife for Aristotelian optimism to be true?  
  

The "tend to" in my statement of Aristotelian optimism is rather vague, and I
don't have a good account of it. However, it is not meant to imply that in
every case, the majority of instances goes right. By violence it is possible
to make the majority of instances to go wrong--we could make sure that all
sheep have less than four legs, that no oak tree grows more than two feet
tall, etc.  
  
I think what I'd like to say is something like this: in the natural ecological
niche, most of the instances go right.  
  
The chickens are not in their natural ecological niche. What the natural
ecological niche for domesticated animals is is unclear, though.

That is interesting. Regarding the I type cases: As I understand it, a number
of species, maybe even most, have evolved in such a way that the reproductive
process is as follows: they have a bunch of offspring, only a few of them
survive. So insofar as their ecological niche is the same as the ecology to
which they have evolved to fit, perhaps their niche is one in which things go
pretty wrong most of the time. Now, again as I understand it, most such
organisms die really really young. And it is unclear exactly how bad their
lives are. Nevertheless, it seems to me at least, that their lives are
importantly incomplete and they aren't living in the way that they are
supposed to and in the fullness for which God has intended for them. And most
of them, in the environment which they evolved to fit, don't get to do the
things you list as what is important for them to do, such as reproduction,
etc.

Scott:  
  
Maybe. That's quite interesting. Perhaps the thing to say is that in those
species the primary goal is to contribute to the reproduction of the species
by increasing the probability of there being a next generation, and they all
do that. Flourishing may be more communal in these cases? Perhaps in these
species, actually reproducing is like winning the lottery--it's good if you
do, but not bad if you don't. But flourishing is playing the lottery.

Dr Pruss, if we accept both Aristotelian optimism as well as theism would this
require that when God creates a world he must cause the creatures in that
world to fulfill their nature? It seems that if we are to have knowledge of
things natures we must have confidence that God always or mostly causes things
to fulfill their nature, however it would also seem to put a lot of
constraints on what God can will.

###  A Thomistic argument for the possibility of an afterlife for animals

Accidents are more intimately dependent on substance than substantial forms on
matter.

If (1) is true and God can make accidents survive without the substance, then
God can make forms survive without matter.

If God can make forms survive without matter, then God can ensure life after
death for animals by making their forms survive and restoring their matter.

The most controversial claim here is (4), but that follows from the Thomistic
account of the transsubstantiation.

Of course, there is a great gap between the possibility of an afterlife for an
animal and its actuality. And the above argument works just as well for plants
and fungi.

Alex  
  
What is this argument supposed to show. According to classical theists, God is
omnipotent, so why would God not be able to create an afterlife for animals?  
  

Could God create an afterlife for my dog as a cat? If so, how was the form
preserved? As a generic mammalian one? As some kind of nonspecific yet very
specific haecceity?  

William:  
  
I think you could have a form of a dog in a body just like a cat's. That would
be a highly defective dog, incapable of many of the things the form of the dog
specifies as things a dog should be able to do.  
  
Walter:  
  
God can't do the logically impossible. One might think that if the body of an
animal is completely destroyed, it is not logically possible for that animal
to come back.

Alex  
  
I der no reason you think that it would be logically impossible.

Dr Pruss, I’m not sure there is a problem here but isnt there something odd
about the way accidents depend on their substances? It would seem that there
is a point in priority where the substance has no accidents, but it seems odd
to think of a dog for example existing without any of the features that make
it a dog such as it’s size or it’s color or location. Maybe the only
requirement for a dog to exist at its first moment is simply for its
substantial form to exist and not to have any specific accidents?

Isnt it metaphysically impossible that accident can exist without substance?
As I understood in Thomism accidents is like in trope-theory.  
And since God cannot do logical/metaphysical impossibilities  

Aquinas thinks that accidents _normally_ depend on their substances, but that
anything that a creature can do, God can do directly. So if I can sustain my
paleness, God can sustain it directly.

Here’s a claim that turns out to be equivalent to the Axiom of Choice:

Given any non-empty set _Ω_ and a collection _M_ of [0,∞]-valued finitely
additive measures on the powerset of _Ω_ such that for any non-empty _E_ ⊆ _Ω_
there is a _μ_ ∈ _M_ with 0 < _μ_ ( _E_ ) < ∞, there is a full conditional
probability _P_ on the powerset of _Ω_ definable in terms of the measures in
_M_ in the sense that for each non-empty _E_ there is a _μ_ ∈ _M_ such that 0
< _μ_ ( _E_ ) < ∞ and for all _A_ we have _P_ ( _A_ | _E_ ) = _μ_ ( _A_ ∩ _E_
)/ _μ_ ( _E_ ).

The easy direction of proof is from (1) to AC. Let _M_ be the collection of
all the finitely additive probability measures on _Ω_ that assign probability
one to some singleton. Clearly _M_ has the desired properties. Now, for any
non-empty _E_ ⊆ _Ω_ , there will be a _μ_ ∈ _M_ such that _P_ ( _A_ | _E_ ) =
_μ_ ( _A_ ∩ _E_ )/ _μ_ ( _E_ ) and 0 < _μ_ ( _E_ ) < ∞. Thus, the point at
which _μ_ is concentrated must be in _E_. Moreover, it is clear that for each
_E_ , the measure _μ_ must be unique. Let _f_ ( _E_ ) be the point at which
_μ_ is concentrated. This is a choice function for all subsets of _Ω_. Since
_Ω_ is an arbitrary non-empty set, we have AC.

Considering that conditional probabilities are necessary for the formulation
of Bayes's theorem, how does this statement impact Bayesian epistemology? Does
this imply that the axiom of choise is neccessary for Bayesian Epistemology?

Quantum collapse is often said to “violate unitarity”. Either I’m confused or
this phrasing is misleading or both.

A bounded linear operator _P_ on a Hilbert space _H_ is said to be unitary iff
it is surjective and preserves inner products. But as I understand it, quantum
collapse is not even an operator. An operator on _H_ is a function from _H_ to
_H_. But a function _f_ , given a specific input | _ψ_ ⟩, yields a unique
output _f_ (| _ψ_ ⟩). Quantum collapse does no such thing. It is an
indeterministic process. Sometimes given input 2−1/2(| _ψ_ 1⟩+| _ψ_ 2⟩) (where
| _ψ_ 1⟩ and | _ψ_ 2⟩ are eigenvectors corresponding to the measurable we are
collapsing with respect to) it gives output | _ψ_ 1⟩ and sometimes it gives
output | _ψ_ 2⟩.

While strictly speaking if some process is not modeled by an operator, it is
not modeled by a unitary operator, to call that a violation of unitarity is
misleading. It is better to say it’s a violation of _operationality_ or
_functionality_. We cannot even say what it would _mean_ for a process not
modeled by an operator to be unitary, just as we cannot say what it would
_mean_ for a frog to be unitary or a linear operator to be a vertebrate.

One might _try_ to say what it would mean to have unitarity for a non-
deterministic evolution. Suppose that | _ψ_ ⟩ would collapse to | _ψ_ ′⟩ and |
_ϕ_ ⟩ would collapse to | _ϕ_ ′⟩ under some measurement. Then one could claim
that unitarity would say that ⟨ _ϕ_ ′| _ψ_ ′⟩=⟨ _ϕ_ | _ψ_ ⟩. But this assumes
that there is a fact of the matter as to what | _ψ_ ⟩ and | _ϕ_ ⟩ would
collapse to. Now, if | _ψ_ ⟩ _in fact_ collapses to | _ψ_ ′⟩, it might make
sense to say that | _ψ_ ⟩ _would_ collapse to | _ψ_ ′⟩. But for unitarity we
need the identity ⟨ _ϕ_ ′| _ψ_ ′⟩=⟨ _ϕ_ | _ψ_ ⟩ for _all_ inputs | _ψ_ ⟩ and |
_ϕ_ ⟩, not just for the ones that actually occurred.

I suppose one could have a generalized Molinist thesis that there is always a
fact of the matter as to what a given wavefunction _would_ collapse to, so
that we might be able to define a collapse operator. And then we could say
that unitarity fails. But it would still likely be misleading to say that
unitarity fails, since we would expect _linearity_ to fail, not merely
unitarity. And in any case, such a generalized Molinist thesis is quite
dubious.

But I know very little about quantum mechanics, and so I may simply be
confused.

It seems a paradigm of irrationality to intend an event _E_ in an action _A_
and yet take the action to lower the probability of _E_.

Suppose that Alice is in a bicycle race and is almost at the finish. If she
just lets inertia do its job, she will inevitably win. But she carefully
starts braking just short of the finish, aiming to cross the finish just a
hair in front of Barbara, the cyclist behind her. She does this because she
wants to make the race more exciting for the spectators, and she carefully
calibrates her braking to make her win but not inevitably so.

Alice is aiming to win with a probability modestly short of one. This is a
specification of winning, so by my principle, she is intending to win. But she
is also, and in the very same action, aiming to decrease the probability of
winning.

Consider the proper class _V_ of formal expressions of the form _x_ _ϵ_ _y_
where _x_ is a non-negative real number that is permitted to be zero only if
_y_ = 0, _y_ is a non-negative surreal number, and _ϵ_ is a formal symbol to
be thought of as “something very small”. (If we want to be rigorous, we let
_V_ be the set of ordered pairs ( _y_ , _x_ ).) Stipulate:

_x_ _ϵ_ _y_ ≤ _x_ ′ _ϵ_ _y_ ′ iff either (a) _y_ > _y_ ′ or (b) _y_ = _y_ ′
and _x_ ≤ _x_ ′

_x_ _ϵ_ _y_ \+ _x_ ′ _ϵ_ _y_ ′ equals ( _x_ + _x_ ′) _ϵ_ _y_ if _y_ = _y_ ′
and otherwise equals the greater of _x_ _ϵ_ _y_ and _x_ ′ _ϵ_ _y_ ′

if _x_ _ϵ_ _y_ ≤ _x_ ′ _ϵ_ _y_ ′ and they’re not both zero, then ( _x_ _ϵ_ _y_
/ _x_ ′ _ϵ_ _y_ ′) = ( _x_ / _x_ ′) _ϵ_ _y_ − _y_ ′

Std _x_ _ϵ_ _y_ equals _x_ if _y_ = 0 and equals 0 othewise.

We can then define finitely-additive probabilities with values in _V_ in the
same way that we do so for reals, and we can then define conditional
probabilities using the standard formula _P_ ( _A_ ∣ _B_ ) = _P_ ( _A_ ∩ _B_
)/ _P_ ( _B_ ).

Say that a _V_ -valued probability _P_ is regular iff 0 < _P_ ( _A_ ) whenever
_A_ is non-empty.

Now here is a fun fact. Given a _V_ -valued probability _P_ , we can define a
real-valued full conditional probability as the standard part (Std) of _P_.
Conversely, and less trivially, any real-valued full conditional probability
can be obtained this way (this follows from the fact that any linear order can
be embedded in the surreals).

So far this doesn’t mark any advantage of using _V_ instead of hyperreals as
the values of our probabilities. But there _is_ an advantage. Specifically, if
our probability space _Ω_ is acted on by a supramenable group _G_ of
symmetries (any Abelian group is supramenable)—for instance, _Ω_ might be a
circle acted on by the group of rotations—then there is a _V_ -valued regular
_G_ -invariant probability defined for all subsets of _Ω_. But if we have
hyperreal (or surreal, for that matter) values, then the existence of a
regular probability invariant under _G_ requires significantly stricter
conditions, ones that won’t be met in the case where _Ω_ is the circle and _G_
is rotations.

However, the advantage comes from the fact that _V_ one to have _a_ \+ _b_ =
_a_ even though _b_ > 0, so that one can have weak regularity—the condition
that 0 < _P_ ( _A_ ) whenever _A_ is nonempty—without strong regularity—the
condition that _P_ ( _A_ ) < _P_ ( _B_ ) whenever _A_ ⊂ _B_. If one wants
strong regularity, using _V_ instead of the hyperreals doesn’t have the same
advantage.

Suppose Alice intends to hit Bob with a stick. There are two ways that the
stick could be involved in Alice’s intentions. First, Alice might not care
that it is a _stick_ she hits Bob with, but a stick happens to be ready to
hand. In that case, her hitting Bob with a stick is a means to her hitting
Bob.

Second, Alice might care about hitting Bob with a stick—perhaps she is
punishing him for hitting a defenseless person with a stick and wants the
punishment to match the crime. In that case, hitting Bob with a stick is not a
means to her hitting Bob, as her hitting Bob does not figure in her intentions
apart from the stick. But even in that case it seems right to say that Alice
intends to hit Bob. For while it is false to say in general that

if _p_ entails _q_ and Alice intends _p_ then Alice intends _q_

(even if one adds that Alice knows about the entailment, or makes the
entailment relevant in the sense of relevance logic), it seems that the
following special case is true:

if _q_ is a specification of _p_ and Alice intends _q_ then Alice intends _p_.

Alice’s hitting Bob with a stick is a specification of Alice’s hitting Bob.

A similar point applies to conjunctions. If Alice intends to hit Bob with a
stick and to insult him, she intends to hit Bob with a stick and she intends
to insult him. But sometimes at least, hitting Bob with a stick and insulting
him do not figure as independent intentions. Yet they are intended
nonetheless. So we have another special case of (1):

if _p_ is a conjunct of _q_ and Alice intends _q_ then Alice intends _p_.

It is an unhappy situation that some special cases of (1) are true, but (1) is
not true in general, and I do not know how to specify which special cases are
true.

This is very interesting, Alex. Maybe the difference is that if p partly
consists of q then anything which might count as a reason to pursue p also
counts as a reason to pursue q (for a fully informed agent, anyway--that is,
for an agent who understands that p partly consists of q). This explanation
leaves room for 1 to be false since p might entail q without partly consisting
of q--as when p will certainly cause q. But if q is a specification of p then
p partly (or wholly) consists of q--at least if I understand what you mean by
specification.  
  
But if this is the right explanation then it is hard to see how Sam could
intend to kill the mammal without intending to kill the human, since killing
the mammal consists of killing the human.

What if Alice has strange beliefs such that she believes q but doesn't believe
p, even if p is a conjunct of q? Does she still intend p if she intends q?

I doubt this is possible. It seems to me that one way to believe p is to
believe a conjunction of which p is a conjunct. It's not like our beliefs are
stored as separate sentences in the brain. They are, I expect, often encoded
in a kind of bundle. And conjunction is one way for them to be bundled.

In general I would be reluctant to ascribe such beliefs to someone but I can
imagine situations where I would. For example, if Alice earnestly said q,
denied p and explicitly said that she does not believe that a conjunction
entails its conjuncts.

If someone said she did not believe that a conjunction entails the conjuncts,
it would take a lot of work to convince me that they know what "conjunction"
means.  
  
Notice that normally when you believe a conjunction, you don't need to take
any extra steps to believe the conjuncts. You automatically count as believing
the conjuncts by believing the conjunction. If you then deny a conjunct, then
it may well be that you are simply contradicting yourself: you both believe
and don't believe that conjunct.

Zsolt:  
  
That's a valiant attempt at generalizing, but I don't think it works. Suppose
Alice doesn't know that pigs are mammals. Then she can easily intend to eat a
pig without intending to eat a mammal, even though pig eatings are a subset of
mammal eatings. In fact, I think even if she does know, mammality may not be
in her intentions at all even if pigness is.

Zsolt:  
  
You have a history of posts written in a style far from the polite, calm and
intellectual style of academic debate. I have given you several warnings,
deleted a number of comments, but the unacceptable emotional tone has
continued. Consequently, I have set up a script to automatically delete new
comments from you. There are some glitches in the script, so the above comment
of your may stay up or not.  
  
Note that Blogger's policy is about Blogger censoring posts. As far as I can
tell, blog owners are free to moderate comments as they see fit.

The fact that a large animal is attacking me would give me both permission and
reason to kill the animal. On the basis of cases like that, one might
hypothesize that permissions to _ϕ_ come from particularly strong reasons to
_ϕ_.

But there are cases where things are quite different. There is an inexpensive
watch on a shelf beside me that I am permitted to destroy. What gives me that
permission? It is that I _own_ it. But the very thing that gives me
permission, my ownership, also gives me a reason _not_ to smash it. So
sometimes the same feature of reality that makes _ϕ_ ing permissible is also a
reason against _ϕ_ ing.

This is a bit odd. For if it were impermissible to destroy the watch, that
would be a _conclusive_ reason against the smashing. So it seems that my
ownership moves me from having a conclusive reason against smashing to not
having a conclusive reason against smashing. Yet it does that while at the
same time being a reason _not_ to smash. Interesting.

I suspect there may be an argument against utilitarianism somewhere in the
vicinity.

Why would your ownership of the watch in and out of itself give you a reason
not to smash it?  
Maybe you bought the watch because it looked pretty to you, or maybe because
it reminded you of your father. But in that case, the reasons why you bought
the watch would be reasons not to destroy it, not your ownership as such.  
You could also have bought the watch in order to destroy it, in which case
your ownership would clearly not be reason not to destroy it.  
The fact that the watch is inexpensive should not matter. If you are permitted
to destroy that watch, you are equally permitted to destroy your Rolex.  
But your Rolex might give you better reasons not to destroy it, not because of
your ownership, but because of its value.

Interesting, Alex! What do you think of the following?  
  
It's not the case that your owning the watch gives you reason not to smash it.
Rather, your reason for not smashing it comes from the value-proposition of
that action--i.e. the unsmashed watch has some value; the smashed watch
doesn't, and that holds irrespective of ownership status.  
  
Admittedly, owning the watch alters in two ways one's reasons not to smash it.
First, as you note, it weakens it (cf. "my ownership moves me from having a
conclusive reason against smashing to not having a conclusive reason against
smashing.") Second, When the watch belongs to someone else, my (non-
permission-related) reason not to smash it is that smashing it deprives *them*
of something of value; when I own it, my reason not to smash it is that
smashing it will deprive *me* of something of value. I assume though, that for
this case, at least, this switch from an other-regarding reason to a self-
regarding reason is not really a significant one. So the thing that gives me
permission to ϕ with respect to O might alter the nature of my reasons for not
ϕing, but I don't see it as giving one a reason against ϕing where one
theretofore lacked such a reason.

But I no longer know if any of (ii)–(v) imply (i). However, (i) is true under
the stronger assumption that _G_ is supramenable _or_ that there exist
invariant hyperreal probabilities.

The above remarks suffice for almost all the philosophical points in the paper
(the philosophical point that behavior for countable sets is decisive is no
longer supported in the full conditional probability case), and all the
applications I mention in the paper.

I do not know if “Theorem 1” is true. This is an interesting mathematical
question.

I am making some progress on fixing the error. I am not 100% sure my fix
works, but it seems to.

In happy news, my fix DOES work: I've proved Lemma 2, and the proof was
verified by a mathematician who works in the field. In fact, my new proof
shows the interesting fact that if any of the conditions of Theorem 1 holds,
then any unconditional G-invariant probability on Omega can be extended to a
full conditional one.

Consider a fair spinner that uniformly chooses an angle between 0 and 360∘.
Intuitively, I’ve just fully described a probabilistic situation. In classical
probability theory, there is indeed a very natural model of this: Lebesgue
probability measure on the unit circle. This model’s probability measure can
be proved to be the unique function _λ_ on the subsets of the unit circle that
satisfies these conditions:

completeness: if _λ_ ( _B_ ) is zero and _A_ ⊆ _B_ , then _λ_ is defined for
_A_

at least one arc on the circle of length greater than zero and less than 360∘
has an assigned probability

minimality: any other function that satisfies 1-4 agrees with _λ_ on the sets
where _λ_ is defined.

In that sense “uniformly chooses” can be given a precise and unique meaning.

But we may be philosophically unhappy with _λ_ as our probabilistic model of
the spinner for one of two reasons. First, but less importantly, we may want
to have meaningful probabilities for _all_ subsets of the unit circle, while
_λ_ famously has “non-measurable sets” where it is not defined. Second, we may
want to do justice to such intuitions as that it is more likely that the
spinner will land exactly at 0∘ or 180∘ than that it will land exactly at 0∘.
But _λ_ as applied to any finite (in fact, any countable) set of positions
yields zero: there is no chance of the spinner landing there. Moreover, we
want to be able to update our probabilities on learning, say, that the spinner
landed on 0∘ or 180∘—presumably, after learning that disjunction, we want 0∘
and 180∘ to have probability 1/2—but _λ_ provides no guidance how to do that.

Unfortunately, the conditional probability approach still doesn’t have
uniqueness, and this is the point of this post. Let’s say that what we require
of our conditional probability assignment _P_ is this:

being defined for all pairs of subsets of the circle with the second one non-
empty

_P_ ( _A_ | _Ω_ ) = _λ_ ( _A_ ) for any Lebesgue-measurable _A_.

Unfortunately, these conditions fail to uniquely define _P_. In fact, they
fail to uniquely define _P_ ( _A_ | _B_ ) for countably infinite _B_.

Here’s why. Let _E_ be a countably infinite subset of the circle with the
following property: for any non-identity isometry _ρ_ of the circle
(combination of rotations and reflections), _E_ ∩ _ρ_ _E_ is finite. (One way
to generate _E_ is this. Let _E_ 0 be any singleton. Given _E_ _n_ , let _G_
_n_ be the set of isometries _ρ_ such that _ρ_ _x_ = _y_ for some _x_ , _y_ in
_E_. Then _G_ _n_ is finite. Let _z_ be any point not in { _ρ_ _x_ : _ρ_ ∈ _G_
_n_ , _x_ ∈ _E_ }. Let _E_ _n_ \+ 1 = _E_ _n_ ∪ { _z_ } (since _z_ is not
unique, we’re using the Axiom of Dependent Choice, but a lot of other stuff
depends on stronger versions of Choice anyway). Let _E_ be the union of the
_E_ _n_. Then it’s easy to see that _E_ ∩ _ρ_ _E_ contains at most one point
for any non-identity isometry _ρ_.)

Let _μ_ be any finitely additive probability on _E_ that assigns zero to
finite subsets. Note that _μ_ is not unique: there are many such _μ_. Now
define a finitely additive measure _ν_ on _Ω_ as follows. If _A_ is
uncountable, let _ν_ ( _A_ ) = ∞. Otherwise, let _ν_ ( _A_ ) = ∑ _ρ_ _μ_ ( _E_
∩ _ρ_ _A_ ), where the sum is taken over all isometries _ρ_. The condition
that _E_ ∩ _ρ_ _E_ is finite for non-identity _ρ_ and that _μ_ is zero for
finite sets ensures that if _A_ ⊆ _E_ , then _ν_ ( _A_ ) = _μ_ ( _A_ ). It is
clear that _ν_ is isometrically invariant.

Let _λ_ * be any invariant extension of Lebesgue measure to a finitely
additive measure on all subsets of the circle. By Armstrong’s results (most
relevantly Proposition 1.7), there is a full conditional probability _P_
satisfying (6)–(8) and such that _P_ ( _A_ | _E_ ) = _μ_ ( _A_ ∩ _E_ ) and _P_
( _A_ | _Ω_ ) = _λ_ *( _A_ ) (here we use the fact that _ν_ ( _A_ ) = ∞
whenever _λ_ *( _A_ ) > 0, since _λ_ *( _A_ ) > 0 only for uncountable _A_ ).
Since _μ_ wasn’t unique and _E_ is countable, conditions (6)–(9) fail to
uniquely define _P_ for countably additive conditions.

There is no problem coming up with explicit Es. (If I’m thinking straight…)
Here is one: {1/2, 1/3, 1/4, …}. Any countable collection with a single one-
sided convergence point will do.  
  
The post shows that _complete_ conditional probabilities exist but are not
unique. How far can you go if you want uniqueness but don’t insist on
completeness? Not very far, I think.  
  
There is an obvious intuitively natural conditional probability on the sets
that can be described as the union of a finite number of intervals, plus or
minus a finite number of single points. But going beyond this doesn’t seem
easy.

Nice points. I guess the advantage of my non-explicit construction is that it
generalizes more easily to other groups of symmetries on other spaces. (For
instance, it works for any case of an infinite group acting on itself.)  
  
There are some results in dimensions 1 and 2 about the uniqueness of Lebesgue
measure in certain contexts in the Wagon-Tomkowicz boon on the Banach-Tarski
paradox.

But now I think there can be cases of murder where there is no intent to
injure _at all_. Suppose that amoral Alice wants to learn what an exploding
aircraft looks like. To that end, she launches an anti-aircraft missile at a
civilian jetliner. SHe has the ordinary knowledge that the explosion will kill
everyone on board, but in her total amorality she no more intends this than
the ordinary person intends to contribute to wearing out shoes when going for
a walk. Alice has committed murder, but without any intention to kill.

In terms of the Principle of Double Effect, Alice’s wrongdoing lies in the
lack of proportionality between the foreseen gravely bad effect (mass
slaughter) and the foreseen trivially good effect (satisfaction of desire for
unimportant knowledge), rather than in a wrongful intention, at least if we
bracket questions of positive law.

It is tempting to conclude that every immoral killing is a murder. But that’s
not right, either. If Bob is engaged in a defensive just war and has been
legitimately ordered not to kill any of the enemy before 7 pm no matter what
(so as not to alert the enemy, say), and at 6 pm he kills an enemy invader in
self-defense, then he does not commit murder, but he acts wrongly in
disobeying an order.

It seems that for an immoral act to be a murder it needs to be wrong because
of the lethality of the harm as such, rather than due to some incidental
reason, such as the lethality of the harm as contrary to a valid order.

I noticed something similar when trying to explain why abortion is murder to
people with a pro-abortion stance. I would claim that few people who procure
or support abortion are doing so because they have as an end the explicit
death of the child. The death of the child is either an effect deemed
tolerable or a means to the end of eliminating an unwanted pregnancy (a desire
that deserves its own analysis).  
  
To make this perhaps a bit more conspicuous, imagine that we could remove a
fetus and place it in an incubator of some kind so that its life is spared and
it can develop to term. How many would object to banning lethal abortions if
such means were possible? I'm sure some would as the knowledge that a living
person resulting from some illicit sexual encounter or whatever is walking
around may sit poorly with one's pride. (Even then, the support for lethality
is still an attempt at a means to "undo" some state of affairs.) Others might
object on the ill-conceived grounds that such bans would interfere with a
woman's rights over her body, to borrow feminist parlance. And indeed, if the
will cannot strictly speaking intend what the intellect construes as evil,
then murder can never be an intended end, but always an intended means.

The pregnancy as such is a reason for abortion in cases where the mother's
health is in danger, or where the woman is physically unable to continue
working due to pregnancy, or where the financial cost of pregnancy care is too
high. But these reasons seem to be a small proportion of actual cases of
abortion.  
  
Most cases of abortion (according to surveys of women in the US) seem to
concern things like the financial or emotional cost of raising a child or the
relationship issues resulting from having the child. Neither of these reasons
would be removed by the incubator. I conclude that in fact in most abortions,
the death of the fetus is intended.

> concern things like the financial or emotional cost of raising a child or
> the relationship issues resulting from having the child. Neither of these
> reasons would be removed by the incubator.  
  
Perhaps I should have made this part more explicit, namely, that the option of
a incubator allows a woman to part with her child before term without killing
her. The biological dependence on the mother has been removed and the mother
can now leave the child in the care of others (effective giving it up for
adoption). Of course, financial and emotional cost can also be largely avoided
by carrying to term as well, so perhaps the difference between having the
option of an incubator and not having that option is effectively small, though
I would not say that it is nil (9 months vs. ~0 months).  
  
In any case, I may be trying to be unduly charitable by confining myself to
the assumptions of someone in that position, but invoking financial and
emotional cost already grounds the argument within the logic of such a mother.
I.e., I cannot see how one might reason from the prospect of financial and
emotional cost to abortion, however fallaciously, with the option of adoption
or an especially an incubator that can, in this thought experiment, permit the
pregnant mother to cut ties with her child from a very early stage. What is to
be ostensibly gained by intending the death, especially given such an option?
We may be treading out of logic and into psychology, but then, the more
emotion is implicated in moving the will and in a way that obstructs the
exercise of reason, the less culpable the mother is for the murder of her
child, in which case, is the intention sufficiently manifested since ascent
has been undermined? (Again, in the context of the though experiment.)  
  
In other words, are you arguing that most abortions are not the result of
amoral reasoning as you've described nor a highly emotionally mental state?
And even in the cases where we ascribe malicious intent, is the murder still
not the means, rather than the intended effect per se?

On a natural law theory of morality, some moral facts are _nature-relative_ ,
i.e., grounded in the particular kind of nature the particular rational being
has, and other moral facts are _structural_ , a part of the very structure of
rationality, and will apply to any possible rational being.

Thus, the norm of monogamy for human beings (assuming, as I think, that there
is one) is surely be nature-relative—it seems very likely that there could be
rational animals to whom a different reproductive strategy would be natural.
But what Aquinas calls the first precept of the natural law, namely that the
good is to be pursued and the bad is to be avoided, is structural—it applies
to any rational being.

I think that evidence for a human norm being nature-relative is that either
the space of norms contains other very similar norms nearby or it’s vague
which precise norm obtains. For instance, take the norm of respecting one’s
parents. This norm implies that we should favor our parents over strangers in
our beneficence. However, _how much_ more should we favor our parents over
strangers? If there is a precise answer to that question, then there will be
other nearby norms—not human ones—that give a slightly different precise
answer (requiring a greater or smaller degree of favoring). On the other hand,
that the good is to be pursued does not seem to have very similar norms near
it—it has an elegant simplicity that a variant norm like “The good is to be
pursued except when it is an aesthetic good” does not have.

I used to think the norms involved in double-effect reasoning were structural
and hence applied to all possible rational being. I am no longer confident of
this. Take the case of pushing a large person in front of a trolley without
their permission in order to stop the trolley from hitting five others. We can
now imagine a continuum of cases depending on how thick the clothing worn by
the large person is. If the clothing is sufficiently thick, the large person
has an extremely small probability of being hurt. If the clothing is ordinary
clothing, the large person is nearly certain to die. In between is a continuum
of probabilities of death ranging from negligibly close to zero to negligibly
close to one, and a continuum of probabilities of other forms of injury. It is
wrong to push the large person if the chance of survival is one in a trillion.
It is not wrong to push the large person if the chance of their being at all
hurt is one in a trillion. Somewhere there is a transition between
impermissibility and permissibility. Either that transition is vague or it’s
sharp. If it’s sharp, then there are norms very similar to the one we have. If
it’s vague, then it’s vague which of many very similar norms we have.

In either case, I think this is evidence that the relevant norm here is
nature-relative rather than structural. If this is right, then even if it is
wrong for us to push the large person in the paradigmatic case where death is,
say, 99.99% certain, there could be rational beings for whom this is not
wrong.

This leads to an interesting hypothesis about God’s ethics ( _somewhat_
similar to things Mark Murphy has considered):

God is only subject to structural moral norms and does not have any nature-
relative moral norms.

I do not endorse (1), but I think it is a hypothesis well worth considering.

How did you manage to misread this little blog post this badly? At no point
did he deny that there are both nature-relative and structural moral facts

Dr Pruss  
  
Do you have any work or future work covering the double effect reasoning
involved in certain cases of pregnancies, i.e the catholic debates over the
nature of act and intension  
Whether craniotomies would be permissible etc

Zsolt:  
  
The first sentence of the post says that on natural law theory some facts are
nature-relative and some others are structural.  
  
Norm:  
  
I have not published on this, but incline to the view that craniotomy need not
be an intentional killing, but is nonetheless a murder. Murder does not
require intentional killing. If a country shoots down a civilian aircraft as
target practice, they need not intend the deaths of the civilians, but they
have nonetheless murdered them.

I know, Alexander, what the first sentence of your post says on natural law
theory some moral facts being nature-relative - grounded in the particular
kind of nature, the particular rational being has - and some other moral facts
being structural - a part of the very structure of rationality, and will apply
to any possible rational being.  
  
Sure. And also sure that those terms "nature-relative" and "structural" are
not mutually exclusive or disjunctive terms - without any overlap like by the
terms or properties of "being a bachelor" and "being married". Duh.  
So on natural law theory some moral facts are nature-relative AND structural -
grounded in the particular kind of nature, the particular rational being has,
which is part of the very structure of rationality, and will apply to any
possible rational being. Huh, huh, **KANT'SCATEGORICALIMPERATIVE** , huh. Oh,
sorry for my coughs there.  
And if that's not included or at least considered on natural law theory, then
maybe it should be, since you know, that **those terms "nature-relative" and
"structural" are not mutually exclusive terms**.  
Or do you, Alexander, honestly think, that those terms are actually mutually
exclusive? Are you then advocating for a false dichotomy here? That's, what,
I'm guessing, is happening here.  
  
Besides that, if the hypothesis (1) _"God is only subject to structural moral
norms and does not have any nature-relative moral norms."_ is supposedly well
worth considering, then I also guess, that it's well worth considering, that
it is indirectly suggested with the hypothesis (1), that God is moral because
of some structural moral norms, to which God is subjected, and it's not that
some structural moral norms are facts because of God, to which those
structural moral norms are subjected.  
If so, then God isn't really essential for morality. But supposedly according
to hypothesis (1) then those structural moral norms are essential for
morality.  
Isn't that correct, Alexander?!?  
At least it appears that way.

No, that last part is incorrect. At no point does the theory require God being
subject to these laws, rather due to the convertibility of goodness with being
(convertibility of transcendentals), the structural moral norms directly
follow from God's nature as the good. Hence rather than being independent from
him, the structural moral norms directly follow from what God is

So then the structural moral norms are "good" or they are, what they are,
because God says so?!?  
They seem then to be quite arbitrary, given that God can make basically any
moral norms or facts to be structural moral norms or facts.  
  
Besides that, how does that _"convertibility of goodness"_ exactly work?!?  
Is it like in the Bible, first in the beginning there was "nothing", then
there was the "word" of God?!?  
If there is a fully developed "theory" to it, then that "theory" should at
list contain, how that _"convertibility of goodness"_ exactly supposed to
work.  
  
It's not like you can just make an unwarranted claim and thesis, then declare
it to be a _"theorem"_ or a _"theory"_ of some sort without giving any proof,
justification or warrant for that _"theorem"_ or _"theory"_ of yours. That’s
not how any proper epistemology works.

It’s occurred to me that the “might well happen that” operator makes for an
interesting modality. It divides into an epistemic and a metaphysical version.
In both cases, if it might well happen that _p_ , then _p_ is possible (in the
respective sense). In both cases, there is a tempting paraphrase of the
operator into a probability: on the epistemic side, one might say that it
might well happen that _p_ if and only if _p_ has a sufficiently high
epistemic probability, and on the metaphysical side, one might say that it
might well happen that _p_ if and only if _p_ has a sufficiently high chance
given the contextually relevant background. In both cases, it is not clear
that the probabilistic paraphrase is correct—there may be (might well be!)
cases of “might well happen that” where numerical probabilities have no place.
And in both cases, “might well happen that” seems context-sensitive and vague.
It might well be that thinking about this operator could lead to progress on
something interesting.

Maybe on the metaphysical side: “The causal mechanisms are in place for X to
happen.” And on the epistemological side, either: “I know about the causal
mechanisms’ being in place for X to happen,” or “I do not know enough about
the causal mechanisms’ being in place to say X won’t happen.”

If one can have justice or justice can be served here in this current life,
then one might as well get it here rather than in the after-life.  
If any child is supposed to be born into a healthy family, then why allow that
happening in the case of an unhealthy or non-existent family like in a
violence or a rape case?  
If that occurs and you or we can serve justice and make it right, then you or
we might as well just do that right here and right now. There is no need for
waiting for justice supposedly being served in an imaginary after-life.

Really, Alexander? In what way appears to you that the phrase "might as well"
being significantly different from the phrase _"might well"_. What's that
difference supposed to be exactly?!?  
You see, physical things might be constituted and explained by matter and
further ghosts might be described by being non-physical things. But that
neither truly explain what ghosts supposed to be and how they might differ
from physical things as your simple sentence of _""might as well" seems quite
different from "might well"."_ constituting there to be significant difference
also doesn't explain, what that difference exactly might be. Is it really so
difficult to write one or two more sentences?!?  
  
Besides that, if you are so concerned of there supposedly being such a
significant difference between those two phrases, then you can have it from me
both ways:  
If one can have justice or justice can be served here in this current life,
then one might [-as-] well get that justice here in the current life rather
than in the after-life.  
If any child is supposed to be born into a healthy family, then why allow that
happening in the case of an unhealthy or non-existent family like in a
violence or a rape case?  
If that occurs and you or we can serve justice and make it right, then you or
we might [-as-] well just do that right here and right now. There is no need
for waiting for justice supposedly being served in an imaginary after-life.  
  
Is Philosophy dead?  
Again, I don't think so. But is Philosophy irrelevant?  
Currently yes. Currently Philosophy is quite irrelevant.

Frances Kamm uses her principle of triple effect to resolve the loop version
of the trolley problem. On the loop version, as usual, the main track branches
into are two tracks, track A with five people and track B with one person, and
the trolley is heading for track A. But now the two tracks join via a loop, so
if there were no one on either track, a trolley that goes on track A will come
back on track B and vice versa. If we had five people on track A and _no one_
on track B, and we redirected the trolley to track B, it would go on track B,
loop around, and fatally hit the people on track A anyway. But the one person
actually on track B is big enough that if the trolley goes on track B, it will
be stopped by the impact and the five people will be saved.

The problem with redirecting to track B on the loop version of the trolley
problem is that it seems that a part of your intention is that the trolley
should hit the person on track B, since it is that impact which stops the
trolley from hitting the five people on track A. And so you are intending harm
to the person on track B.

In her _Intricate Ethics_ book, Kamm gives basically this story about
redirecting the trolley in the loop case:

Initial Intention: Redirect trolley to track A to prevent the danger of five
people being hit from the front.

Initial Defeater: The five people come to be in danger of being hit from the
back by the trolley.

Defeater to Initial Defeater: The one person on track B blocks the trolley and
prevents the dangers of being hit from the back.

The important point here is that the defeater to the defeater is not
intended—it is _just_ a defeater to a defeater. Thus there is no _intention_
to block the trolley via the one person on track B, and hence that person’s
being hit is not a case of their intentionally being used as a means to saving
lives.

But this defeater-defeater story is mistaken as it stands. For given the
presence of the person on track B, there is no danger of the five people being
hit from the back. Thus, there is no initial defeater here.

Now, if you don’t know about the one person on track B, you would have a
defeater to the redirection, namely the defeater that there is danger of being
hit from the back. But learning about the person on track B would not provide
a defeater to that defeater—it would simply _remove_ the defeater by showing
that the danger doesn’t exist.

That the story doesn’t have a defeater-defeater structure does not mean that
one is intending the one person to be hit. Kamm might still be right in
thinking there is no intention to block the trolley via the one person on
track B. But I am dubious of Kamm’s story now, because I am dubious that the
danger of _being hit from the front_ yields a worthy initial intention. For
there is nothing particularly bad about _being hit from the front_. It is only
the danger of being hit _simpliciter_ that seems worth preventing.

It is interesting to me to note that even if Kamm’s story doesn’t have
defeater-defeater form, the main place where _I_ want to use her triple effect
account seems to still have defeater-defeater form. That place is the _felix
culpa_ , where God allows Adam and Eve to exercise their free will, even
though he knows that this would or might well (depending on details about
theories of foreknowledge and middle knowledge) result in their sinning, and
God’s reasoning involves the great goods of salvation history that come from
Adam and Eve’s sin.

Initial Intention: Allow Adam and Eve to exercise their free will.

Here the initial defeater is not mistaken as in the looping trolley case—the
sin or its possibility is really real. Moreover, while it’s not an initially
worthy intention to prevent people from being hit from the front, unless they
aren’t going to be hit from behind (or some other direction) either, it _is_
an initially worthy intention to allow Adam and Eve to exercise their free
will, even if no further goods come about, because free will is intrinsically
good.

Thus we can criticize Kamm’s own use of triple effect while yet preserving
what I think is a really important theological application.

How do I read The Existence of God (coedited with R. M. Gale)? where is the
pdf?

It's out of print. I have one hard copy. For copyright reasons, I can't make a
PDF available.

Wow, I was just thinking of asking the same question a few days ago.

Suppose a defeater of a primary intention is a fact which threatens to render
the primary intention unreasonable. Then it seems that the defeater of the
primary intention is false in the Party Case also (although the notion of
"threat" is vague here). That there will be a mess does not threaten to render
the intention to throw the party unreasonable. For the agent knows all along
that the mess will be cleaned. So, maybe a defeater is just a fact which,
*taken on its own* might seem to render the primary intention unreasonable.
But then the fact that the trolley is headed toward the five via the loop
could plausibly be construed as a defeater in the loop case even though the
agent who diverts knows that the trolley will be stopped by the man on the
tracks.  
  
Also, here is a variant of the Party Case: Sam throws a party because he knows
his friends will feel sufficiently indebted to him that they will never leave
a mess in the first place. It is clear that he does not throw the party in
order to make his friends feel indebted. This is only desired because it will
prevent the party from resulting in a mess--its value is parasitic on the
occurrence of the party.  
  
So, an agent might decide to x because of some factor f, not because f solves
a problem created by x, but because f prevents x from resulting in problems to
begin with. Maybe this suggests that construing the cases in defeater-defeater
terminology is mistaken, or maybe it suggests that defeaters are just facts
which *taken on their own* seem to render the primary intention unreasonable.
If the first of these options is true it is not a problem for Kamm that the
defeater is false. If the second is true it is not clear that the defeater is
false. In neither case is there a problem here for her view.  
  
I share your suspicion that her application of DTE to the Loop Case fails, but
I'm not sure how relevant it is that the defeater is false on a certain
construal of what it means to be a defeater.

A standard scoring rule argument for probabilism—the doctrine that credence
assignments should satisfy the axioms of probability—goes as follows. If _s_
is a scoring rule on a finite probability space _Ω_ , so that _s_ ( _c_ )( _ω_
) is the epistemic utility of credence assignment _c_ at _ω_ in _Ω_ , and (a)
_s_ is strictly proper and (b) _s_ is continuous, then for any credence _c_
that does not satisfy the axioms of probability, there is a credence _p_ that
does satisfy them such that _s_ ( _p_ )( _ω_ ) is better than _s_ ( _c_ )( _ω_
) for all _ω_. This means that it’s stupid to have a non-probabilistic
credence _c_ , since you could instead replace it with _p_ , and do better, no
matter what.

The argument for probabilism assumed two things about the scoring rule: strict
propriety and continuity. Strict propriety is the claim that:

_E_ _p_ _s_ ( _p_ ) > _E_ _p_ _s_ ( _c_ ) whenever _c_ is a credence other
than _p_

for any probability _p_. In words, by the lights of a probability _p_ , then
we get the best expected epistemic utility if we make _p_ be our credence.

Now, if I am not convinced by the argument that (1) should hold for any
probability _p_ and any credence _c_ other than _p_ , then I will be unmoved
by the scoring rule argument for probabilism. So suppose that I am convinced.
But recall that I think that credences in _M_ are just as rationally good as
the probabilities in _P_. Because of this, if I find (1) convincing for all
probabilities _p_ , I will also find it convincing for all credences _p_ in
_M_ , where _E_ _p_ is my preferred way of calculating expected utilities—say,
a level set integral.

Thus, if I am convinced by the argument for strict propriety, I will just as
much accept (1) for _p_ in _M_ as for _p_ in _P_. But now we have:

**Theorem 1.** If _E_ _p_ is strongly monotonic for all _p_ ∈ _P_ ∪ _M_ and
coincides with mathematical expectation for _p_ ∈ _P_ , and (1) holds for all
_p_ in _P_ ∪ _M_ , where _M_ is non-empty, then _s_ is not continuous on _P_.

(Strong monotonicity means that if _U_ < _V_ everywhere then _E_ _p_ _U_ < _E_
_p_ _V_. The Theorem follows immediately from the Pettigrew-Nielsen-Pruss
domination theorem.)

Suppose then that I am convinced that a scoring rule _s_ should be continuous
(either on _P_ or on all of _P_ ∪ _M_ ). Then the conclusion I am apt to draw
is that there just is no scoring rule that satisfies all the desiderata I
want: continuity as well as (1) holding for all _p_ ∈ _P_ ∪ _M_.

In other words, the only way the argument for probabilism will be convincing
to me is if my reason to think (1) is true for all _p_ in _P_ is significantly
stronger than my reason to think (1) is true for all _p_ in _M_ , _and_ I have
a sufficiently strong reason to think that there is a scoring rule that
satisfies all the true rational desiderata on a scoring rule to conclude that
(1) holding for all _p_ in _M_ is not among the true rational desiderata even
though its holding for all _p_ in _P_ is.

And once I additionally learn about the difficulties in defining sensible
scoring rules on infinite spaces, I will be less confident in thinking there
is a scoring rule that satisfies all the true rational desiderata on a scoring
rule.

Suppose that a process _Q_ has a chance _r_ of producing some non-
instrumentally bad result _B_ , and nothing else of relevance. That fact gives
us reason not to actualize _Q_. But suppose _Q_ is actualized. Is it bad?

Well, if it’s bad, it seems it’s only instrumentally bad. It is no worse to be
killed by a well-aimed arrow than by a well-aimed bullet, even though in the
case of the well-aimed arrow the process of a deadly projectile’s flight lasts
longer. Yet if a process producing a bad result were non-instrumentally bad,
it would be worse if it lasted longer.

_Q_ is instrumentally bad if and only if _B_ does not eventuate.

Option (4) is crazy. Option (2) destroys the very idea of an instrumental bad.
So that leaves options (1) and (3).

If we opt for option (1), then we can have a world that contains instrumental
bads without any non-instrumental bads—just imagine that _Q_ obtains, _B_ does
not eventuate, and nothing else that’s bad ever happens. This seems a little
counterintuitive: instrumental bads are derivatively bad, but how can
something be derivatively bad without anything that is non-derivatively bad?

That suggests we should go for option (3): a process that has a chance of
leading to a non-instrumental bad is bad only when the non-instrumental bad
eventuates.

But now imagine Molinism is true. Suppose that God knows that _Q_ , if
actualized, would _not_ lead to _B_ , even though it has a non-zero chance _r_
of doing so. In that case, the fact that _Q_ has a chance _r_ > 0 of leading
to _B_ is no reason for God not to actualize _Q_. But that something is bad is
always a reason not to actualize it. If instrumental bads are an exception for
this, then instrumental bads aren’t bads.

Now, I think Molinism is false. But whether (3) is true should not, it seems,
depend on whether Molinism is true. So if (3) is false on Molinism, it is
simply false.

Maybe the right move is this. Fake money isn’t money and merely instrumental
bads aren’t bad. This allows us an escape from the Molinism argument. For if
merely instrumental bads aren’t bad, there is no problem about the fact that
the Molinist God has no reason not to produce them.

Another move might be to say that (3) is true, but disproves Molinism. This
doesn’t strike me as right, but maybe it’s defensible.

Until this is resolved, one really shouldn’t be running any arguments that
depend on instrumental bads being actually bad.

###  The intrinsic badness of certain future tensed facts on presentism

It is bad that tomorrow someone will be in intense pain. On eternalism, we can
easily explain this: tomorrow’s pain is just as real as today’s. But on
presentism and growing block, future pains don’t exist.

Presumably, the presentist and growing blocker will say that the tensed fact
of there being an intense pain tomorrow is bad, and this bad tensed fact
presently exists.

Is this badness of the future tensed fact about the pain an instrumental or
non-instrumental badness? If it’s instrumental, it is not clear what it could
be instrumental to. The main candidate (apart from special cases where there
is an obvious candidate, such as when the pain leads to despair) is that the
fact that there will be a pain tomorrow is instrumental to tomorrow’s pain.
But the fact that tomorrow there will be pain won’t cause that pain—otherwise,
it would be _trivial_ that every future event has a cause.

So the present badness of there being a pain tomorrow would be non-
instrumental. But now imagine two scenarios with finite time lines.

Scenario _A_ : There is a mindless universe with a day of random particle
movement, followed by the formation of a brain which has intense pain for a
minute, followed by the end of time.

Scenario _B_ : There is a mindless universe with a century of random particle
movement, followed by the formation of a brain which has intense pain for a
minute, followed by the end of time.

Let’s suppose we find ourselves at the last moment of time in one scenario or
the other. Then in Scenario _A_ , there was a day of the obtaining of a
“future pain fact”, and in Scenario _B_ , there was a century of the obtaining
of a “future pain fact”. If a future pain fact is a non-instrumentally bad
thing, then there was non-instrumentally bad stuff in Scenario _B_ for a much
longer period of time than in Scenario _A_ , and so Scenario _B_ is much worse
than Scenario _A_ with respect to future pain. But that seems mistaken: the
greater length of time during which there is a future pain fact does not seem
any reason to prefer one scenario over another.

English is not my native language, but the last sentence shouldn't be rather
phrased like this?  
  
 _"The greater length of time during which there is a future pain fact does
not seem_ [to be] _any_ [or some] _reason_ [for preferring] _one scenario over
another."_  
  
Is this correct? Does that "seem" to be that way?  
Well, it seems to me at least, that you rather wanted to state and claim there
the following:  
"The greater length of time during which there is a future pain fact is no
rational reason for preferring one scenario over another."  
  
Did you rather mean that there?  
Really, is that no good and rational reason?!?  
Why are you so ignorant and blind regarding to reasons - to good and rational
reasons?!?

Besides in both scenarios there is intense pain for a minute in the future.
How appears one scenario to be worse than the other one?!?  
Because of "presentism"-existential pain?!?  
Hahahahahahhahahahahahahahahahh.....

For this post, suppose that an A-theory of time is true, so there is an
absolute present. If we think of possible worlds as fully encoding how things
can be so that:

A proposition _p_ is possible if and only if _p_ holds at some world,

then we live in different possible worlds at different times. For today a
Friday is absolutely present and tomorrow a Saturday is absolutely present,
and so how things are is different between today and tomorrow (or, in terms of
propositions, that it’s Saturday is false but possible, so there must be a
world where it’s true). In other words, given (1), the A-theorist is forced to
think of worlds as tensed, as centered on a time.

But there is something a little counterintuitive about us living in different
worlds at different times.

However, the A-theorist can avoid the counterintuitive conclusion by limiting
truth at worlds to propositions that cannot change their truth value. The most
straightforward way of doing that is to say:

If ( _p_ or _q_ ) is true at a world _w_ then _p_ is true at _w_ or _q_ is
true at _w_.

For the disjunction that it’s Friday or it’s not Friday is true at some world,
since it’s a proposition that can’t change truth value, but neither disjunct
can be true at a world by (2).

Alternately, we might limit the propositions true at a world to those
expressible in B-language. But if our A-theorist is a presentist, then this
still leads to a rejection of (3). For on presentism, the fundamental
quantifiers quantify over present things, and the quantifiers of B-language
are defined in terms of them. In particular, the B-language statement “There
exist (tenselessly) dinosaurs” is to be understood as the disjunction “There
existed, exist or will exist dinosaurs.” But if we have (3), then worlds will
have to be tensed, because different disjuncts of “There existed, exist or
will exist dinosaurs” will hold at different times. A similar issue comes up
for growing block.

So on the most popular A-theories (presentism and growing block), we have to
either allow that we inhabit different worlds at different times or deny (3).
I think the better move is to allow that we inhabit different worlds at
different times.

Amateur A-theorist and presentist here, and I affirm that different times are
different possible worlds. (This was a conclusion I had already arrived at
before reading your blog post.) I don't find this to be unintuitive.

What about this? (I'm writing this on the fly so there's bound to be some
shortcomings, but hopefully it gestures to something ultimately workable)
A-Theorists can identify worlds as maximal sets of pairs [w,t] where w is a
world understood as a maximal proposition including propositions which change
truth value ('it is now Friday', WAS(q), etc.) and t is a time (perhaps a
maximal present tense proposition, so 'it is now Friday', but no WAS(q) etc.).  
  
Then, a possible world is just such a set where each w could be true in a
sequence given by the order placed on the t's. So W = {[w1,t1], [w1,t2]} (with
t1 < t2) is not possible if, say, w1 includes WAS(p) and w2 includes ~WAS(p).  
  
Finally, a world is maximal just in case it is not a subset of a larger world.
This is to rule out worlds containing just the temporal slices of the last 100
years, say. This shouldn't cause any problems with pairs of worlds otherwise
alike except for the second world being 1 second longer, because the final
element of the former world will include ~WILL(p) whereas the penultimate
element of the latter will include WILL(p) for some p.  
  
What does this mean for (3)? It probably renders (3) ill-formed. Perhaps the
fundamental locution should be: p is true at t in W. Then of course, p is true
at t in W iff p is a conjunct of some w such that is an element of W. Suitably
amended, (3) should come out true. We also don't have the problem of living in
different worlds at different times. (I'll leave it to open futurists to amend
this to make sense on their model).

All of the counterintuitiveness seems to arise from taking the term 'possible
worlds' as a literal description rather than a label that became attached to a
certain kind of logical object due to the history of the field. However:  
  
(1) Nothing actually requires that possible worlds be literally worlds; if
something can be represented by consistent sets of truth-valued propositions,
you can apply possible worlds semantics to it, even if you are not dealing
with worlds.  
  
(2) We don't live 'in' possible worlds but in the actual world, which is
always at every point represented at the level of possibilities by many, many
different possible worlds. Thus what really changes across time is not what
possible world one 'lives in', but what possible worlds are accessible in the
manifold of all possible worlds. This is, so far from being counterintuitive,
exactly the principle by which one represents temporal modalities in possible
world semantics.

An action is unjust if society has a utility-based reason to punish that
actions of that type.

An action is wrong if there is utility-based reason not to peform that action.

Mill writes as if the unjust were a subset of the wrong. But it need not be.
Suppose that powerful aliens have a weird religious view on which dyeing one’s
hair green ought to be punished with a week in jail, and they announce that
any country that refuses to enforce such a punishment as part of the criminal
code will be completely annihilated. In that case, according to (1), dyeing
one’s hair green is unjust. But it is not guaranteed to be wrong according to
(2). The pleasure of having green hair could be greater than the
unpleasantness of a week in jail, depending on details about the prison system
and one’s aesthetic preferences.

The problem with (1), I think, is that utility-based reasons to punish actions
of some type need have little to do with moral reasons, utilitarian or not,
against actions of that type.

There are three big mysterious aspects of the concrete world around us:

The three mysteries are interwoven. Teleology is the domain of the interplay
of the causal and the normative. And the mental always comes along with the
normative, and often with the causal.

There is no hope of reducing the normative or the mental to the causal. Some
have tried to reduce the normative to the mental, either via relativism
(reducing to the finite mental) or Plantingan proper functionalism (reducing
to the divine mental), neither of which appears particularly appealing in the
end. I’ve toyed with reducing the mental to the normative, but while there is
some hope of making progress on intentionality in this way, I doubt that there
is a solution to the problem of consciousness in this direction.

Theism provides an elegant non-reductive story on which the three mysterious
aspects of concrete reality are all found interwoven in one perfect being, and
indeed follow from the perfection of that perfect being.

I wonder, too, if there is some way of seeing the three mysteries as
reflective of the persons of the Trinity. Maybe the Father, the ultimate
source of the other persons, is reflected in causality. The Son, the Logos, in
the mental. And the Spirit, the loving concord of the Father and the Son may
be reflected in the normative. But such analogies can be drawn in many ways,
and I wouldn’t be very confident of them.

Alex  
  
Nothing can be 'interwoven' in a simple being.

Suppose the future is open. Then it is not true that tomorrow Jones will
freely mow the lawn. Moreover, it is _necessarily_ not true that Jones will
freely mow the lawn, since on open future views it is _impossible_ for an open
claim about future free actions to be true. But what is necessarily not true
is impossible. Hence it is impossible that Jones will freely mow the lawn. But
that seems precisely the kind of thing the open futurist wishes to avoid
saying.

What's impossible is the proposition 'WILL(Jones freely mows thee lawn)'. This
is consistent with the truth of 'Jones freely mows the lawn'. The former
proposition (like all propositions) is about how the world is _right now_ ,
not about what's happening at some future moment (at least on presentism,
where most of the open futurists reside). p is not logically equivalent to
WAS(WILL(p)).

Me again. It just occurred to me that another way to capture the difference is
to focus on the relative scope of the POSSIBLE and WILL operators. So the
presentist open futurist should insist that ~POSSIBLE(WILL(Jones freely mows))
whilst also maintaining WILL(POSSIBLE(Jones freely mows lawn)). I think you
take it that former entails the negation of the latter? (or even entails
simply that ~POSSIBLE(Jones freely mows) ?). But this neglects the different
scopes at play.

Okay. I suppose the future to be open as you said, that in your first sentence
_"Suppose the future to be open."_.  
So then possibly Jones will freely mow the lawn tomorrow as possibly Jones
will freely not mow the lawn tomorrow, if we also suppose there being "free
will".  
Now **it's not necessarily the case** , that Jones will freely mow the lawn
tomorrow, **if and only if it is possibly the case** , that Jones will not
freely mow the lawn tomorrow: _~□(proposition P) ⇔ ◇(~P)._  
Also **it's necessarily not the case,** that Jones will freely mow the lawn
tomorrow, **if and only if it is not possibly the case** , that Jones will
freely mow the lawn tomorrow: _□(~P) ⇔ ~◇(P)_.  
 **But since we supposed to suppose the future to be open [ _◇(P) Λ ◇(~P)_ ],
then how are we supposed to suppose, that ~◇(P) or □(~P) could ever be the
case?!?**  
So then what are you, Alexander, talking about again?  
EITHER I don't understand the notion of "open future" or we understand
different things under the notion of "open future" OR the "inconsistent
narrator" is at it's best again producing an inconsistent narration - you
unreasonably twisting logic itself - not properly making a quantifier shift or
mish mashing different quantifiers with each other.("Necessity □" and
"possibilty ◇" are just modal logical quantifiers - logically working
similarly to the usual quantifiers all/any ∀ and "some ∃".)

This would prove too much as it would prove that a denial of Molinism is
false.  
  
Suppose there are no true subjunctive conditionals. Then it is not true that
Jones would freely mow the lawn (in some hypothetical scenario S). Moreover,
it is necessarily not true that Jones would free mow the lawn, since on a non-
Molinism view, it is impossible for conditionals regarding free actions to be
true. But what is necessarily not true is impossible. Hence it is impossible
that Jones would freely mow the lawn in S. But that is precisely the kind of
thing that any libertarian would want to avoid saying.  
  
I think the way out of your problem and my parody is to say that the modal
operator modifies the entire statement. In my case, it modifies the
conditional and in yours it modifies the future. For example, it is impossible
that Jones would freely mow the lawn in S. But not because wouldn't mow the
lawn in S, but rather, because any statement about what he would do in S is an
impossible statement. There is no such thing. Likewise, for open future views,
the claim that Jones will mow the lawn is necessarily false. Not because he
will in fact mow the lawn, but because any proposition about future free
conditionals is necessarily false.

Zsolt:  
  
What people generally mean by open future is that there are no facts about
what will contingently happen: i.e., ~WILL(p) and ~WILL(~p).

ASBB:  
  
That's one option for the open futurist. But ~POSSIBLE(WILL(Jones mows the
lawn)) still sounds wrong. Mowing the lawn differs relevantly from squaring
the circle.

If there are no facts about what will contingently happen, then it's not, that
~WILL(p) AND ~WILL(~p).  
If there are no current facts about what will contingently happen, then WILL(p
OR ~p) = WILL(p) OR WILL(~p) = WILL(p) OR ~WILL(p).  
  
~WILL(p) AND ~WILL(~p) = WILL(~p AND p) = WILL(logical contradiction).  
I still think very much so, that you are simply logically inconsistent here.

Well, to be more precise I guess, that these are the logical
implications/biconditionals, which are satisfied by the predicate "WILL":  
(I) For any proposition p: ~WILL(p) ↔ WILL(~p)  
(II) For any proposition p and q: WILL(p AND q) ↔ (WILL(p) AND WILL(q))  
  
(corollary) For any proposition p and q: WILL(p OR q) ↔ (WILL(p) OR WILL(q))  
Proof:  
1.0) ~(WILL(p OR q) ↔ (WILL(p) OR WILL(q))) (indirect proof assumption)  
1.1) (~WILL(p OR q) AND (WILL(p) OR WILL(q))) OR (WILL(p OR q) AND ~(WILL(p)
OR WILL(q))) (1.0, by logical equivalence)  
1.2) (WILL(~(p OR q)) AND (WILL(p) OR WILL(q))) OR (WILL(p OR q) AND (~WILL(p)
AND ~WILL(q))) (1.1, by I and De Morgan's law)  
  
  
1.3) (WILL(~p AND ~q) AND (WILL(p) OR WILL(q))) OR (WILL(p OR q) AND (WILL(~p)
AND WILL(~q))) (1.2, by De Morgan's law and I)  
1.4) ((WILL(~p AND ~q) AND WILL(p)) OR (WILL(~p AND ~q) AND WILL(q))) OR
(WILL(p OR q) AND WILL(~p AND ~q)) (1.3, by AND dirstribution over OR and II)  
1.5) (WILL((~p AND ~q) AND p) OR WILL((~p AND ~q) AND q)) OR WILL((p OR q) AND
(~p AND ~q)) (1.4, by II)  
2) WILL(p OR q) ↔ (WILL(p) OR WILL(q)) (1.0-1.5, by indirect proof)  
  
How on earth and by which logic does the assumption of an "open future"
supposed to entail, that ~WILL(p) AND ~WILL(~p)?!? I still don't get it,
what's the matter here.

Zsolt:  
  
The "open future" view says basically that in the case of a future contingent,
WILL(p) is not true. Thus, it is not true that Jones will mow the lawn, since
"Jones will mow the lawn" would be a future contingent. Similarly, it is not
true that Jones will not mow the lawn.  
  
There are two main versions of the view:  
1\. WILL(p) is neither true nor false  
2\. WILL(p) is false.  
(But both agree that WILL(p) is not true.)  
  
Additionally, there is disagreement as to whether  
3\. WILL(p) iff True(WILL(p)).

According to wavefunction realism, we should think of the wavefunction of the
universe—considered as a square-integrable function on _R_ 3 _n_ where _n_ is
the number of particles—as a kind of fundamental physical field.

Here are two interesting consequences of wavefunction realism. First, it seems
like it should be logically possible for the fundamental physical field to
take any logically coherent combination of values on _R_ 3 _n_. But now
imagine that the initial conditions of the wavefunction “field” are have it
take a combination of values that is not a square-integrable function, either
because it is nonmeasurable or because it is measurable but non-square-
integrable. Then the Schroedinger equation “wouldn’t know” what to do with the
wavefunction. In other words, for quantum physics to work, given wavefunction
realism, we need a very special initial combination of values of the
“wavefunction field”. This is not a knockdown argument, but it does suggest an
underexplored need for fine-tuning of initial conditions.

I don't think you have a guarantee of a continuous solution in the 1D case,
even with a finite continuous potential, if the initial values of the
wavefunction are not themselves continuous.

The time evolution operator e^{−iHt} on the Hilbert space is unitary. In the
1D case, the Hilbert space can be written as L^2(R). Take any discontinuous v0
in L^2(R) (e.g., the function which is 1 on [0,1] and 0 outside [0,1]). Let
v(t) = e^{-iHt} v0 be the application of the unitary time evolution operator
to v0. Then v(t) corresponds to a solution of the Schrodinger equation in the
distributional sense, with discontinuous initial condition v0. I may be
missing something--it's been decades since I've taken a class in QM, and I am
more comfortable with vector spaces than differential equations.

Actually, I think you can just set V=0, but I haven't checked the details.

If _F_ is a contingent fact solely about physical reality that does not depend
on creaturely free choice, then God can effectually will an exact duplicate of
_F_.

Assumption (1) is a central claim of the A-theory of time, in fact form.
Assumption (2) is a hedged consequence of omnipotence, formulated to take into
account the possibility of uncreatable Platonic entities and the essentiality
of origins.

We now have a problem. Let _B_ be the tensed fact that the Big Bang occurred
billions of years ago. This is a contingent fact solely about physical reality
that does not depend on creaturely free choice. So, by (2), God can
effectually will an exact duplicate of _B_. But an exact duplicate of _B_
would still be a tensed fact about what happened billions of years ago. And to
will such a fact about the past would be backwards causation, contrary to (3).

Note how the problem disappears if we don’t have tensed facts. For then all we
have is an untensed fact such as that the Big Bang occurs at _t_ 0, and God
can will that without backwards causation, whether God is in time (e.g., he
can then will it at _t_ 0) or outside time.

I personally don’t have a problem with backwards causation. But a lot of
A-theorists do.

I suppose what the A-theorist should do is to replace (2) with:

If _F_ is a contingent fact solely about physical reality that does not depend
on creaturely free choice, then God can effectually will a _perhaps re-tensed_
exact duplicate of _F_.

Assuming there is no change in God, how is it backwards causation?

But the "today" and "yesterday" of God's will are only distinctions in
reference to creatures. They're not distinctions in the actual will of God as
that is outside of time. It's only causation in the since that it's eternally
accounted for by God. I don't see how the temporal direction (in reference to
creatures) of this type of causation matters to the A-theorist. For example, I
don't see why an A-theorist would be okay with praying for some future
intention but not okay with praying for the soul of someone who has long since
died.

Sir  
  
I apologize in advance this is a question irrelevant to the Topic. Iam
teenager interested in Philosophy of Religion and Mind. Iam New to Philosophy  
  
Does Essentiality of Origins Pose a Problem for The Leibiniz Cosmological
Argument?

Don:  
  
God's point of view is the correct point of view. If from God's point of view,
there is no objective present, then there is no objective present.  
  
Walter:  
  
Despite some efforts to argue to the contrary, I don't think God can be a
timeless being if the A-theory is correct.

God's pov is outside of time so I don't see how it's relevant to temporality.

Dr. Pruss,  
  
I don't see how your last comment isn't different from saying: if from God's
pov there is no change (meaning He is immutable) then there is no objective
change. I don't see why the fact that God's mode of existence is not a
creaturely mode of existence should dismiss the mode of existence of creatures
as not objectively real.

(2) seems strange to me. It states that God can effectually will an exact
duplicate of a fact. If a fact here means a proposition, then that means God
can will the duplicate of a proposition. What does that mean? That He creates
another abstract object? Or that He wills an duplicated truthmaker of this
proposition?

Don:  
  
If God's point of view is outside temporality, in such a way that God doesn't
know which time is objectively present, and if the A-theory is true so that
some time IS objectively present, then God isn't omniscient, because there is
some objective truth that he doesn't know.  
  
AS:  
  
Here, I am thinking of facts as concrete states of affairs, not as true
propositions.

Dr. Pruss,  
  
Knowing time is a creaturely operation. It's the product of a creaturely mind
since it's the measure of change. No mind experiencing change means no time.
God not knowing the present, past, and future *as* present, past, and future
(which can only happen by means of temporal experience) doesn't impinge his
omniscience any more than does His not knowing the color red by means of
sight.

To clarify my last point: God knows the present, past, and future but not *as*
present, past, and future--ie, not by temporal means.

Dr Pruss, I'd like to ask few questions. I will be happy if you reply.  
  
Sir If we need to escape Modal Collapse Should we accept an indeterministic
Link between God and his Effects?  
  
If we Do, Does God Have no control over his effects? And Does it reduce God as
an Intentional Agent?  

I have a question,  
  
P1. Every fact has an explanation.  
P2. It is a fact that God is necessary.  
  
C1. The fact that God is necessary has an explanation  
  
  
Doesn't God's necessity itself need an explanation?

Don:  
  
It either is or is not an objective mind-independent fact that 2022 is
present. If it is an objective mind-independent fact, God had better know it.
If it is not an objective mind-independent fact, then we have a B-theory of
time.

Since when does accepting B-theory of time have the implication of assuming
there to be no time at all or time being non-existent?!?  
If accepting of B-theory of time has any implications, then the implications
are, that there is time or that time exist - the past and future events are as
real as the current event and moment in time.  
  
By the way accepting A-theory of time also has the implication of there being
time or that time exists. But A-theory also implies, that only the current
event or moment is real. Past and future events are not real or at least not
as real as the current event or moment in time.  
  
Does William Laine Craig really think, that accepting B-theory of time would
imply there to be no time at all?!?  
I don't think so, but if that's so, then I guess, that this is just a big
misunderstanding of what each theory of time does or might imply from some
non-particular persons here.

"There would be no change, only differences between points in time": But
differences between points in time ARE changes. :-)

Alexander R Pruss:  
  
I guess the differences between the points in time would be changes. I have
problems understanding causation with eternalism. Did God eternally cause the
Big Bang, which then eternally caused the next states in the Universe? Or did
God cause the entire Universe eternally, while leaving humans free?  
  
I also have some other questions. Is eternalism the only B-theory of time? Do
you know of any other theories? Do you have any good resources on theories of
time?

Hey Dr. Pruss, I think we have Zsolt's burner account here lol

Zsolt: While the civility of your recent comments has improved significantly,
this is not the forum for critique of Bill Craig, but for discussion of *my*
arguments. Please don't make me have to waste time moving to a moderation
system for comments.

Here’s perhaps a simple way to make my argument go (I am grateful to Dean
Zimmerman for suggestions that helped in this reformulation). If infinite time
is a central feature of reality, as the temporalist says, then one of the most
fundamental things for God to decide about the structure of creation is which
of these three is to be true:

There is creation but it doesn’t go infinitely far back in time.

But without backwards causation, a temporal God cannot decide between (2) and
(3). For at any given time, it’s already settled whether (2) or (3) is the
case.

Now, it seems that the temporalist’s best answer is to deny the possibility of
(2). We don’t expect God to choose whether to create square circles, and so if
we deny the possibility of (2), God only needs to choose between (1) and (3).

But there are two issues with that. First, creation going infinitely far back
in time is the temporalist’s best answer to the Augustinian question of why
God waited as long as he did before creating—on this answer (admittedly
contrary to Christian doctrine), God didn’t wait.

Second, and perhaps more seriously, there is the question of justifying the
claim that (2) is impossible. There are four reasons in the literature for
thinking that _in fact_ creation has a finite past:

None of these allow the temporalist to justify the impossibility of creation
going infinitely far back in time. Big Bang cosmology is contingent, and does
not establish impossibility. And if the arguments (ii) and (iii)  
are good reasons for rejecting an infinite past of creation, they are also
good reasons for rejecting divine temporalism, since divine temporalism would
require God to have lived through an actually infinite time. And (iv) also
seems to rule out divine temporalism. For suppose that in fact creation
follows an infinite number of days without creation. During that infinite
number of days without creation, on any day we could ask why nothing exists.
And the answer is that God didn’t decide to create anything. So the emptiness
of the empty day causally depends on God’s infinitely many decisions in days
past not to start creating yet, contrary to causal finitism.

Consider the assertions in this paper: arxiv.org/pdf/2011.02348.pdf by Nicolas
Gisin. In it, Gisin states that allowing real numbers to actually be a part of
the physical universe would imply infinite information at the start of the
universe (information being present in the real number's decimal expansion's
nonterminating nature).  
  
Would this mean that your "no infinite causal chains principle" would also
keep any typical real number (of the type that is unstructured in its decimal
expansion) from having any causal role in its full value?  

Imagine this unfortunate sequence of events will certainly befall you in a
classical universe:

While asleep, your memory will be reset to that which you had in step (1).

You will be made to fall asleep for a third time.

While asleep, your memory will be reset again to that which you had in step
(1).

How likely is it that you will be shown a green shape?

How likely is it that you will be shown a red shape?

The answers to these questions are obviously: one and one. You will be shown a
green shape twice and a red shape one, and that’s certain.

Now consider a variant story where personal identity is not maintained in
sleep. Perhaps each time in sleep the person who fell asleep will be
annihilated and replaced by something that is in fact an exact duplicate, but
that isn’t identical with the original according to the correct metaphysics of
diachronic personal identity. (We can make this work on pretty much any
metaphysics of diachronic personal identity. For example, we can make it work
on a materialist memory theory as follows. We just suppose that before step
(1), you happen to have three exact duplicates alive, who are not you. Then
during the _n_ th sleep cycle, the sleeper is annihilated, and a fresh brain
is prepared and memories will be copied into it from your _n_ th doppelganger.
Since these memories don’t come from you, the resulting brain isn’t yours.)

And in the variant story, let’s ask the questions (10) and (11) again. What
will the answers be? Again, it’s easy and obvious: zero and zero. You won’t be
shown any shapes, because you will be annihilated in your sleep before any
shapes are shown.

Now consider Everettian branching quantum mechanics. Suppose there is a
quantum process that will result in your going to sleep in an equal
superposition of states between having a red square, a green triangle and a
green circle in front of your head, so that upon waking up an observation of
the shape will be made. Now ask questions (10) and (11) again.

I contend that this is just as easy as in my classical universe story. Either
the branching preserves personal identity or not. If it preserves personal
identity, the answer to the questions is one and one. If it fails to preserve
personal identity, the answer to the questions is zero and zero. The only
relevant ontological difference between the quantum and classical stories is
that in the quantum stories the wakeups might count as simultaneous while in
the classical story the wakeups are sequential. And that really makes no
difference.

In _none_ of the four cases—the classical story with or without personal
identity and the branching story with or without personal identity—are the
answers to the questions 2/3 and 1/3. But those are _in fact_ the right
answers in the quantum case, contrary to the Everett model.

Now, one might object that we care more about decisions than predictions.
Suppose that you have a choice between playing a game with one of two three-
sided fair quantum dice:

And suppose pain will be induced if and only if the die comes up red. Which
die should you prudentially choose for playing the game? Again, it depends on
whether personal identity is preserved. If not, it makes no difference. If
yes, clearly you should go for die _A_ on the Everett model—and that is indeed
the intuitively correct answer. But the reason for going for die _A_ on the
Everett model is different from the reason for going for it on a non-branching
quantum mechanics. On the Everett model, the reason for going for die _A_ is
that it’s better to get pain once (die _A_ ) rather than twice (die _B_ ).

So far so good. But now suppose that you’ve additionally been told that if you
go for die _A_ , then before you roll _A_ , an irrelevant twenty-sided die
will be rolled. (This is a variant of an example Peter van Inwagen sent me
years ago, which was due to a student of his.) Then, intuitively, if you go
for die _A_ , there will be twenty red branches and forty green branches on
Everett. So on die _A_ , you get pain twenty times _if_ personal identity is
preserved, and on die _B_ you get pain only twice. And so you should surely go
for die _B_ , which is absurd.

One might reasonably object that there are in fact infinitely many branches no
matter what. But then on the no-identity version, the choice is still
irrelevant to you prudentially, while on the identity version, no matter what
you do, you get pain infinitely many times no matter what you choose. And that
doesn’t work, either. And if there is no fact about how many branches there
will be, then the answer is just that there is no fact about which option is
preferable on the identity version, and on the no-identity version,
indifference still follows.

This is all basically well-known stuff. But I like the above way of making it
vivid by thinking about classically sequentializing the story.

Because of "personal identity" or to really say, that because of "subjective
reality"?!?  
What? I don't get it.  
I mean, if I were to be asking (M10) _"How **likely** is it that you will be
shown a green shape?"_ and (M11) _"How **likely** is it that you will be shown
a red shape?"_  
and that person from that scenario might response and answer with:  
(Y12) _"The answers to these questions are obviously: one and one. I will be
shown a green shape twice and a red shape one, and that’s certain."_  
Then my response would be:  
(M13) _"First of all it is quite remarkable, how you can answer my questions,
when you have been permanently annihilated given (9). Or "will" that be the
case? Ups. Spoiler Alert!  
Second of all, "One and one." are not even considered answers to my questions.
So I reiterate my questions here:  
(M10) "How **LIKELY** is it that you will be shown a green shape?"  
(M11) "How **LIKELY** is it that you will be shown a red shape?"  
Third of all, how can you know, that "[You] will be shown a green shape twice
and a red shape one, and that’s certain.", when your memory has been actually
reseted two times given (4) and (7)? Or again those cases "will" be the case?
Ups. Another Spoiler Alerts!"_  
That person from that scenario again:  
(Y14) _"To your second point: Ahh. Now I get it. It will depend on the
distribution of shown green and non-green shapes as it will depend on the
distribution of shown red and non-red shapes, how **LIKELY** it will be, that
I will be shown a green shape and/or a red shape. Of course. How could I ever
forget being a frequentist. Duh.  
To your first and third point: What?!? And I don't know, maybe?!? I'm just a
character and imagination of a person, maybe?!? Maybe ask the narrator, why is
he so inconsistent with his narration? Again, I don't know."_  
  
I have so many questions. I guess the most important one from me is the
following:  
 **What exactly is "personal identity"? And how exactly does that relate to an
objective reality?**  
Your example doesn't explain, what exactly "personal identity" is supposed to
be.  
I guess, that wasn't your intent. Fair enough! You can assume for your given
example, that the reader knows exactly, what "personal identity" is supposed
to be. But it appears to me, that you think, that your given example somehow
explains or shows, how "personal identity" can relate or is related to an
objective reality.  
Am I correct with this impression of mine? Is that given example/scenario of
yours explaining or demonstrating that?!?  
If so, then I'm so confused.  
 **How is _"One and one. You will be shown a green shape twice and a red shape
one, and that’s certain."_ such an "obvious" and trivial or rational answer to
anything here?!?**  

Imagine the following unfortunate events happening to Fred simultaneously at
the current moment:  
  
(1) Fred has never married before. Hence, Fred is currently a bachelor.  
(2) Fred is marrying at the current moment. Hence, Fred is married currently.  
  
So obviously Fred identifies himself to be a "married bachelor" at this
current moment, because one green shape and one red shape equals to be two
shown green shapes and one shown red shape.  
I mean, that's the only rational thing, which can be thought of here.  

Personal identity is easy. There is personal identity between x and y iff x is
a person, y is a person and x is the same entity as y. :-)  
  
I don't see any reason to measure with Lebesgue measure here. Take a non-
quantum example. Suppose you're a two-dimensional being and are about to
fission into continuum many two-dimensional future selves, stacked along the
third dimension between z=0 and z=1 (each future self to one z-value).  
  
Option 1: The future selves between z=0 and z=0.6 are in pain and the future
selves between z=0.6 and z=1 are OK.  
  
Option 2: The future selves between z=0 and z=0.6 are OK and the future selves
between z=0.6 and z=1 are in pain.  
  
By Lebesgue measure, you should prefer option 2, since the measure of those
that are OK in Option 2 is 0.6 and the measure of those that are OK in Option
1 is 0.4. But why should the _position_ of the selves matter at all? I can see
how _counting_ them matters, but then on both options equal cardinalities are
OK and in pain.  
  
Now imagine this. As soon as the pains are induced, the selves are moved, so
that the self at coordinate z gets moved to z^2. After the movement:  
  
Option 1: Pain is had by those now at coordinates between z=0 and z=0.36.  
  
Option 2: Pain is had by those now at coordinates between z=0.36 and z=1.  
  
Now it looks like Option 1 is better by Lebesgue measure. But simply moving
the slices around doesn't actually change anything important! So the Lebesgue
measure doesn't matter.

Ah, so that's "personal identity".  
And how does that amount or relate to an objective perspective of the actual
world?!? ;-)  
  
Did you know, that once something happened in the past, then that's fixed.  
Sure. One might be able to move points on the space axes from left to right
and from right to left or from z to z². But how does that exactly supposed to
work on the time axes?!?  
Besides that yes, there are reasons to use Lebesgue measure - to be more
precise there is a century, the last century amount of physics and confirmed
hypothesis of quantum mechanics relying on the Lebesgue measure - a lot of
reasons for using Lebesgue measure.  
I know, you are more of an _a priori_ knowledge or _prime face_ guy. You know,
I'm more of an _a posteriori_ knowledge guy - I can not simply ignore such
theories resulting in confirmed results and predictions physically measured to
such a high precision and accuracy - to the most precision and accuracy of
science history to this current date. That's not my thing.

According to _pure divine temporalism_ , God is a being in time without a
timeless existence all of whose decisions are made at moments of time.

I will argue that on plausible assumtions divine temporalism is incompatible
with divine creative libertarian freedom.

If pure divine temporalism is true, time has no beginning in the sense that
before every moment of time, there was an earlier moment.

This is because everyone agrees that God is eternal. If there were a moment
that had no moment before it, then according to pure divine temporalism, that
moment would be God’s first moment of existence, without any timeless
existence prior to or beyond it, and that is just incompatible with divine
eternity. At that first moment it would be correct to say that God has just
appeared.

One might object by saying that the first moment has infinite duration, and so
it was an infinitely long changeless state. This is difficult to understand.
An infinitely long changeless state seems like a timeless state more than
anything else. In any case, if the point is pressed, I will simply stipulate
that I don’t allow for moments like that.

Every contingent feature of creation not even partly due to creaturely
indeterministic activity was decided on by God with God having had the
possibility of deciding otherwise. (Divine creative libertarian freedom)

The fact _N_ that there was a moment of time before which there were no stars
obtains.

The fact _N_ is a contingent feature of creation not even partly due to
creaturely indeterministic activity.

Time is linearly ordered: for any distinct moments of time _t_ 1 and _t_ 2,
one is earlier than the other.

What do we have? Well, our assumptions imply that God at some time decided on
_N_ while yet having the possibility of deciding to the contrary. But prior to
any past time _t_ 1, the fact _N_ was already in place. History by time _t_ 1
already made it be the case that there was a time before which there were no
stars. So if there is no backwards causation, at no past time _t_ 1 did God
have the possibility of making _N_ _not_ be true. It was always already too
late! But divine creative libertarian freedom requires that possibility.

**Objection 1:** The fact _N_ does not actually obtain. We live in a
sequential multiverse and before every time there were already stars in our
universe or another.

**Response:** In that case, let _S_ be the following contingent feature of
creation: it was always the case that there already had been at least one
star. I.e., for any past time _t_ , there was a time _t_ ′ < _t_ at which
there had already had been at least one star. And an argument similar to the
above goes through with _S_ in place of _N_. At any past time, it was already
too late to make _S_ true, because history at that time was sufficient to make
it be the case that prior to every time there was a star.

**Objection 2:** Fact _N_ is made true by an infinite conjunction of facts
such as that in year _n_ there were no stars, in year _n_ − 1 there were no
stars, in year _n_ − 2 there were no stars, and God unproblematically makes
each of these facts true while having the power not to make it true.

**Response:** This objection is basically a rejection of (2). It says that
some facts (even among the ones that aren’t due to creaturely indeterminism)
aren’t freely decided on by God, but are instead consequences of other facts
freely decided on by God. This reminds one of the Principle of Double Effect:
God need not intend all the consequences of what he intends. He intends _N_
_n_ , there not being stars in year _n_ , as well as _N_ _n_ − 1, and _N_ _n_
− 2, and so on, but doesn’t intend their joint consequence _N_. I think this
is a powerful objection. I don’t want to rule out the possibility of such a
thing. But _N_ is a morally unproblematic and structurally central part of the
arrangement of reality. It seems very plausible that even if we reject (2) in
general, we should accept it in the special case of morally unproblematic and
structurally central parts of the arrangement of reality. Otherwise, God isn’t
really in charge of creation.

Here's a model on which I think you could solve this problem. I find it very
implausible, but let's see if it works.  
  
Assumptions:(i) Facts are concrete Armstrongian-esque States of Affairs. (ii)
All facts are time-bound, with exact duplicates taking their place when it
appears that they endure. Thus, the fact of my being green is not multiply
located at each time I am green, but each time has its own event of me being
green then.(I think you need (i) to make (ii) remotely plausible)  
  
Then, at a given moment t, It is God's free choice whether there will be a
subsequent moment t+1 or whether history ends there. So God has a free choice
over whether some fact will exist at t+1(namely, an instance of the fact
(which exists essentially at t+1 and no other time), that WAS(No Stars)). Of
course, there already exists a fact WAS(No Stars) at t (and can exist nowhen
else), which God freely brought about at t-1.  
  
Note that what we're talking about here are NOT facts like (No stars at time
tn) but facts of the form WAS(No Stars). This separates where I am about to go
from where your response 2 went.  
  
So for all facts WAS(No stars), God freely brings them about. We could say
that that's all there is. Just the individual time-bound facts. Or, we could
say that there is some sense to be made of an enduring WAS(No Stars) fact,
which is the composite of all the time-bound facts (this would work on
eternalism, with facts persisting via perdurance). But if God makes all the
parts, and if He wills the laws of composition, then He makes the whole. So
God explains the big generic WAS(No Stars) fact.  
  
[As I say, I don't buy it, but worth a shot. How to motivate (ii). Perhaps you
could say that my being green now causes my being green in 1 second. Thus my
being green now =/= to my being green in one second. Then, apply some
A-Theoretic tendencies to identify my being green now, with my being green
simpliciter. Once you do this, you can start to motivate (ii)]

Where's the backwards causation? Consider a time t and all the facts that
exist at t. They all exist because of God's causal activity at t-1. Consider a
time t0. It has some facts (I am green, Jim is square, etc.) obtaining then.
God decides to create a subsequent time t1, otherwise just like t0 but with an
additional angel. Then, God causes t1 to exist, the new angel to exist, as
well as some facts (I am green, Jim is square) to exist. These facts exist
only at t1. They share properties with some other facts which exist only at
t0. For example, a fact at t0 and a fact at t1 share the property "being a
fact of Jim being square". A fact at t0 and a fact at t1 also share the
property "being a fact of me being green". No backwards causation to be found.

Well "So for all facts WAS(No stars), God freely brings them about." But to
presently bring about a WAS fact is to engage in backwards causation, even if
the WAS fact exists presently.  
  
Compare the presentists who want to solve the problem of diachronic causation
by saying that the present WAS(cause) fact causes the present effect fact.
There is a very intuitive sense in which these presentists believe in forwards
causation. If on, the other hand, they thought that a present cause fact
caused a WAS(effect) fact, they would, in a very intuitive sense, be believing
in backwards causation. And that's the case even though in both cases the
causal relation is between present facts.  
  
Additionally, I want to deny the compositional inference. Compare this case.
God has daily willed the following two conditionals:  
1\. "If yesterday all of reality was nonvacuously red, today it will all be
nonvacuously red, too."  
2\. "If yesterday all of reality was nonvacuously green, today it will all be
nonvacuously green, too."  
And in fact reality was always nonvacuously green. Then I think a composition
argument very similar to yours says that God has willed all-time-greenness.
But that's mistaken. God's willings are neutral between all-time-greenness and
all-time-redness (and other hypotheses, as well).  
  
Now suppose that God didn't ever will (1), but only (2) every day. Then God's
willings are asymmetric, but it's still not true that God has willed all-time-
greenness. For by taking a willing away, one doesn't make God to have willed a
new thing.

I see it completely differently. The presentist resolution to diachronic
causation you articulate strikes me as a manifest case of _simultaneous_
causation. (The effect begins at t1, the cause - the WAS fact - begins at t1,
they are related by causation at t1. How much more simultaneous can you get?).  
  
To get backwards causation is to confuse the WAS fact, with the fact that was.
Suppose time passes from p at t0, to ~p & WAS(p) at t1. Now, it was the case
that p. But what's the _past_ fact here? What's the fact that was? Clearly
it's p. WAS(p) - i.e., the fact that p once was - is a presently obtaining
fact, stating the present reality that p used to obtain. Consider the first
moment of time t0. As I see it, it's trivial that any agent who can make time
pass from t0 to t1, can bring it about that WAS(p) for all facts p which
obtain at t0. And the effect that they bring about (i.e. WAS(p)) obtains in
the future relative to their action at t0. No backwards causation.

Good point. I think we may want to distinguish between metaphysically
simultaneous/backwards/forwards causation and ordinary-language
simultaneous/backwards/forwards causation. So on the theory in question,
metaphysically all causation is simultaneous. Let's assume that. But we still
want to make certain ordinary language distinctions about causation. For
instance, we want to be able to talk about "short-term" and "long-term"
effects. We can no longer distinguish the two by saying that distinction
concerns how far temporally apart the cause and the effect are. But we still
need to make the ordinary-language distinction, e.g., by talking of WAS(p)
causing q, and discussing how long ago p was. Similarly, then, we will want to
distinguish the engineer who claims that she can make an alarm go off tomorrow
("forwards causation") from the nut who claims that she can make an alarm go
off yesterday ("backwards causation"). In both cases, metaphysically, we have
simultaneous causation. But in one case the causal fact is tensed before the
effect fact and the other case the causal fact is tensed after the effect fact
(where "WAS(p)" is "tensed before" "q" when "q" has no tense operators, etc.)
Do you see what I mean?  
  
So, then, what I should say about your suggestion is that even though the
causation is metaphysically simultaneous, it's ordinary-language backwards.  
  
Put it this way. Anyone who thinks that it is absurd to suppsoe that someone
can affect the dinosaurs will be unmoved by being told that all causation is
simultaneous and affecting the dinosaurs is just a matter of affecting a
WAS(q) fact.

Here's a theory: a material thing is something that has or is a causal power
that is not a mental causal power. Variant: that is not a rational causal
power.

I think it would be very hard to reach a wide consensus on that definition.
Anybody who was a physicalist but not an epiphenomenalist would likely
disagree with that definition.

Sure, but I'm not looking here for a consensus, but the truth. :-) It's
notoriously hard to come up with an account of matter.

I would think it would be possible for an immaterial being to have effects by
virtue of that being’s beauty, and that the causal power in such cases would
neither be a mental causal power nor a rational causal power. At the very
least, the causal power in question would not be linked to a specific
intention had by the immaterial being.

Yeah, it might turn out that,  
(A) necessarily every beauty had by immaterial beings is a mental beauty.  
That doesn’t sound like a logical necessity to me, but I could be wrong.  
Does it follow from (A) that  
(B) necessarily every causal power exercised by virtue of a mental beauty is a
mental causal power.  
?  
  
Maybe.

Some cosmological theories lead to the worrisome conclusion that most people
with present brain states like ours are Boltzmann brains—random aggregations
of molecules in space that came together to form a brain in a little bubble of
oxygen. Usually when people talk about Boltzmann brains, they talk of how this
induces a sceptical problem for the theory that generates them. Thinking about
Boltzmann brain issues that way leads to messy epistemological questions such
as whether we get to simply assume that we have hands, and the like. Moreover,
if there is evidence for the cosmological theory, then that becomes evidence
for Boltzmann brains, which then undermines the evidence for the cosmological
theory, and that’s all a mess.

Here is how I suggest we think about what happens when a cosmological theory
_T_ leads to a Boltzmann brain issue. The vast majority of Boltzmann
brains—even ones with brain states like ours—are short-lived. Their bubble of
oxygen dissipates in the absence of gravity, and after a brief moment of
hypoxia they die. So think of the point this way. If a cosmological theory
predicts a large ratio of Boltzmann brains to ordinary evolved brains, then
the theory makes an empirical prediction: in a moment you are extremely likely
to start blacking out. So just do the experiment: wait a moment and see if
you’re blacking out. If you’re not, then you’ve got very strong
disconfirmation of the cosmological theory, and you’re done with it. You don’t
have to worry about self-defeat, Moorean questions about whether you have two
hands, or anything deep like that. (And if you are blacking out, then if it’s
a Boltzmann brain related blockout, you’ll be dead in a moment. If you do come
back to, and not in the afterlife, that’s massive evidence against the theory
again, but now you should see a doctor about your blackout problem.)

In fact, you don’t even have to wait: on cosmological theories that generate
too many Boltzmann brains, you should expect to already be starting to black
out—because most of the Boltzmann brains will be _extremely_ short-lived.

**Response:** Sure. But for entropic reasons they will be much less common
than the short-lived ones. You might, of course, worry that in many of these
cosmological scenarios there are infinitely many Boltzmann brains, and
infinitely many are short-lived and infinitely many are long-lived, and you
can’t say that the short-lived ones are more common. The short-lived ones will
be more common in a “typical” large finite region, but overall we just have
infinity. Now, if you are worried about this—and I think you should be—then
that worry already applied at the beginning of the story when you looked at
the ratio of ordinary to Boltzmann brains, because there will be infinitely
many of each on such a cosmological theory, and the formulation of the problem
that I gave at the beginning, namely that Boltzmann brains greatly outnumber
ordinary brains, is inaccurate. (I think if you do have this worry, then the
theory has _another_ problem, namely that probabilistic reasoning makes no
sense in a world described by the theory. That is a kind of sceptical and
self-defeat problem, but of a different nature.)

My point in this post is modest: if you want to say that Boltzmann brains
greatly outnumber ordinary brains, then instead of thinking deep stuff about
self-defeat of theories and scepticism, you should just think of the theory
that generates this prediction as falsified by future observation.

Suppose that for antisceptical reasons you think that you should dismiss any
hypothesis on which you didn't live as long as common sense days you did. Then
the falsified prediction of the cosmological theory changes: it predicts we're
in a bubble of "normal" reality whose radius is equal to your age times the
speed of light. And that's disconfirmed by looking whether stars beyond that
distance disappear. And they don't.

I don't think this response to Boltzmann brains works. The reason you don't
find yourself blacking out is because you JUST NOW came into existence
completely with false memories of a past that didn't actually happen. At any
moment, it only SEEMS like you've been around a while because those memories
were JUST NOW implanted in you. If you are a Boltzmann brain, then you will
surely die in the very next moment. The only reason you haven't died yet is
because you JUST NOW came into existence. I don't know if I'm explaining that
well or not.

Boltzmann brains aren't instantaneous. They come into existence and then die
soon after that once they run out of oxygen. Most of them just barely have
enough oxygen to be conscious for a very short period. But that short period
isn't a moment, and their perishing isn't instantaneous.

I don't see why it would need to be instantaneous for my point to go through.
Regardless of how short or long Boltzmann brains last, it would still be the
case that the reason you don't experience yourself going out of existence is
because you just now came into existence. After all, you only ever experience
the immediate present. You don't experience the past even a fraction of a
second ago, nor the future a fraction of section from now. So you could've
come into existence a fraction of a second ago, and that's why you haven't
begun to deteriorate yet.

Response 1: You could have. But the theory predicts that most of your life
would be a deterioration. You would probably only have a small fraction of a
second of mental clarity, and then have started going down into darkness, and
the going down into darkness time would probably be significantly longer than
the brief moment of clarity. In other words, the theory predicts that you
would already be experiencing the deterioration.  
  
Response 2: Don't worry about any of the fancy sceptical stuff. Just use the
ordinary scientific method. You're conscious now and aren't blacking out. The
theory predicts you will soon be blacking out. So wait and see. You waited and
saw and there was no blackout. All well and good. Theory disproved.

It is so funny. In the other post it is stated, that it is supposedly
_"notoriously hard"_ difficult to come up with an account of matter and here
it is stated or implied the matter oxygen to be an essential part or necessary
matter for a functional brain.  
I myself cannot come up with such a great irony.

###  What I think is wrong with Everettian quantum mechanics

One can think of Everettian multiverse quantum mechanics as beginning by
proposing two theses:

Superpositions in the global wavefunction can be correctly interpreted as
equally real branches in a multiverse.

But _prima facie_ , these two theses don’t fit with observation. If one
prepares a quantum system in a (3/5)|↑⟩+(4/5)|↓⟩ spin state, and then observes
the spin, one will will observe spin up in |3/5|^2=9/25 cases and spin down in
|4/5|^2=16/25 cases. But (roughly speaking) there will be two equally real
branches corresponding to this result, and so _prima facie_ one would expect
equally likely observations, which doesn't fit observation. But the Everettian
adds a third thesis:

One ought to make predictions as to which branch one will observe
proportionately to the square of the modulus of the coefficients that the
branch has in the global wavefunction.

Since Aristotelian science has been abandoned, there has been a fruitful
division of labor between natural science and philosophy, where investigation
of normative phenomena has been relegated to philosophy while science
concerned itself with the non-normative. From that point of view, while (1)
and (less clearly but arguably) (2) belong to the domain of science, (3) does
not. Instead, (3) belongs to epistemology, which is study of the norms of
thought.

This point is not a criticism. Just as a doctor who has spent much time
dealing sensitively with complex cases will have unique insights into
bioethics, a scientist who has spent much time dealing sensitively with
evidence will have unique insights into scientific epistemology. But it is
useful, because the division of intellectual labor is useful, to remember that
(3) is not a scientific claim in the modern sense. And there is nothing wrong
with that as such, since many non-scientific claims, such as that one
shouldn’t lie and that one should update by conditionalization, are true and
important to the practice of the scientific enterprise.

But (3) is a non-scientific claim that is absurd. Imagine that a biologist
came up with a theory that predicted, on the basis of their genetics and
environment, that:

There are equal numbers of male and female infant spider monkeys.

One ought to make predictions as to the sex of an infant spider monkey one
will observe in inverse proportion to the ninth power of the average weight of
that sex of spider monkeys.

And now, because male spider monkeys are slightly larger than females, we will
make predictions that roughly fit our observations.

Here’s what went wrong in our silly biological example. The biologist’s
epistemological claim (5) was not fitted to the actual ontology of the
biologist’s theory. Instead, basically, the biologist said: when making
predictions of future observations, make them in the way that you should if
you thought the sex ratios were inversely proportional to the ninth power of
the average weights, even though they aren’t.

This is silly. But exactly the same thing is going on in the Everett case. We
are being told to make predictions in the way you should if the modulus
squares of the weights in the superposition were chances of collapse. But they
are not.

It is notorious that any scientific theory can be saved from empirical
disconfirmation by adding enough auxiliary scientific hypotheses. But one can
also save any scientific theory from empirical disconfirmation by adding an
auxiliary _philosophical_ hypothesis as to how confirmation or disconfirmation
_ought_ to proceed. And doing that may be worse than obstinately adding
auxiliary scientific hypotheses. For auxiliary scientific hypotheses can often
be tested and disproved. But an auxiliary epistemological hypothesis may
simply close the door to refutation.

To put it positively, we want a certain degree of independence between
epistemological principles and the ontology of a theory so that the ontology
of the theory can be judged by the principles.

Comment delete due to sarcasm. Sad, because there was actually a point in that
was important.

Alex  
  
Why don't you simply address the important point?

Fair enough. As I remember it, the idea was basically to consider a case where
we have a region R divided into two subregions, A and B, of unequal non-zero
areas, and a point is randomly chosen in R, and the universe branches
depending. Then it's a mistake to think there are only two branches coming
out. There are infinitely many, one for each point in R. It then makes sense
to identify the probabilities of A and B with the areas of the two regions.  
  
In response, I'd first say that there are some difficulties here. Technically,
both regions have the same infinite number of points (the cardinality of the
continuum) so there are equally many A-type and B-type branches. So the
proposal to go with the area needs further work to justify.  
  
But more importantly, the way the quantum spin probabilities work, it's not
like there are more ways of getting spin down than spin in my case. Spin up
and spin down are the only two possible outcomes (assuming we idealize; in a
non-ideal situation, there are other options such as the observational
apparatus catching on fire, etc.; moreover, there is branching going on due to
all sorts of other quantum stuff going on all the time in the universe). The
differences in spin up/down probabilities are NOT due to differences in
numbers or measures of more fine-grained results. There is just up and down.
So there are only two branches (again, idealizing).

I wasn't sarcastic here, Alexander.  
I still don't know, how exactly your previously stated and claimed "theorem"
follows from an "ad reductio absurdum". Nothing in that roughly put - really
roughly put "proof" of yours makes any sense at all.  
  
Besides that, from "equally real" branches doesn't follow those branches to be
"equally likely", since the number of realizations of those "equally real"
branches might differ from each other of those branches.  
Apropos number of realizations of those "equally real" branches. Of course
there are two subregions A and B in the phase space of spins **with different
sizes** in your example. You specifically set ratio of the sizes of those two
regions (spin up:spin down) to be 9:16. You are just ignorant here about the
proper mathematical description of quantum mechanics with its very specific
mathematical space and its very specific **METRIC** and its very specific
**MEASURMENT**.  
You are basing your scepticism of quantum mechanics or Everettian's quantum
mechanics on misconceptions and straw mans really.  

While I'm not convinced either, the most developed Everettian answer to this
by David Wallace argues that branch number isn't well defined in the first
place, so branch density is the only relevant consideration. I think that
deserves response, since it's really the leading theory out there.

Doesn't the density issue just mean there are equal infinite numbers of
branches?

On reflection, I shouldn't have focused on equal probability. There just is no
probability there, because there are no facts to assign probability to.

Wallace has a pretty extended argument that branch number is undefined rather
than infinite, because it's dependent on a choice of grain.  
  
The latter point seems much more salient to me. Worlds, according to Wallace,
are basically Lewisian (Alastair Wilson makes this explicit): they're maximal
coherent sets of macro facts. But what's supposed to ground those macro-facts
are non-world-bounded superpositions. So first, worlds aren't fully definite--
and thus can't have probabilities for quantum facts. And second, worlds are
dependent on pragmatic choices, so the facts become pragmatic. Now, for
Wallace, probabilities are pragmatic--they're just decision theory. But it
seems to me that classical decision theory, which he embraces, relies on there
being determine outcomes on which to base the pragmatics.

Thanks for the clarification. Undefined makes it even worse, I think. This is
just not a metaphysics with probabilities. The probabilities are inserted as a
non-scientific epistemological posit, and an implausible one.  
  
Years back, I argued against open future views on the grounds that the
probability of p should be equal to the probability of p being true. The same
applies here.

Zsolt:  
  
The information conservation theorems assume unitarity of the evolution, which
is denied by collapse theories.

GRW collapse theories are in principle distinguishable from non-collapse
theories, but I believe not with the present level of technology (at least for
certain values of the collapse parameter). Thus, at the present level of
technology, experiments confirming conservation of quantum information are
insufficient to determine whether the kind of failure of conservation involved
in GRW collapse has occurred. The question between collapse and no-collapse
theories is still empirically unsettled, even though it is actually a bona
fide empirical question.

Ahh. So that's the current state of affairs.  
By the way, is it really the case that collapse theories are denying the
unitary time evolution of a physical system?  
If so, then why is there the Hamilton operator in the GWR master equation for
the time evolution of the density operator?!?  
The Hamilton operator is the generator of unitary dynamics. That's weird.

I’ve been thinking about how well Descartes’ cogito argument works given the
following plausisble thesis:

Supposedly, (2) is clear and distinct. But wait (!). By (1), I only introspect
premise (2) with a time delay. In other words, by the time I introspect
premise (2), the pain is over. It is one thing to be in pain—obviously, when I
am in pain, I am in pain—but it is another to be aware that I am in pain.

In other words, at the present moment, if I am to stick to the indubitable,
all I get to say is:

Now, if eternalism or growing block is true, I still get to conclude that I
exist _simpliciter_ , but not indubitably so (since I need to rely on the
arguments for eternalism or growing block).

But there is an even more serious problem. Once we accept the time delay
thesis (1), we no longer have indubitability in our introspection of pain. For
suppose the time delay from being in pain to being aware that one is in pain
is a microsecond. But now consider the half-microsecond hypothesis that the
universe came into existence, fully formed, half a microsecond ago. If so, I
would still have the introspective awareness of being in pain—without having
had a pain! The half-microsecond hypothesis is crazy, but no crazier than the
evil demon hypothesis that Descartes cares so much about. So now we don’t have
indubitability about (2) _or_ (5).

And what goes for pain goes for any other conscious state, i.e., for anything
that Descartes calls “thought”.

We might now want to deny the time-delay thesis (1), and say that:

Whenever I have a conscious state _Q_ , I am immediately _thereby_ aware of
having state _Q_.

But a bit of introspection shows that (8) is false. For being aware is itself
a conscious state, and so if (8) were true, then whenever I have a conscious
state, I have an infinite sequence of conscious states of meta-awareness. And
I clearly do not.

Indeed, introspectively reflecting on the states of meta-awareness shows that
_sometimes_ the time-delay thesis _is_ true. Let’s say that I am aware that I
am in pain. It takes reflection, and hence time, to become aware that I am
aware that I am in pain. So the time-delay thesis is at least sometimes true.

Now it might be that we are lucky and the time-delay thesis is false for
introspection of first-order conscious states, like being in pain. I am a
little sceptical of that, because I suspect a lot of non-human animals are in
pain but don’t even have the first meta-step to perceiving that they are in
pain.

So let’s grant that the time-delay thesis is false for introspection of first-
order conscious states. Now it is no longer true that, as Descartes thought,
his _cogito_ could be run from _any_ conscious states. It can only be run from
the ones for which the time-delay thesis is false. But it’s worse than that.
Even if the time-delay thesis is false for some introspective perceptions, it
is not _indubitable_ that it is false for them. The claim that these
introspections lack time-delay is far from indubitable.

Yet all that said, isn’t it true that even in the half-microsecond world, I
exist? Even if I didn’t have the pain that I think I had, surely to think that
I had it requires that I am! Yes, but I only become _aware_ that I think I had
a pain with a time-delay from my thinking that I had a pain, because the time-
delay thesis is empirically true at all the meta-levels.

This is all very strange. Maybe one can save something by supposing that
awareness of a conscious state _Q_ is always partly constituted by _Q_ , and
even with a time-delay we have indubitability. Maybe in the half-microsecond
world, I couldn’t be aware of having had a pain when I didn’t have the pain,
because the second-order awareness is partly constituted by the occurrence of
the first-order awareness, be that occurrence past or present. Maybe, but the
partial constitution thesis seems dubitable. And once we get to some meta-
levels it seems implausible. Couldn’t I be mistaken in thinking that I aware
that I am aware that I am aware that I am aware of _Q_ , while in reality I
only had two meta-levels?

Worse still, existence itself probably requires some minimum duration that
varies by the object.

I don't know about that. Couldn't God create a person for an instant?

Alex  
  
What is the duration of an instant  
If it has no duration, in what way does the person exist?  

God could make the ways things exist any way at all, but I am speaking of
existing in an "ordinary" way without a special act by deity for that
particular object. It seems that a planet that exists only for a second never
is a real planet, since it never orbits.  

What if we said, "If I have ever had a conscious state, then I have existed"?
Even if we are having a false memory of having been in pain, that memory
itself ia a conscious state. So to think at all, whether presently or in the
past, seems to entail that you have existed at some point.

Sam: Agreed. And if eternalism is true, then it follows that you exist
simpliciter.

I think God is timeless. For a long time I’ve been vaguely worried by the
thought that on a B-theory of time, a timeless being is like a being that
exists at only one instant of time. But the latter being is really evanescent,
while a timeless being is the opposite of evanescent. What’s the difference?

We can say: well, a being that exists at only one instant will cease to be
when a new instant comes, but a timeless being won’t cease to be. But now
imagine a being that exists at only one instant, but that instant is the very
last instant of time. It’s no longer true that that being will _cease_ to be,
because to cease to be there has to be a future time at which one does not
exist, and at the last instant of time there is no future at all. Yet the
being that exists at the last instant of time is still evanescent.

If one believes in a “flow of time”, one can say that a timeless being is like
a being at an instant of “time” in a “time” sequence that doesn’t flow (so
it’s not really time, but only “time”). But a “flow of time” is hard to make
sense of.

Here are two alternative stories. First, we might suppose that instants of
time can have a “duration weight”. Thus, while one might think that the
duration of _n_ instants of time is always (in the most natural units)
precisely _n_ , one might think that instants have a duration which measures
how long they endure. It’s not that they are exactly intervals. It’s still
going to be the case that no change is possible during an instant. But perhaps
duration is possible. Then on a discrete theory of time, a sequence of
instants has a duration equal to the sum of the durations of the instants. And
on a continuous theory of time, the temporal length of a segment of intervals
is equal to the integral of the durations.

We can then say that a timeless being is like one that exists on an instant of
infinite duration, an instant that has nothing before it or after it. On a
discrete theory, this is straightforwardly just an infinite duration. On a
continuous theory, it would be like a Dirac delta.

Second, we might hypothesize that what yields the subjective experience of
“moving on” from one instant to another is the poverty of our experiences
contained in the instant. But mystics talks of being caught up to eternity in
their experiences of the infinite: time appears to slow down for them. But the
experiences of mystics do not, after all, _comprehend_ the infinite. However,
perhaps, an experience that _did_ comprehend the infinite would slow one down
to the point that an instant would _literally_ last subjectively for eternity.
And this subjective time could then be an accurate reflection of the internal
time of the being. If so, then only a being that comprehends the infinite,
like an infinite God contemplating himself, could be timeless.

(Note that there may be some difficulty in fitting the above to the common
observation that time flies when you’re having fun. But it has been
hypothesized that the latter is due to the fact that when you’re having fun,
you fail to notice every tick of your internal clock. Thus the fact that time
flies when you’re having fun isn’t merely due to the richness of the
experience when you’re having fun. It may be that what we have is a kind of
phenomenon where modest finite fun makes subjective time go by faster, but
then once we transcend fun into a mystical experience, the opposite happens.)

An amoeba is alive but an accurate simulation of an amoeba wouldn’t be alive.

If (1), then an accurate simulation of a human wouldn’t be alive.

If an accurate simulation of a human wouldn’t think, Strong AI is false.

Behind (2) is the idea that the best explanation of (1) is that computer
simulations of living things aren’t alive. I think (4) is perhaps the most
controversial of the premises.

You could also replace (2) with a long list of increasingly complex organisms:  
  
(2*) If (1), then an accurate simulation of mold wouldn’t be alive.  
(3*) If (2*), then an accurate simulation of a mushroom wouldn't be alive.  
...  
(9999*) If (9998*), then an accurate simulation of an ape wouldn't be alive.  
(10000*) If (9999*), then an accurate simulation of a human wouldn't be alive.

Yes, Apologetics², (2) could be replaced by such a monstrosity of a slippery
slope.  
But then again by hypothetical syllogism (2) follows from (2*)-(10000*). If
so, then why bother with the slippery slope, when you could have a much
shorter, more simple and nice argument.  
  
Example:  
(1') If a drawn figure is a square, then that drawn figure is a rectangle.  
(2') If a drawn figure is a rectangle, then that drawn figure is a
parallelogram.  
(3') If a drawn figure is a parallelogram, then that drawn figure is
trapezoid.  
(4') If a drawn figure is a trapezoid, then that drawn figure is a
quadrilateral.  
(1) Therefore, if a figure is a square, then that figure is a quadrilateral.
(from 1'-4' by hypothetical syllogism)  
(2) My drawn figure is a square.  
(3) Therefore, my drawn figure is a quadrilateral. (from 1 and 3 by modus
ponens)  
  
Why make a slippery slope, when you can have the same argument much, much
simpler?

###  Yet another formulation of my argument against a theistic multiverse

Here’s yet another way to formulate my omniscience argument against a theistic
multiverse, a theory on which God creates infinitely concretely real worlds,
and yet where we have a Lewisian analysis of modality in terms of truth at
worlds.

Premise schema: For any first order sentence _ϕ_ : Necessarily, _ϕ_ if and
only if God believes that _ϕ_.

Premise schema: For any sentence _ϕ_ : Possibly _ϕ_ if and only if ∃ _w_ (at
_w_ : _ϕ_ ).

Necessarily, there are unicorns if and only if God believes that there are
unicorns. (Instance of 1)

Possibly God believes that there are unicorns if and only if ∃ _w_ (at _w_ :
God believes that there are unicorns). (Instance of 2)

∃ _w_ (at _w_ : God believes that there are unicorns). (6 and 7)

∃ _w_ (at _w_ : God believes that there are no unicorns). (from 1, 2, 4 in the
same way 8 was derived from 1, 2, 3)

So, either there is a world at which it is the case that God both believes
there are unicorns and believes that there are no unicorns, or what God
believes varies between worlds. The former makes God contradict himself. The
content of God’s beliefs varying across worlds is unproblematic if the worlds
are abstract. But if they are concrete, then it implies a real disunity in the
mind of God.

Premise schema (1) is restricted to first order sentences to avoid liar
paradoxes.

I think that many of the steps are underspecified as to worlds, which allows  
some variation in the meaning of "possible" to lead to contradiction.  
  
Using the schema set in step 2 to specify worlds in the later steps:  
  
3\. Premise: Possible there are unicorns at a multiverse w: say, possible
world w3.  
  
4\. Premise: Possible there are no unicorns at many possible multiverses w:
w1, w2, w4,...  
  
5\. Necessarily, there are unicorns at w if and only if God believes that
there are unicorns at w.  
  
6\. Possibly, God believes that there are unicorns at w3.  
  
7\. Possibly God believes that there are unicorns at w3 if and only if  
∃w(at w3: God believes that there are unicorns at w3).  
  
8\. ∃w(at w3: God believes that there are unicorns at w3).  
  
9\. ∃w(at w1, w2, w4...): God believes that there are no unicorns at w1, w2,
w4...).  
  
So with that specification we do not get to an inconsistency.  
  
Making it concrete, if I somehow knew there were unicorns on a planet on the
other  
side of the galaxy, I could still truthfully say that there are no unicorns in
the  
entire world, counting on Earth as the world. The same might go for a concrete  
multiverse, versus our local universe.  
  
What kind of arguments against such multiverses remain? I suppose that God
could not  
truly go against his nature in actions involving any universe. So there are
limits in  
variation in the rules or physics of such universes: they would all be made in
some senses good.  

I don't see the problem. God knows there are toads on Earth, but not on Mars.
The same type of thing is going on here. God knows there's a unicorn in w1,
but not in w2. What's the contradiction?

Alex: None, that's my problem. It looks like (in my understanding of Theistic
Multiverses like Almeida's) there is w1 with unicorns, and w2 with no
unicorns. Hence, God would believe there is no unicorns in w1 (p8) and no
unicorns in w2 (p9). Both appear to be correct beliefs, but the premises as
you wrote them create an ambiguity since you didn't differentiate between the
possible worlds with unicorns and those without. If the premises are meant to
say that there is a world where God believes that unicorns are impossible,
then I would deny that God has such a belief (since there is a possible world
with Rhinos/Unicorns in it). I think the multiverse is probably false for
other reasons, but this one doesn't make much sense to me.

If you don't dispute any premise, then presumably you think some nonpremise
step is invalid. Which one?

Alex: Then I will reject P9. I affirm premise 8. ∃w(at w: God believes that
there are unicorns). And premise 9*. ∃w2(at w2: God believes that there are no
unicorns). I think that this is the actual derivation of 1, 2, and 4 (I
suppose this would be a nonpremise step).

Perhaps 8. and 9. do not actually contradict one another, because they are
each true in a different, underspecified context.

9 is not a premise but a conclusion from 1,2,4. And I don't see a way of
accepting the derivation of 8 from 1,2,3 that doesn't in exactly the same way
give a derivation of 9 from 1,2,4.  
  
If you do accept 8 and 9, then you need to deal with the prose argument
afterwards. Which we can put more precisely as:  
  
10\. ~∃w(at w: (God believes that there are unicorns AND God believes that
there are no unicorns))  
11\. ~∃w1∃w2(at w1: God believes that there are unicorns AND at w2: ~(God
believes that there are unicorns))  
12\. ~∃w1∃w2(at w1: God believes that there are no unicorns AND at w2: ~(God
believes that there are no unicorns)).  
13\. Contradiction!

Isn't it  
10\. ~∃w(at w: (God believes that there are unicorns AND God believes that
there are no unicorns))  
11\. ~∃w1∃w2(at w1: God believes that there are unicorns at w1 AND at w2:
~(God believes that there are unicorns at w2))  
12\. ~∃w1∃w2(at w1: God believes that there are no unicorns at w1 AND at w2:
~(God believes that there are no unicorns at w2)).  
  
I might not understand predicate logic well enough to see how there's an
actual contradiction between God knowing that there are unicorns in one world
and God knowing there are not unicorns in a different world, but still knowing
about the unicorns in the first world

Why is God “believing” x or y to be true.  
God is omniscient he either “Knows” x or y  
Is true therefore there’s no need to “believe”  
X and y is true. “Believe” implies a sort of lack of knowledge  
Such as when someone asks how much money do you  
“Believe” I have in my wallet? I don’t think God  
“Believes” something to be true he either knows it to be  
True or false

Zsolt naggy  
  
What is your definition of “believe” and why do you “believe” God would fall
into  
Having to “believe” anything rather than already know something is true, as
being omniscient  
Belief itself seems like holding on to a position without having data or
direct experience of something  
But God being omniscient would and should not be subject to “belief” if his
omniscience leads him  
To have direct knowledge of x thus bypassing the “belief” stage

Zsolt Nagy you neither answered what I asked nor is your response related to
the original post

You, Japexican007, asked "Why is God “believing” x or y to be true."

Someone might believe in a proposition P to be true justifiably and with a
warrant, if and only if there is evidence for that proposition P to be
true...".  
  
Sure I agree with what you said, I don’t agree with belief to be synonymous
with knowing, if God knows something to be true then there is no need for God
to “believe” something is true, I hold to the view that  
  
Knowledge is all about information. Knowledge is what we gain through
experience and experimentation. God knows what is true because he is
omniscient  
  
Belief on the other hand is a firmly held opinion. This does not require any
information as in the case of knowledge.  
  
Just like one can say I believe you have x amount of dollars in your wallet
without any information whatsoever, this has nothing to do with knowing how
much money I actually have, one is not synonymous to have a “belief” of x if
one has knowledge of x. I disagree with your expression of belief and
knowledge being interchangeable  

Yeah, I know, that you, Japexican007, are disagreeing with the general notion
of belief and knowledge. But I don't know exactly, for what reasons you are
disagreeing.  
It appears to me, that if you believe me having some amount of money in my
wallet, then it is for some specific reasons like you knowing/believing me to
be an adult working person, who usually has some money in his or hers wallet.
Otherwise your believe wouldn't be justified or warranted.  
By splitting hairs here you are just creating a double standard. For what
specific reason is this kind of a double standard necessary? Or for what
reasons exactly are justified and warranted belief and justified and warranted
knowledge to be separated?

I’m not sure where you get your double “standard from”, you can Google the
difference between belief and knowing you don’t need to my take my word for
it, it seems you just disagree because your definition doesn’t apply for every
instance as I have shown  
  
God knows x does not imply God “believes x to be true” one has data and direct
experience and the other doesn’t, it’s quite simple  
  
The definition you used “ Someone might believe in a proposition P to be true
justifiably and with a warrant, if and only if there is evidence for that
proposition P to be true...".  
  
“Someone might believe in a proposition to be true justifiable and with a
warrant” so what? That’s not the definition of belief that’s a reason to
justifiably believe I’m something  
  
“If and only if that proposition p to be true” this again doesn’t apply to
every instance of belief such as the wallet scenario or even if have a jar
with x amount of marbles, just because you believe the jar has 99 marbles
doesn’t mean you’re justified in believing or have data to believe that
conclusion, conversely you don’t need to have data or be justified in holding
a belief to have a belief, those are two different things that you’re
equating, God doesn’t need to believe something because he has the omniscience
to know the instance of that something, I’m not sure what you’re arguing for
here but it seems to be your own definition of “belief” incorporated with the
definition of “knowledge” or knowing

Belief vs faith? No one said belief vs faith  
Why would God have faith vs belief  
I’m sorry this is a strawman

I'm not "no one". I'm some one and I said "Belief vs Faith". Hence, not no one
said "Belief vs Faith", but some one said "Belief vs Faith".  
As for why would God have faiths or beliefs?  
Because any one can have faiths or beliefs AND God is some particular one.
Hence, some particular one can have faiths or beliefs AND God is still some
particular one. Therefore, God can have faiths or beliefs.  
This is not a straw man. But this is simple and plain logic.

Your response didn’t attack my original statement of belief vs knowledge but
rather you’ve made up your own dilemma, as for your reasoning  
Why would God have faith? Because anyone can have faith, depends what exactly
your definition of faith is, if it’s something like trust without knowledge
then no because God is omniscient, but furthermore faith in what exactly?
Again this strawman response is beside any conversation that anyone brought up
except of course yourself, which you seem to think if you bring up an argument
or response against no one but yourself then that somehow counters what others
have said which has nothing to do with anything you’ve said, that’s kind of
odd, someone presents 2+2= 4 and you say yea but 3*5 = 15 which has nothing to
do with what was said but you want to be taken seriously rather than someone
who has no idea what they’re talking about so they say whatever is on their
mind to make it seem as if they’re part of the conversation, now I think
you’re a troll, this is my last response, good day

You have given some arguments?!? Ah, you mean, that you have your own
definitions of things.  
Sure. As I have my own definitions of things.  
As far as I'm concerned, I have simply answered your questions.  
  
Besides that the claim _"anyone can have faith"_ doesn't only depend on the
definition of faith. You can and I think, you rather want to reject that claim
and if so, then please do it properly: **Not anyone can have faith. Or to say,
that someone can not have faith and that someone supposed to be for example
God, since bla, bla, bla.**  
If so, then my response is this: Supposedly every one _except for God_ is
created in the "image" of God and apparently every one _except for God_ can
have faith or beliefs. So then why exactly is God such an exception?!?  
It should come naturally, that if every one _except for God_ is created in the
"image" of God and every creation/"image" of God can have faiths or beliefs,
then also the Creator/God himself is capable of having faiths or beliefs.  
  
Besides that you didn't presented "2+2=4". But rather asked questions like
_"Why is 2+2=4?"_.  
My answer and response: Because "2+2=4" follows from some mathetical **axioms
- unjustified and unwarranted propositions assumed and believed to be true** ,
not really derviable claims by any rational reasoning besides of those axioms
being consistent. So it is really hard and difficult to imagine God having no
faith in such mathematical axioms to be simply consistent.  
Expecially if that God supposedly knows such mathematical propostions like
"2+2=4" to be true like and as we do.  
  
Have also a good day!  
  
Best regrads,  
Zsolt Nagy

###  There could still be a persistence-based cosmological argument even if
there were existential inertia

Suppose that today at noon, Felix the cat enters a time machine and travels
back to the time of the dinosaurs, where he spends the rest of his life
hunting small reptiles. According to the doctrine of existential inertia,
objects have a blockable tendency to continue existing.

**Question:** If Felix has existential inertia, was his inertial tendency to
continue existing blocked at noon when he time-traveled to the past, and hence
failed to exist past today’s noon?

My intuition is that the answer is negative. Existential inertia seems to me
to be about “having a future” and today at noon, Felix does have a future,
even if that future is in the distant past. In other words, if there is such a
thing as existential inertia, it concerns what I call “internal” rather than
“external” time.

Beyond mere intuition, here is a reason for a defender of existential inertia
to agree with me. If existential inertia concerns external time, then in a
relativistic world it is a doctrine that says that an object that exists at
point _z_ of spacetime has a tendency to exist somewhere or other in the
forwards lightcone centered on _z_. But there is something odd about a
metaphysical principle, like existential inertia is supposed to be, that
impels an object to continue to exist in some location or other in some
infinite set of locations (say, the infinite number of locations in the
forward lightcone one second away from the present in some reference frame),
without impelling the object to exist in any particular location, or even
imposing any kind of probability distribution on where it is to exist.
Moreover, it is not clear why the forward lightcone would be so
_metaphysically_ special that a fundamental metaphysical principle would
coordinate with lightcones so neatly.

Perhaps this is not completely convincing. But it has some legs. There is thus
some reason to think that existential inertia applies to internal rather than
external time. But if so, then existential inertia has not removed all that
needs to be explained about persistence. For a normal cat not only tends to
continue to exist in its internal-time future, but also tends to continue to
exist in its external-time future, since normally there is no time travel. And
this external-time persistence is not explained by existential inertia, if
existential inertia concerns the external-time future. So there is a
persistence to explain, and theism offers an explanation. There is still room
for an argument for theism from persistence.

Here is a closely related explanatory problem: Why is it that internal and
external time tend to be correlated, so that internal-time persistence tends
to imply external-time persistence?

Suppose that, contrary to my relativity theory intuitions, one insists that
existential inertia concerns external-time persistence rather than internal-
time persistence? Then there is still something to be explained: the
correlation between internal and external time.

Very simple answer : INERTIA. when you change the curvature of spacetime to
make your cat time travel, you change its "trajectory" so only after that it
follow again by inertia.  
Everything not changed continue to be not changed, the cat is changed by the
travel, the non-cat is changed by the travel. Then both follow the laws of the
universe. Nothing more is needed.  
  
This is like asking "i stopped ball rolling and changed its direction before
pushing it again; so inertia doesn't exist or it need to explain why the speed
changed when it supposed not to ; checkmate atheist ! "

Eventually, the modern tradition becomes very suspicious the idea that there
can be a similarity between the contents of the mind and characteristics of
things in the external world. First, we have Locke denying the possibility of
the similarity thesis for secondary qualities like red and sweet, and then we
have others, like Berkeley and Reid, denying the possibility of the similarity
thesis for primary qualities, like triangularity. In the case of primary
qualities, it just seems absurd to think that the mind should hold something
like a triangle.

This denial of the possibility of the similarity thesis seems to me to be a
massive failure of the philosophical imagination, and a neglect of a sympathy
to the history of philosophy. The allegation of the absurdity of thinking that
triangularity should be present in the mind and in the world seems to come
from thinking that the only way triangularity can be present in an entity is
by the entity’s _having_ triangularity. But why should _having_ be the only
possible relation by which triangularity could be present in a thing?

Here are some ways in which a property could be in a thing without the thing
having the property.

Let _S_ be the set of the polygonality properties. Thus, the members of _S_
are triangularity, quadrilaterality, etc. Triangularity is then in _S_ _qua_
member of _S_ , but _S_ is not a triangle—it does not _have_ triangularity.

On divine simplicity, God is identical with his divinity. But God can be
present in Francis without Francis _having_ God’s divinity—i.e., without
Francis being divine.

Suppose that I have a wood triangle in a steel box. The triangle’s
triangularity is in the triangle, and the triangle is in the box, so the
triangularity is in the box.

Say that my fingernail is pointy. The properties of a thing are parts of a
thing. So, the fingernail has its pointiness as a part. But the fingernail is
a part of me, and parthood is transitive. So the pointiness of the fingernail
is a part of me. But I am not pointy, even though I have a pointiness in me.

There is nothing absurd, then, about there being triangularity in the mind
without the mind being itself triangular.

Moreover, having triangularity in the mind is not even a necessary condition
for there to be a relevant similarity between the mind and a wooden triangle
outside of me. It could be that the triangularity in the triangle is not a
simple entity, but is composed of two components, _T_ and _P_ , where the _P_
component is common (either as type or as token) between all properties, and
the _T_ component distinguishes triangularity from other properties. Thus,
squareness might consist of _S_ and _P_ , and redness might consist of _R_ and
_P_. Well, then, we can suppose that when I think of or perceive a triangle as
a triangle, then _T_ comes to be in my mind without _P_ doing so. Perhaps _T_
comes to be “elementally” present in my mind, or perhaps it comes to be
compounded with something else. (Here is a Thomistic version: triangularity
has an essence _T_ and a natural _esse_ _P_ ; when present in the mind, the
essence is there, but instead comes to have a different thing from the natural
_esse_ , say an intentional _esse_.) In either case, we have something
importantly in common between the mind and the triangle _qua_ triangular,
namely _T_ , without having _triangularity_ in the mind, but only a component
of triangularity.

There is no paucity of options. Indeed, we have an embarrassment of
riches—many, many ways of making the similarity thesis true.

I think the issue here has to do with the metaphysics of properties. If you
think of substances and properties as existing independently and being related
to one another by the relation of instantiation or predication then there's no
reason why there shouldn't be a variety of relations in which a substance can
stand to a property, and knowledge/cognition could be one such relation. (John
Sergeant, a neo-Aristotelian direct realist critic of Locke, seems to make
this kind of move in the late 17th century.) But it's much harder to see how
this would work on a nominalist view, and it certainly won't work under
Cartesian metaphysics. In Cartesian metaphysics, the principal attribute is
not really distinct from the substance itself, and every (fundamental)
property possessed by a substance must be a modification of its principle
attribute—i.e., a manner of thinking or a manner of being extended. So we
can't see the properties as separate from the substances in such a way as to
allow a plurality of relations to different substances. The property (mode) is
the substance's manner of being.  
  
Now Arnauld (and maybe Descartes?) takes the modes of thought to possess
intentionality intrinsically and primitively, and hence to relate the mind to
objects, including external ones. But Malebranche thinks the modes of mind are
just sensations—phenomenal feels, without intrinsic intentionality or
representational content. Once you start thinking of thought in terms of
phenomenal experience, rather than in terms of representation/intentionality,
you don't have Arnauld's move available, and the question becomes just the one
Berkeley poses: how could a _sensation_ , a _phenomenal feel_ , or anything
like it be in an unthinking object?

Kenny,  
  
Interesting point about nominalism. It hadn't occurred to me that all these
folks might be nominalists. And I am still not sure they are. The language of
"modification" does not imply nominalism. Modifications can still exist, even
if their existence is dependent on that of which they are modifications.
Spinoza, for instance, thinks we are modifications of modifications, but I
don't think he would want to deny his own existence--just his substantiality.
Leibniz seems quite happy to quantify over appetitions and perceptions, and we
have no indication that these don't exist--just they don't substantially
exist.  
  
In other words, the language of modifications or manners fits quite fine with
what contemporary folks call a trope theory, and all my examples were meant to
work within a trope theory. Indeed, it is not clear that either my triangle or
my fingernail cases work on Platonism, because it's not clear that on
Platonism the properties are IN the substance that has them.  
  
Do Berkeley and Locke deny that phenomenal qualities are entities, even if
dependent ones? If they don't deny it, they aren't nominalists (or at least
not consistent ones).

By 'nominalism' I mean the denial of the mind- and language-independent
existence of universals. 'Nominalism' in the strict sense maintains that only
words or other signs can be universal or general. 'Nominalism' in the broad
sense allows that mental states (concepts, ideas, etc.) may also be universal
or general. Nearly all early moderns are standardly interpreted as nominalists
in the broad sense. Hobbes is clearly a nominalist in the narrow sense, and I
think Berkeley is as well.  
  
This is consistent with the existence of tropes, or something similar. Tropes
are individuals, not universals. Tropes can't be had in common by multiple
objects.  
  
The standard read on Descartes would be that individual modes (e.g., the
roundness of this apple) exist but are not really distinct from their
substances (e.g., the apple). Meanwhile, he's standardly interpreted to deny
the existence of an (immanent or transcendent) universal roundness. E.g.,
there's no sense in which the same roundness exists in multiple apples. The
picture is complicated a bit by the theory of true and immutable natures,
though.  
  
I thought your discussion was committed to universals (though immanent,
Aristotelian ones would be fine) because the whole thing appears to turn on
the notion that the _same_ property can be 'in' different objects (in a
variety of ways). On the Cartesian metaphysics of modification, a mode's very
being consists in a substance possessing its principal attribute in a
particular way. It's then hard to see how the mode could exist 'in' anything
other than the substance it modifies. However, Descartes's notion of
'objective being' requires it to! Hence, his followers are left with a
philosophical puzzle.

Kenny,  
  
Well, any nominalist who isn't crazy and who accepts tropes has some way of
explaining how two different things are triangular or two different minds are
in pain. The standard way is to say that two different things can have exactly
similar (or sufficiently similar) tropes, with the similarity being a
fundamental piece of the ideology. I think everything I wrote can be made to
fit with that.  
  
Let me go through my four examples.  
  
The first one, I must now admit, was written in Platonist style. But the
example does not require Platonism about properties. Just let S the set of the
polygonality properties of actually existing objects (stop signs, yield signs,
watch faces, etc.) Then the individual triangularity of an individual yield
sign is "in" S, even though S isn't a triangle.  
  
The second could be read in a Platonist way, but I would prefer not to. God
dwells in St Francis, as is evident from St Francis's holy life. But God is
identical to God's trope of divinity according to divine simplicity. So God's
trope of divinity is IN St Francis, even though St Francis isn't divine (at
least in the sense in which God is; I don't mean to deny theosis).  
  
The third is straightfoward. The individual triangularity of the wooden
triangle is IN the wooden triangle, which in turn is in a steel box, which
steel box is, we may suppose, a rectangular prism rather than a triangle.
Being-in is transitive, so the particular triangularity of the wooden triangle
is IN the steel box, without the steel box being triangular.  
  
The fourth is very similar. The individual pointiness of my nail is in my
nail, and my nail is in me, so the pointiness is IN me, without me being
pointy. (Variant: The individual redness of my blood is in the blood, the
blood is in me, but I am not red.)  
  
On reflection, I could imagine one of the moderns criticizing these examples
on the grounds that in all these cases, the individual trope or mode or
accident that is in the thing that doesn't have the relevant property is ALSO,
and more fundamentally, in a thing that does have the property. Thus, while I
am not pointy, the pointiness is in my nail, which IS pointy. And the divinity
that is in Francis is also in God, and more fundamentally so. But it seems
that if an individual triangularity is in my mind, then it isn't the
triangularity of any particular triangle.  
  
Maybe, but maybe not. One could have a theory on which the particular trope
that is in my mind is a trope of some particular thing that is modified by
that trope. Perhaps the individual triangularity that is in my mind when I
think of triangles is the very triangularity of the first individual triangle
I ever encountered. (Since a number of the folks in question are empiricists,
they should not object that we can have concepts of things unencountered.) One
might wonder how that individual triangularity can continue to exist when it
is dependent on a triangular substance that might well have been destroyed by
now. Well, Descartes as a Catholic at least should be OK with that, since the
doctrine of transubstantiation as usually interpreted requires the persistence
of the accidents of bread and wine after the destruction of their substance.
And, in any case, if one is an eternalist, like I am, one can embrace the idea
of a triangularity depending on a pastly existent substance.  

  
Or one could have a theory on which tropes normally exist in substances that
they modify, but there can be unaffiliated tropes. Some current trope theories
have these. To make them more plausible, suppose they are produced and
preserved by the power of God. Aquinas has the nice principle that whatever
can be accomplished by creatures can be accomplished by God without the help
of the creatures. If I have the power to produce my tallness and then preserve
it (by growing tall and staying tall), God has the power to produce a tallness
and preserve it without any creature being involved. That tallness could then
exist in a mind.  
  
Granted, one may think that these ideas are crazy. But while I admit they are
strange, they are less crazy than the anti-realism of a Berkeleian view.  
  
And there are other options, such as the parts-of-tropes view I give at the
end of the post.  
  
The point is that there are MANY ways out of the arguments, and it is simply a
massive shortfall in philosophical imagination to accept the arguments without
arguing against the many ways out.

Kenny:  
  
Even if the particular examples are out, once we have seen that with a little
bit of thought we have found so a bunch of ways of one a property being "in"
something that doesn't have that property, we really shouldn't have much
confidence that there isn't some other way we haven't yet given. This is, I
guess, the sui generis move.  
  
That said, here are two further options. First, while the soul is simple, it
isn't completely simple in the way that God is on classical theism. It could
well be that the soul is only lacking what one might call "integral parts" in
Thomistic jargon, but still has some ontological complexity. If so, why
couldn't it have a trope as a non-integral part without this property
qualifying it?  
  
Second, even if the soul has no parts of any sort, I don't think we have any
good argument that tropes themselves are simple. And if they're not, there are
lots of options.

One thinks of virtue ethics as a unified family of ethical systems. But it is
interesting to note just how different virtue ethical systems can be depending
on how one answers the question of what it is that makes a stable character
trait _T_ be a virtue? Consider, after all, these very varied possible answers
to that question, any one of which could be plugged into a virtue ethical
account of rightness as what accords with virtue.

having _T_ is required by one’s nature or by the nature of one’s will (natural
law virtue ethics)

a typical human being is expected to gain utility by having _T_ (egoist virtue
ethics)

a typical human being is expected to contribute to total utility by having _T_
(utilitarian virtue ethics)

it is pleasant to think of oneself as having _T_ (hedonistic virtue ethics)

it is pleasant to think of another as having _T_ (Humean sentimentalist virtue
ethics)

This is an interesting post. Another example comes to mind -- something like
this: having T makes one more likely to follow consistently the Categorical
Imperative. (broadly Kantian virtue ethics)

According to Spinoza, I am a mode and God is the only substance. But I am not
directly a mode of God. I am a mode of a mode of a mode of … a mode of God,
with infinitely many “a mode of” links in between.

I'm not super familiar with Spinoza, but why would he think that we're not
direct modes of God?

In this case, my "intuition" comes from the following:  
  
Theorem: There is no connected infinite graph with the properties (i) every
node lies on at most two edges and (ii) there are two nodes ("endpoints") that
each lie on only one edge.  

Nope, that's not a theorem.  
  
For the record, here's a proof of my theorem.  
  
Suppose there is a graph G with (i) and (ii). Let A and B be distinct
endpoints. Let a_0 = A. Now inductively define a sequence (a_n) of nodes for
n>0 each of which lies on exactly two edges, one of these connecting a_n to
a_(n-1). Since A is an endpoint, it is connected to exactly one node. Call
that node a_1. Then a_1 lies on at most two edges, on at least one. If a_1
lies on exactly one edge, then the nodes A and a_1 are connected to each other
and to nothing else, and hence {a_0, a_1} is a finite subset of the nodes of G
that are not connected to anything outside the subset, contradicting the claim
that G is a connected infinite graph. So a_1 lies on exactly two edges.
Suppose now that a_1,...,a_n have been defined with the property that each
lies on exactly two edges, one of them connected a_k to a_(k-1) for each k<=n.
Since a_n lies on two edges, and is connected to a_(n-1), let a_(n+1) be the
node that a_n is connected to via the other edge it's on. The remaining thing
to prove is that a_(n+1) is on two edges. It is on at least one, the one that
connects it to a_n. Suppose that's the only edge is on. Then a_0 is on exactly
one edge, connecting it to a_1, a_(n+1) is on exactly one edge, connected it
to a_n, and a_k for k strictly between 0 and n+1 is on exactly two edges,
connecting it to a_(k-1) and a_(k+1). Thus {a_0,...,a_(n+1)} is a finite
subset of the nodes of G that are not connected to anything outside the
subset, contradicting the claim that G is a connected infinite graph.  
  
So, we have now defined the sequence a_0,a_1,.... Of these, a_0 is connected
to a_1, and to nothing else, every note a_k for k other than zero is connected
to a_(k-1) and a_(k+1) and to nothing else (since each node is on at most two
edges). Thus, {a_0,a_1,...} is a non-empty set of nodes of G no member of
which is connected to anything outside the set. Since G is a connected graph,
that set of nodes must contain ALL the nodes of G. Hence it must contain two
endpoints, since G does. But it only contains one endpoint, namely a_0, since
a_k for k non-zero lies on TWO edges. Contradiction!

Contradiction?!?  
Contradiction to what exactly?!?  
What is the contradiction there in your proof?  
I guess, that's supposed to be your proofless theorem as an oxymoron, since
the given and provided proof doesn't proof the made claim and theorem. Also
that theorem doesn't have a proof, the negation have already been proven to be
true.  
So all that is there to it, I guess.

The derived claim that there is only one endpoint contradicts the assumption
at the beginning of the proof that there are two endpoints.  
  
(It's an annoyingly tricky proof.)

Hm, but the proof starts with a finite graph with two endpoints and it is
supposedly concluding with **some kind of an** infinite graph with only one
endpoint and not with an arbitrary one. Do I understand your given proof
correctly?  
I guess so and if so, then why not start with an infinite graph with two
endpoints from the get go?!?  
After all you want to show, that **any arbitrary** infinite graph has no two
endpoints and not only some?!?

I meant: "Suppose there is an INFINITE CONNECTED graph G" at the beginning.
The theorem only applies to infinite connected graphs, so there would be no
point thinking about a finite or disconnected graph.

What?!? Right at the beginning an INFINITE CONNECTED graph G have been
supposed?!?  
What?!?  
And then how does follow from that **INFINITE CONNECTED graph G, that _"hence
**{a_0, a_1} is a finite subset of the nodes of**_ **INFINITE CONNECTED _G
that are not connected to anything outside the subset"_**?  
What?!?  
I'm so confused by your "proof" and I don't think, that's because of the
language barrier between us - English being not my native language.  
Well if so, and That supposed to be the problem here, then why not give a
formal proof of your theorem?  
That might also help to understand this "mess" of a proof. **

I still don't understand, how does follow from that INFINITE CONNECTED graph
G, that _"hence {a_0, a_1} is a finite subset of the nodes of INFINITE
CONNECTED G that are not connected to anything outside the subset"_?  
How is {a_0, a_1} _a finite subset of the nodes of_ INFINITE CONNECTED G _not
connected to anything outside the subset_ , when G is an INFINITE CONNECTED
graph?!?  
Certainly the finite subset {a_0, a_1} is connected t other nodes of the
INFINITE CONNECTED G. Or not?!?  
I'm still very much confused here.

Pretty much nobody in mathematics, outside of work on foundations or computer
verifications, gives formal proofs, because doing so is way too time-
consuming. Mathematics papers almost always have proofs written in prose.  
  
As for your question why {a_0,a_1} is not connected to anything else, remember
that the proof is a reductio ad absurdum. I started by assuming that A was an
endpoint. I labeled it a_0. Because a_0 is an endpoint, it is connected to
exactly one other node, which I called a_1. Now, we prove that a_1 does NOT
lie only on one edge. For if a_1 were to lie only on one edge, then it would
be connected to only one thing. It IS connected to a_0, we already assumed.
The assumptions we have so far would then ensure that (a) a_0 is connected to
a_1 and only to a_1 and (b) a_1 is connected to a_0 and only to a_0. It
follows from this that {a_0,a_1} is not connected to anything on its outside.
But that contradicts the assumption that G is an infinite connected graph. So,
indeed, it is false that a_1 lies on only one edge. Hence, it must lie on two.

So the answer to my question is, that the sub set finite sub set {a_0,a_1} of
nodes of graph G is actually connected to something outside of the sub set,
namely to other nodes of the infinitely connected graph G.  
If so, then my question kind of remains still unanswered: Why write in your
proof that the sub set {a_0,a_1} wouldn't be connected to anything else
outside of the sub set, when that's not actually the case here?  
I know, that your proof supposed to be a reduction ad absurdum. But the only
absurd thing, I'm seeing here, is your "mess", that you are calling a "proof".

Particularly I don't understand this:  
"If a_1 lies on exactly one edge, then the nodes A and a_1 are connected to
each other and to nothing else, and hence {a_0, a_1} is a finite subset of the
nodes of G that are not connected to anything outside the subset,..."  
Why assuming a_1 lieing only on exactly one edge?!?  
If then that assumption leads to a contradiction in conjunction with other
assumptions like the considered graph G being supposedly infinite, then wait
follows from that contradiction exactly?!?  
It might be that the considered graph is actually only finite and not
infinite!!!  
This is all so confusing.

If a_1 lies on exactly one edge, then the nodes A and a_1 are not connected to
each other and to nothing else, and hence {a_0, a_1} is a finite subset of the
nodes of G that are connected to something outside the subset.

Like wise for any finite subset {a_0,...,a_(n+1)}:  
{a_0,...,a_(n+1)} is a finite sub set of nodes of G, which are connected to
something outside of the sub set, namely to other nodes of the infinite graph
G.  
  
Yeah, it's like a big giant "red herring" not contributing anything
substantial to the "proof" of your "theorem" Why have it that even in there in
that "proof" of yours then?!?

Also let me define now the following sequence:  
a_0=A (one endpoint of the infinitely connected graph G)  
a_1=B (the other endpoint of the infinitely connected graph G)  
and the nodes are connected in the following way:  
a_0,edge,a_2,edge,a_4,edge,...,edge,a_5,edge,a_3,edge,a_1  
Then this is an infinitely connected graph with two endpoints. Therefore,
there is such an infinitely connected graph with two endpoints.  
  
I can shred your "mess" of a "proof" for your "theorem" to pieces.  
You can not do the same with mine.

So then by reductio ad absurdum (or obviously and trivially saying) any
{a_0,...,a_(n+1)} is a finite subset of nodes of G, which are connected to
something outside of the sub set, namely to other nodes of the infinite graph
G.  
Hence, {a_0,a_1,...} is a non-empty SUBset of nodes of G with some members of
which being connected to something outside the set. Since G is a connected
graph, that set of nodes must contain SOME of the nodes of G, but sadly not
all even if that SUBset is already containing an infinite amount of nodes
(just like the set of infinitely many odd numbers is just a subset of all
natural numbers).  
I guess, this is the result of your "proof"/"reductio ad absurdum" here.  
Or how am I supposed to understand this "proof"/"reductio ad absurdum" of
yours correctly here?!?

So your intuitions, Alexander, on infinity are relying on a false "theorem"
here. Then why have those false intuitions then?!?  
Because based upon those you can "justify" your scepticism and objections
towards other positions and claims?  
But such scepticism and objections based upon false intuitions and false
"theorems" are worth nothing. In my opinion such faulty or fallacious
justifications might even be harmful by giving the false impression of there
to be a proper warrant for a believe, when there is actually no such proper
warrant for it or just only fallacious ones.  
 **I rather don't believe in a true proposition, than believe in a false
proposition based upon fallacious or even false reasoning and deduction.**  
And your so called "theorem" is not just lacking any proper proof or deduction
here, but it is also false because of its negation being simply provable and
deductable by giving a proper example, which has been provided before multiple
times here already.

One of the main arguments for physicalism is based on the closure principle:

Any physical event that has a cause has a physical cause.

If a physical event has a nonphysical cause, the event is overdetermined.

And hence in the absence of systematic overdetermination, mental causes must
be physical.

But (2) doesn’t follow from (1). There are at least _three_ ways for an event
_E_ to have two sufficient causes _A_ and _B_ :

chaining: _A_ causes _B_ which causes _E_ or _B_ causes _A_ which causes _E_

parthood: _A_ causes _E_ by having _B_ as a part which causes _E_ , or _B_
causes _E_ by having a part _A_ which causes _E_.

Let’s think a bit about how the chaining and parthood options might avoid
physicalism in the case of mental causation and yet allow for closure.

Option I: Nonphysical-physical-physical chaining: A nonphysical event _M_
causes a physical event _P_ which causes a physical event _E_. This can’t be
the whole story for how we respect closure. For by closure, _P_ will need a
physical cause _P_ 2, and so it is looking like _P_ is going to be
overdetermined, by _M_ and _P_ 2. But that does not follow without further
assumptions. For we could have the following scenario:

_E_ is caused by an infinite chain of physical causes which chain is causally
preceded by _M_ , namely: _P_ ← _P_ 2 ← _P_ 3 ← ... ← _M_ , with infinitely
many physical events in the “…”.

This scenario requires the possibility of an infinite sequence of causal
means, contrary to causal finitism, and hence is unacceptable to me. But those
who are less worried about infinite chains of causes should take this option
seriously. Note that this option is reminiscent of Kant’s view on which our
noumenal selves collectively cause the physical universe as a whole.

Option II: Physical-nonphysical-physical chaining: Here, the physical event
_P_ causes _E_ by having a mental event as an intermediate cause. This option
exploits a loophole in the closure principle as it is normally formulated:
nothing in the closure principle says that the physical cause can’t operate by
means of a nonphysical intermediary. Granted, that’s not how we normally think
of physical causes as operating. But there is nothing incoherent about the
story.

Option III: Physical parts of larger events: A physical event _E_ is caused by
a physical event _P_ , and the physical event _P_ is itself a part of a larger
event _M_ which is only partly physical. One might object that in this case
it’s only _P_ and not the larger event that counts as the cause. But that’s
not right. If someone dies in the battle of Borodino, then at least three
causes of death can be given: a shot being fired, the battle of Borodino, and
the War of 1812. The shot is a part of the battle, and the battle is a part of
the war. One particular way to have Option III is this: a quale _Q_ is
constituted by two components, a brain state _B_ (say, a state of the visual
cortex) and a soul state _S_ of paying attention to the brain system that
exhibits _B_ , with _B_ being the causally efficacious part of the _Q_. So a
physical event—say, an agent’s making an exclamation at what they saw—counts
as caused by the physical event _B_ and the event _Q_ which is not physical,
or at least not completely physical.

One might object, however, that by “nonphysical”, one means _entirely_
nonphysical, so _Q_ ’s having a nonphysical part _S_ does not make _Q_
nonphysical. If so, then we have one last option.

Option IV: Some or all physical causes cause their effects by having a
nonphysical part that causes the event. That nonphysical part could, for
instance, be an Aristotelian accidental or substantial form. Thus, here a
physical event _E_ is caused by a physical event by means of its nonphysical
part _M_.

What if one objects that “physical” and “nonphysical” denote things that are
_purely_ physical and nonphysical, and neither can have a part that is the
other? In that case, we have two difficulties. First, the closure principle is
now stronger: it requires that a physical event that has a cause always has a
_purely_ physical cause. And we have a serious gap at the end of the argument.
From closure at most we can conclude that a physical event doesn’t have a
_purely_ nonphysical cause. But what if it has a partly physical and partly
nonphysical cause? That would be enough to contradict physicalism.

"parthood: A causes E by having B as a part which causes E, or B causes A by
having a part A which causes E."  
  
Is this a typo? Shouldn't it be: "... or B causes E by having a part A which
causes E."  
  
Or am I misunderstanding?

Bayesian update on evidence _E_ is transitioning from a credence function _P_
to the credence function _P_ (⋅∣ _E_ ). Anti-Bayesian update on _E_ is moving
from _P_ to _P_ (⋅∣ _E_ _c_ ) (where _E_ _c_ is the complement of _E_ ).
Whether one thinks that Bayesian update is rationally required, it is clear
that Bayesian update is better than anti-Bayesian update.

But here is a fun fact (assuming the Axiom of Choice). For any scoring rule on
an infinite space, there is a finitely additive probability function _P_ and
an event _E_ such that 0 < _P_ ( _E_ ) < 1 where _P_ (⋅∣ _E_ ) and _P_ (⋅∣ _E_
_c_ ) get exactly the same score everywhere in the probability space. It
follows that when dealing with finitely additive probabilities on infinite
spaces, a scoring rule will not always be able to distinguish Bayesian update
from anti-Bayesian update. This is a severe limitation of scoring rules as a
tool for evaluating the accuracy of a credence function in infinite cases.

One might take this as some evidence that _finite_ additivity is not good
enough.

If _E_ and _Ē_ (complement of _E_ ) are the complements of each other (yes,
_Ē_ is the complement of _E_ , but also _E_ is the complement of _Ē_ ), then
in what way is the Bayesian Update better than the Anti-Bayesian Update?!?  
If that would actually be the case, then I guess, that the Anti-Bayesian
Update is better then the Anti-Anti-Bayesian[simple Bayesian] Update.

I don't follow. The idea behind anti-Bayesian evidence is this. You observe E.
So you replace your credences with credences conditionalized on not-E!  
  
An immediate consequence is that although you observed E, your credence for E
after the update is zero.  
  
For instance, suppose you roll a die, and a friend observes that the answer
was even. What do you do? You conditionalize on odd, and assign probability
1/3 to each of 1, 3 and 5.

Hi Alex, interesting observation. I think this can be brought to bear more
directly on the standard accuracy-based argument for conditionalization. That
argument is based on showing the *plan* to conditionalize has highest expected
accuracy. In general, an update plan is a function from a partition to the
space of probability measures.  
  
Take a binary partition {E, not-E} for simplicity. Say an update plan U is
anti-Bayesian for P if U(E) = P(. | not-E) and U(not-E) = P(. | E). Let C be
the conditionalization plan, e.g. C(E) = P(. | E). In general, the P-expected
value of an update plan U is  
  
E_P(U) = \int s(w, U(E(w))) P(dw),  
  
where E(w) is that cell of the partition containing w. So, with P as in your
post and U anti-Bayesian, we have  
  
E_P(U) = \int_E s(w, P(. | not-E))P(dw) + \int_{not-E} s(w, P(. | E)) P(dw) =
\int_E s(w, q)P(dw) + \int_{not-E} s(w, p) P(dw).  
  
And if C is the conditionalization plan for P, then  
  
E_P(C) = \int_E s(w, P(. | E))P(dw) + \int_{not-E} s(w, P(. | not-E)) P(dw) =
\int_E s(w, p)P(dw) + \int_{not-E} s(w, q) P(dw).  
  
So E_P(U) = E_P(C) because s(p) = s(q).  
  
If s is strictly proper that argument doesn't work, which is why the argument
for conditionalization plans work in finite spaces.

In fact, yes, it's easy to see that Theorem 3 of the second linked paper fails
to generalize, using your example.  
  
In the terminology of that paper, the credal strategy (P,C) is probabilistic
and conditionalizing, but the credal strategy (P,U), where U is anti-Bayesian,
is not conditionalizing. By your example, the score of (P,C) is the same as
the score of (P,U). So, if part (c) of Theorem 3 generalizes, then there is no
credal strategy that strongly dominates (P,C). But then part (b) fails. So
either (c) or (b) fails to generalize.

Deleting my comments, administrator, won't answer my questions though.  
On the other hand proper answers and responses have much more **chances**
(-wink, wink) properly addressing my questions.  
  
How about addressing just one question of mine properly?  
I mean another proper question of mine and not the previous one. Ahhh, silly
and fallible me.  
It is just so easy to be fooled and tricked by one's own intellect, I guess.  
  
So here is that proper question of mine for you, administrator:  
 **Why and how exactly is the _"regular"_ conditionalizing or Bayesian Update
supposed to be _"better"_ than the _"anti"_ conditionalizing or _"Anti"_
-Bayesian Update?**  
I would rather consider the _"Anti"_ -Bayesian Update to be just a
"complementary" Bayesian Update on pair with the original Bayesian Update,
since each of those Bayesian Updates are complementary to each other as _E_
and _not-E_ are complementary to each other.  
But hey, if you have good reasons to think, that the one is _"better"_ than
the other one, then please, enlighten me about how and why that is exactly
supposed to be the case, administrator.  
Thank you.

(1) For evidence _E_ , the Bayesian Update on evidence _E_ is _"better"_ than
the Anti-Bayesian Update on _not-E_.  
 **(2) Sometimes absence of evidence is evidence of absence or to say, that
sometimes _not-E'_ is the evidence _E_ : _E_ = _not-E'_**  
From 1 and 2:  
(3) Therefore sometimes for evidence _not-E'_ , the Bayesian Update on
evidence _not-E'_ is _"better"_ than the Anti-Bayesian Update on _not-not-E'_
(= _E'_ ).

Zsolt:  
  
I am sorry. I really just don't get the question. Anti-Bayesian update would
mean that you get E as evidence, and you conclude that E didn't happen. Let's
say you're not sure it's raining. You go outside, see that it's raining, and
therefore you assign probability 1 to its NOT raining. If that's not absurd, I
don't know what more to say.

Do you, Alexander, understand what I'm talking about here?  
I certainly don't understand, what you mean by "observing, that <"it is
actually raining"> AND simultaneously assigning to the probability of <"it is
NOT raining"> the value 1.  
Is that supposed to be a proper response to my previously given argument?  
(1) For evidence E, the Bayesian Update on evidence E is "better" than the
Anti-Bayesian Update on not-E.  
 **(2) Sometimes absence of evidence is evidence of absence or to say, that
sometimes not-E' is the evidence E: E = not-E'**  
From 1 and 2:  
(3) Therefore sometimes for evidence not-E', the Bayesian Update on evidence
not-E' is "better" than the Anti-Bayesian Update on not-not-E'(=E').  
If so, then here is my nonsensical response to your nonsensical (and
uncharitable) response:  
(1) For evidence E, the Bayesian Update on evidence E is "better" than the
Anti-Bayesian Update on not-E.  
 **(2) Sometimes absence of evidence e.g. <"it is raining"> is evidence of
absence or to say, that sometimes not-<"it is raining"> is the evidence E: E =
not-<"it is raining"> = <"it is not raining">**  
From 1 and 2:  
(3) Therefore sometimes for evidence <"it is not raining">, the Bayesian
Update on evidence <"it is not raining"> is "better" than the Anti-Bayesian
Update on not-<"it is not raining"> (= <"it is raining">).  
I feel so bamboozled by your response. Why are you calling yourself an
"analytical philosopher"?  
Seriously, you shouldn't call yourself that by giving such nonsensical
responses.  
  
*Sidenote: **What if your car is in the garage, while it's raining?**  
Yeah, weirdly enough Wade Tisthammer also couldn't answer that question
properly.  
And I don't wonder about that any more given him learning logic and
rationality from such persons, who shouldn't have called themselves
"analytical philosophers" in the first place or who are calling themselves
wrongly and falsely that currently.

I made up the term "anti-Bayesian update" so I get to say what it means. And
what it means is that when you get evidence E, you modify your credences just
like the Bayesian would have modified them on getting the evidence of not-E.
So, you observe that the it's raining, and you update your credences just like
the Bayesian would if the Bayesian observed that it's not raining. In other
words, the anti-Bayesian on getting evidence E pretends that they are a
Bayesian getting evidence not-E. Yup, that's the dumbest thing ever. That's
the point.

Really? That's supposed to be the dumbest thing ever?  
If so, then I guess, your Anti-Bayesian Update would be on pair with the
**prosecutor's fallacy - they are simply irrelevant as most of the work from
wrongly and falsely claimed to be "analytical philosophers"**. And therefore,
your whole blog post here is just irrelevant.  
  
How about a more relevant analysis about conditional probabilities then?  
Given the transpositions for material conditionals: For every proposition _P_
and proposition _Q_ it follows, that _[P → Q] ⇔ [~Q → ~P]_.  
Is this also true or in some way analogous for conditional probabilities?  
Is it for evidence _E_ and hypothesis _H_ , such that _P(H|E) = P(~E|~H)_ or
at least _P(H|E) ≈ P(~E|~H)_?  
And what about the material implication _[P → Q] ⇔ [~P ∨ Q]_?  
Is it then _P(H|E) = P(~E ∪ H)_ or at least _P(H|E) ≈ P(~E ∪ H)_?  
And further with De Morgan’s law [P → Q] ⇔ [~P ∨ Q] ⇔ [~(P ∧ ~Q)]?  
Is it then _P(H|E) = P(~(E ∩ ~H))_ or at least _P(H|E) ≈ P(~(E ∩ ~H))_?  
Relevant questions upon more relevant questions.  

_P(E→H) = P(~E∪H) = P(~E)+P(H)-P(~E∩H)  
=1-P(E)+P(E∩H)=1-P(E)+P(E∩H)/P(E)•P(E)  
=1+(P(H|E)-1)•P(E)_  
So,  
 _P(H|E)=1+(P(E→H)-1)/P(E)_ and  
 _P(E→H)=1+(P(H|E)-1)•P(E)_  
Further in the case of **_P(E) = 1_**  
we get the following:  
 _P(H|E) = P(E→H) = P(~H→~E)  
= P(~E∪H) = P(~(E∩~H))_  
  
Just in case someone was wondering about this.

People sometimes use the progress of science to argue for physicalism about
the mind. But it seems to me that Dostoevskii made more progress in
understanding the human mind by existential reflection than anybody has by
studying the brain directly. More generally, if we want to understand human
minds, we should turn to literature and the spiritual masters rather than to
neuroscience.

Thus, any argument for physicalism about the mind from the progress of science
is seriously flawed. And perhaps we even have some evidence _against_
physicalism. For it is a surprising fact that we learn more about the mind by
the methods of the humanities than by study of the brain if the mind is the
brain.

A bit of a weird question, but what are your thoughts on the compatibility of
LFW with a Groundhog Day Loop situation, where you repeat the last day many
times after waking up, and the people keep doing the same things and making
the same choices over and over again. The only exception being yourself (as
you know you're in the loop) and any person you directly interact with
significantly differently than before.  
  
Would such a scenario where people repeat the same choices to the point you
can literally predict what a person will do next be incompatible with
Libertarian Free Will, or could it be accommodated?

It's like when people toss a fair coin and it keeps coming up heads. It's
super unlikely, but logically possible.

I'm trying to thin the herd of old computers at home. I realized that the only
real reason I had a 20-year-old Linux box at home was if I ever wanted to use
a 3.5" drive in it to deal with floppies for various systems, especially my HP
1653B oscilloscope (I could get a USB floppy drive for one of the laptops at
home, but they aren't usually compatible with non-DOS disk formats).

And now I can read and copy floppies for my oscilloscope on my laptop. :-)

From time to time I’ve had occasion to make use of examples where someone says
different things to two different interlocutors in a single utterance. My
favorite examples were pointing to a bottle and saying “Gift!”, which would
mean a very different thing to a German speaker and to an English speaker, or
using coded language while speaking to someone while knowing a spy is
overhearing. Such examples illustrate the interesting fact that we cannot
identify propositions with equivalence classes of utterance tokens, because a
single utterance token can express different propositions.

But arguments based on such contrived cases have a tendency to be less than
convincing. However, it has just occurred to me that dog whistles in politics
are a real-life example of the same phenomenon, and one technically within a
single language.

By the way, if we’re looking for equivalence classes that function like
propositions, I guess instead of looking at equivalence classes of tokens
utterances, we should look at equivalence classes of context-token pairs,
where a context includes the language and dialect as well as the (actual?
intended?) audience.

Alice knows that her friend Bob has no pets and no experience with birds.
While recommending Bob for a birdkeeping job at a zoo and having discovered or
to be surprisingly ignorant about birds, she says:

It seems that Alice is lying. Yet it seems that to lie one must assert, and to
assert one must express a proposition. But Alice’s sentence does not express a
proposition since “triggle” is meaningless.

But entailment is a relation between propositions, and (1) neither is nor
expresses a proposition. We might want to say that if it _did_ express a
proposition, it would express a proposition entailing (2). But even that isn’t
so clear. After all, maybe a world where “triggle” denotes a science-fictional
beaked reptile is closer than a world where it denotes a kind of bird (imagine
that some science-fiction writer _almost_ wrote Southern yellow-beaked
triggles as reptiles into a story but stopped themselves at the last moment).

Here is what I think I want to say about what Alice did. According to Jorge
Garcia, what makes lying bad one linguistically solicits trust that what one
is saying is true, while at the same time betraying that trust. Alice did
exactly that, but without asserting. So, while Alice did not lie, she did
something that is wrong for the same reason that lying is.

I'm actually not convinced that assertion requires asserting a proposition
(rather than asserting something *as* a proposition), but even setting this
aside, (1) seems straightforwardly false; Alice is proposing that Bob has a
fine collection of what cannot be collected at all. If I say "John drew a
square circle" or "Pedro owns a fine xksksksa", the fact that my predicate
term includes something nonsensical or meaningless doesn't make these
nonpropositions but false propositions -- no inventory of what can be drawn
will ever include square circle, no inventory of what Pedro owns includes
xksksksa. Likewise, no inventory of what Bob has a fine collection of will
ever include a triggle.

Independent of the _grounds_ for why lying is wrong, it still seems true to
say that Alice _attempted to lie_. Now if lying is always wrong (or at least
wrong in this circumstance) that Alice was acting wrongly in attempting to
lie. That fact may be sufficient to satisfy our intuitions about where Alice
has gone morally wrong in this scenario.

Brandon:  
  
If a proposition is false, its negation is true. "Pedro doesn't own a fine
xksksksa" would then be true (at least given that Pedro exists; otherwise, we
would opt for the broad scope negation). But what would that say about the
world? What is it that he doesn't own?  
  
ASBB:  
  
But Alice knows that she is uttering nonsense. She isn't trying to speak sense
and failing.

Alex,  
  
It seems obvious to me that "Pedro doesn't own a fine xksksksa", which is
strictly the negation of the proposition, is true; if we took a complete
inventory of what Pedro owns, xksksksa would not indicate anything on it. The
error, it seems to me, is thinking that an object tucked inside a predicate
has to exist or even be meaningful in order for the preciate to be
meaningfully applied to the subject.  
  
Compare: "Pedro is drawing a square circle." This is false, at least if by
'drawing' we mean really drawing and not merely trying to draw, because square
circles cannot be drawn. Its negation, "Pedro is not drawing a square circle",
is true. It doesn't make any sense to reply to this, "What in the actual world
is it that he is not drawing?" We are simply saying that 'square circle' is
not in any accurate inventory of what Pedro is drawing (because it can't be
any inventory of anything actually drawn). If we didn't say something like
this, it would be impossible for us to assert anything about impossibilities.  
  
Now, one could argue that we can give nominal definitions of impossibilities
like 'square circle', even if not real definitions, and that this is a
potentially significant difference between the two cases, since in the square
circle case we have an inconsistent definition and in the xksksksa and triggle
cases we have no definition at all. But we do know enough to know that
xksksksa and triggle are not actually corresponding to anything, as opposed to
just being foreign words or even words of a conlang; and we know that as such
we can dismiss any attempt to place them in any inventory of owned or
collected things. They fall outside of the particular universe discourse,
which in all other cases (even ordinary cases) indicates the truth of the
negation. If I say, "There is a black cat," when talking about a particular
group of cats, but determine that in that universe of discourse, i.e., that
particular group of cats, there is no black cat, then it's false. The same
thing is true of the square circle case, since it's false because square
circles necessarily fall outside of the relevant universe of discourse. Thus
by parity we should say the same of 'Pedro-owned xksksksa'; xksksksa is just
not able to be in the universe of things owned by Pedro. Therefore "Pedro owns
a fine xksksksa" is necessarily false. It has to be false if we at least can
know enough about the use of 'xksksksa' to know that it is meaningless, since
we know that meaningless things fall out of the universe of discourse.  
  
This would differ from purely meaningless statements, in which we cannot
establish a universe of discourse at all.

If "xksksksa" is completely meaningless, we can't even parse "Pedro owns a
fine xksksksa". Is "fine" a noun or an adjective? Imagine that "xksksksa" is a
meaningless rasping cough. Then the sentence is: "Pedro owns a fine [cough,
cough]". Then "fine" is a noun. (What does it mean to own a fine? That's not
clear, either. Is it like owing a fine or someone owing one to you?) Or what
if "xksksksa" means the same thing as "nothing"? Then "Pedro owns a fine
nothing" is a weird way of something that he is without possessions.  
  
There is a difference between something like "square circle" and merely
gobbledy-gook. We understand the phrase "square circle". Indeed, it is because
we understand it that we know that it is impossible to have one.

_If "xksksksa" is completely meaningless, we can't even parse "Pedro owns a
fine xksksksa"._  
  
I don't think this is right; we can easily parse it. A part of speech is a
function, and xksksksa is being put in a direct object place, and therefore is
operating functionally in this sentence as something that can be a direct
object. The meaninglessness of the word itself does not imply that it is not
being put forward as serving a function in the sentence, and it is the latter
that is captured when we are parsing. 'xksksksa' has no meaning, but the
sentence in which it occurs can be straightforwardly parsed, on the basis of
which we know that "Pedro owns a fine xksksksa" is trivially false. And in
fact, this is necessary: we very often have to parse sentences even if we
don't know what the meaning of particular words.  
  
Indeed, this capacity to parse sentences without requiring particular words to
have meaning is essential for natural language regimentation and
formalization. Consider: "Pedro owns an X" or "There is an X such that Pedro
owns it". We can parse this, make sense of the sentence, despite the fact that
a variable is not a word with a meaning. "All S is P" is easily parsed even
though neither the subject nor the predicate mean anything. It's because
parsing is about function and not about content that we can have formal
systems.  
  

Brandon:  
"Pedro owns a fine always."  
"Pedro owns a fine---nohedoesn'townanythingfine!"

Thought experiments like Searle’s Chinese Room are supposed to show that
understanding and consciousness are not reducible to computation. For if they
are, then a bored monolingual English-speaking clerk who moves around pieces
of paper with Chinese letters letters—or photographic memories of them in his
head—according to a fixed set of rules counts as understanding Chinese and
having the consciousness that goes with that.

I used to find this an extremely convincing argument. But I am finding it less
so over time. Anybody who thinks that computers could have understanding and
consciousness will think that a computer can run two different simultaneous
processes of understanding and consciousness sandboxed apart from one another.
Neither process will have the understanding and consciousness of what is going
on in the other process. And that’s very much what the functionalist should
say about the Chinese Room. We have two processes running in the clerk’s head.
One process is English-based and the other is a Chinese-based process running
in an emulation layer. There is limited communication between the two, and
hence understanding and consciousness do not leak between them.

If we accept the possibility of strong Artificial Intelligence, we have two
choices of what to say about sandboxed intelligent processes running on the
same hardware. We can say that there is one person with two centers of
consciousness/understanding or that there are two persons each with one
center. On the one person with two mental centers view, we can say that the
clerk does understand Chinese and does have the corresponding consciousness,
but that understanding is sandboxed away from the English-based processing,
and in particular the clerk will not talk about it (much as in the computer
case, we could imagine the two processes communicating with a user through
different on-screen windows). On the two person view, we would say that the
clerk does not understand Chinese, but that a new person comes into existence
who does understand Chinese.

I am not saying that the proponent of strong AI is home free. I think both the
one-person-two-centers and two-person views have problems. But these are
problems that arise purely in the computer case, without any Chinese room kind
of stuff going on.

The one-person-two-centers view of multiple intelligent processes running on
one piece of hardware gives rise to insoluble questions of the unity of a
piece of hardware. (If each process runs on a different processor core, do we
count as having one piece of hardware or not? If not, what if they are
constantly switching between cores? If yes, what if the separate the cores to
separate pieces of silicon that are glued along an edge?) The two-persons
view, on the other hand, is incompatible with animalism in our own case.
Moreover, it ends up identifying persons with software processes, which leads
to the unfortunate conclusion that when the processes are put to sleep, the
persons temporarily cease to exist—and hence that _we_ do not exist when
sufficiently deeply asleep.

These are real problems, but no additional difficulty comes from the Chinese
room case that I can see.

I think that this objection is similar to the systems and subsystems replies.
The systems reply holds that from the fact that the clerk doesn't understand
Chinese, it does not follow that the room doesn't understand Chinese. To fix
this, we can suppose that the clerk "absorbs" the room by memorizing the
rulebook and running through the program mentally without using paper and
pencil. At this point, the subsystems reply kicks in: From the fact that the
clerk (who is now the entire system) does not understand Chinese, it does not
follow that no subsystem in the clerk's head understands Chinese. Perhaps, in
virtue of the clerk running the program, there is a homunculus inside the
clerk that understands Chinese, a second stream of consciousness that the
clerk is not aware of. B. Jack Copeland, for instance, defends this argument.
In one of my papers, I attempt to defend the Chinese room from this objection
by applying the Chinese room scenario to the homunculus. The basic strategy is
to replace the homunculus inside the clerk with another clerk. Now, either the
homunculus understands Chinese in virtue of running a computer program or it
does not. If not, then the homunculus understands for some other reason and
therefore Strong AI is ruled out as the explanation. The homunculus does not
understand simply in virtue of running a program. If so, then have another
clerk run whatever program the homunculus is running (this program would be a
sub-program of the overall program that the first clerk is running). For the
same reason that the original clerk does not understand Chinese, the second
clerk also will not understand Chinese. Suppose, however, that we posit a
homunculus inside this second clerk that understands Chinese. In this case, we
can apply the Chinese room to this second homunculus just as we did with the
first. The overall end result is either an infinite regress or we get to a
point where some non-computational process explains (or at least contributes
to an explanation of) a consciousness that understands Chinese. Thus, the
thesis that computation, by itself, is sufficient for conscious understanding
is false. (I apologize for any sloppiness or typos as I am typing this on the
phone).  
  
Thoughts?

I never understood the notion of the "room understanding Chinese". The whole
point is that computation is like syntax without semantics. Where in the
"room" can you find the signified? Not the symbols, not the rules and
therefore neither the book nor the clerk. Without intentionality, we cannot
speak of language and therefore intelligence.  
  

I'm not convinced of the Chinese Room thought experiment showing consciousness
not being reducible to computation as I'm not convinced of the conceivability
of the existence of Philosophical Zombies without any consciousness supposedly
implying physicalism to be false.  
Physicalism either obtains or doesn't obtain consciousness and consciousness
might be or might not be reducible to physicalism.  
It might be even the case, that there are some physical minds as there are
some non-physical mind. At this point it is really not, that we could really
disregard either possibilities with our yet incomplete understanding and
knowledge about Nature, Science and Consciousness.  
Just because we can conceive a program giving perfect Chinese responses and
simultaniosy not being conscious about those responses, from that doesn't
follow, that it is metaphysically not possible for there to be a program
giving perfect Chinese responses AND simultaneously being conscious about
those responses.  
It might also be just the case, that we have really bad methods for testing
and differentiating between such two similar yet very distinct cases.

Colin:  
  
This is very interesting, but I think the homunculus solution may be different
from mine. The homunculus solution is a two-person solution. But the case of
the computer running two parallel conscious processes sandboxed from each
other shows that it is not right to identify the person with something that
performs the computation or runs some software. For it is the hardware that
performs the computation and runs the software, and there is only one relevant
piece of hardware, and yet two persons. Thus, in the Chinese room case, the
two-person functionalist should not identify the clerk with a physical object,
but with a process running in a physical object's brain. The process is
constituted by a piece of running software, and it is a category mistake to
think of the process as performing the computation or running the software.  
  
There is still a homunculus. For the computational process P1 that is the
clerk has a subprocess P2 that is a Chinese speaker. But I think your
objection no longer applies. For P2 does not understand in virtue of running a
program. Rather, P2 understands in virtue of being constituted by the running
of a program C (for Chinese), just as P1 understands in virtue of being
constituted by the running of a program E (for English). It is true that P2 is
some sort of emulation subprocess of P1, of course. Your suggestion was to
have another clerk run whatever kind of software the homunculus is running.
But now the homunculus is constituted by the running of C, rather than the
homunculus itself being the subject running C. If we extract C and let it run
directly on another clerk, without the emulation subsystem, then what we have
is just a clerk who is perfectly ordinary Chinese speaker.  
  
On the other hand, if we take the one-person two-personality view, then there
isn't any homunculus. There is just one person with two consciousness
processes somewhat sandboxed from each other. The clerk understands English
and the clerk understands Chinese, but the two understandings are largely
sandboxed from each other.  
  
For Christian readers, it is worth making note of the fact that if the
Incarnation makes sense, so does the one-person reading of the Chinese room.
For Christ has two minds, a human mind and a divine mind, and presumably there
is a separate stream of consciousness associated with each mind, so that
Christ by his human mind need not be aware of what he is aware of by the
divine mind (though of course by omniscience, he is aware of absolutely
everything by the divine mind).

I knew it! You all have and hear multiple distinct voices in your heads.  
So then what's wrong with me, if I only have and hear my one and only voice in
my head?  
Also I can't hear other voices from other heads directly only indirectly by
sound waves. So I can not directly confirm you all having multiple distinct
voices in your heads.  
Is there such a method to directly confirm such hypothesis?

Dr. Pruss,  
  
Thanks for the reply! I’m understanding more clearly now. Yes, I agree that in
your proposed scenario, my objection no longer applies. The homunculus doesn’t
understand in virtue of running the program itself, but is rather constituted
by a running program that is executed by something else. On that theory, I
concur that it seems like the Chinese room is simply inconclusive. I tend to
think that the most fundamental argument against computationalism/Strong AI is
the idea that computation is itself a mind-dependent phenomenon. Something
counts as performing a computation only if an observer interprets the physical
states of the system as having computational significance. Sometimes this
argument is taken in the direction of pancomputationalism, the idea that every
physical system computes everything. And if pancomputationalism is true and
Strong AI is true, then this would entail panpsychism. Thus, if we reject
panpsychism, then we should reject Strong AI. I think, however, that there are
good arguments against pancomputationalism. But the idea of the mind-
dependence of computation doesn’t entail pancomputationalism and so even if
that is false, the mind-dependency argument could still go through. There may,
in the functionalist spirit, be non-trivial causal constraints that limit what
kind of physical system could function as a computer. Similarly, there are
non-trivial causal constraints on what sort of a thing could function as a
knife. For example, steel will do the job of cutting, but shaving cream will
not. So, not just any old thing could function as a knife. Nevertheless, that
something counts as a knife at all is dependent on our attitudes towards it. A
knife is an artifact. I think that a similar thing applies to computation in
physical systems. Perhaps not any old thing could function as a computer.
Nevertheless, that a given thing is a computer is dependent on our attitudes
towards it. If this is right, then computation is to be explained in terms of
mind rather than mind in terms of computation. Obviously, this is just a very
basic sketch.

That's basically one of the main reasons I have always been suspicious of
Strong AI.  
  
There is a way out of this, but it is expensive: require teleology for
computation. This undercuts pancomputationalism, since not all of the abstract
ways that a physical system could be said to compute realize the system's
teleology. To save Strong AI, we can say that you can get teleology from a
programmer. To save physicalist functiodnalism about human beings, we can then
say that you can get teleology from evolution (Millikan, etc.). The cost is
that consciousness now becomes an extremely extrinsic property: a computer's
being conscious is partly constituted by the intentions of the programmer and
a human's being conscious is partly constituted by what evolutionary events
happened millions of years ago (and besides that, there are serious technical
problems with the evolutionary reduction of teleology).  
  
\--  
  
Note that it's not just panpsychism that results from Strong AI and
pancomputationalism. Panpsychism doesn't seem so terrible to me. But what we
get is what one might call panomnipsychism--every physical system is in every
possible phenomenal state at every time. That undercuts lots of ethics as then
there is no point to relieving anyone's suffering, because every system is
always suffering in every possible way anyway.

By the way, causal constraints on what can function as a computer are not
enough. For we still get omnicomputationalism about computers--anything that
IS a computer satisfies the causal constraints, and hence computes everything
all the time--and hence, given functionalism, my laptop right now has every
possible conscious state. Rather, we need causal constraints on what process
can count as a computation of a particular sort (e.g., what process can count
as an addition).  
  
This causal constraint view seems to me to be problematic for multiple
reasons. The first is that you have no epistemic access to what the causal
constraint is besides the fact that your brain fulfills the constraint. It's
reasonable for you to generalize from that that all human brains fulfill the
constraints, and maybe even all brains on earth. But it is not reasonable to
generalize that alien life forms fulfill the constraints. This leads to an
implausible scepticism about alien consciousness.  
  
Second, now it seems lucky that the evolved beings on earth meet the
constraint. (Remember that we don't know what the constraint is, besides the
fact that human brains meet it.) Why did evolution come up with a solution
that meets the constraint rather than a solution that produces the same
behavior but does not meet the constraint? This isn't a problem for theists,
but is a problem for physicalists.  
  
Third, if this is actually going to support Strong AI, then we have the
problem that we have no idea of what hardware architectures actually meet the
constraints. What if carbon is required? What if only analog systems are
allowed? How many layers of emulation and of what sort are allowed?

A static solution to Wordle would be a sequence of five guess words which
would distinguish all the answer words. I've run C-based parallel nearly-brute
force (with some time-saving heuristics) code to try to see if there is a
static solution. No luck so far. The closest I have is **flitt dawds vughy
kerel combo paean** , which leaves two pairs undistinguished (spine/snipe and
gauge/gauze). There may be a full solution, but I don't have it. (Note: I am
working with the original answer list, not the modified New York Times one.)

It is only permissible to punish a person for doing what is morally wrong.

It is permissible for the state to punish a person for disobeying law.

This is already an interesting and somewahat controversial conclusion. It
pushes us to the view that when the law forbids something that is innately
morally permissible—such as driving on the left side of the road—that thing
becomes morally impermissible.

I suppose all this focuses one’s attention on (1). The opposing view would be
that it is permissible to punish a person for doing things that are legally
wrong even when they are _merely_ legally wrong. But this seems mistaken. A
person who fulfills all moral imperatives is perfectly innocent. But it is
wrong to punish a perfectly innocent person.

Hello, Dr. Pruss.  
  
I hope this comment finds you well.  
  
My question is not related to this post; I was wondering what your current
view is with respect to causal finitism. My goal is to purchase your book:
Paradox, Causation, Infinite; though I'm wondering if you still accept much of
the ideas in the book.

While I see some complications I didn't see at the time, and have one or two
additional arguments for causal finitism, basically I don't have any
significant shift.

Do you think you'll ever publish a revised version that addresses the
complications you came to see later? Or have you written about it elsewhere?

Tell me what you think of this objection to (1).  
  
Suppose smoking marijuana is morally permissible. The USFG has prohibited it,
and it continues to punish those guilty of possessing marijuana. On (1), this
is morally impermissible.  
  
But there are other considerations that count against breaking laws that
prohibit perfectly moral behavior. For example, regularly breaking this law
might disrupt the stability of a society. It might show disrespect to rulers,
which is morally impermissible. (In regard to disrespect, a close analogy is a
child refusing to obey her parent's command to not play a game even if playing
that game is perfectly fine and the parent's command is mistaken.).  
  
I think you raised this objection when I presented my jury nullification paper
in colloquium: perhaps we should not nullify in cases of unjust punishment
because there may be other considerations that make it all-things-considered
wrong to nullify.  
  
What do you think?  
  
(keep posting about stuff like this! I can't keep up with the heady
metaphysics and bayesianism!!!)

This is very interesting. On your hypothesis that smoking marijuana is morally
permissible, are you assuming that it is still morally permissible after the
state has forbidden it? My view would be that smoking marijuana (in
moderation, when there is no significant danger of addiction) is intrinsically
morally permissible, but becomes morally impermissible once the law is in
place. In this regard (and not only!), it differs from worship of God, which
is intrinsically morally permissible, and the state cannot make it
impermissible.

It’s mildly interesting to note, when evaluating the evidential impact of
evil, that there can be evil events that would be evidence for the existence
of God. For instance, suppose that three Roman soldiers who witnessed Christ’s
resurrection conspired to lie that he didn’t see Christ get resurrected. That
they lied that they didn’t see Christ get resurrected entails that they
thought they witnessed the resurrection, and that would be strong evidence for
the existence of God, even after factoring in the counterevidence coming from
the evil of the lie. (After all, we already knew that there are lots of lies
in the world, so learning of one more won’t make much of a difference.)

In fact, this is true even for horrendous and apparently gratuitous evils. We
could imagine that the three soldiers’ lies crush someone’s hopes for the
coming of the Messiah, and that could be a horrendous evil. And it could also
be the case that we can’t see any possible good from the lie, and hence the
lie is apparently gratuitous.

But Alex, the actual evidence for the existence of God would be the
resurrection itself. The lies do not add anything to that evidence.  
If the lies do constitutie evidence, the evil of the lies is not gratuitous,
unless you believe evidence for God is not good.  
  

Consider two events:  
L1: The soldiers said that they didn't see Christ get resurrected.  
L2: The soldiers lied that they didn't see Christ get resurrected.  
L1 is evidence that Christ did NOT get resurrected. L2 is evidence that Christ
DID get resurrected (since if they lied that they didn't see it, then they at
least thought they saw it). The two events are closely related. They might
even be the same coarse-grained event. If so, then my argument requires fine-
grained events. And, in any case, coarse-grained events are not appropriate as
evidence, I think.  
  
But L2 can still be gratuitous even if it is evidence for the resurrection.
For the fact that it IS evidence for the resurrection--and as a Bayesian, all
I really mean by that is that P(Resurrection | L2) > P(Resurrection |
~L2)--does not mean that anyone TAKES IT as evidence for the resurrection. The
only way to take it as evidence for the resurrection would be if one had
evidence independent of the resurrection that the soldiers were lying. And it
would be unlikely that we would have such evidence (unless we subjected them
to a correctly functioning lie detector).

If one thinks that one should always switch to a weakly dominating option,
then this conclusion provides an argument for probabilism.

One might, however, reasonably think that it is only required to switch to a
weakly dominating option when one assigns non-zero probability of the weakly
dominating option being better. If so, then we get a weaker conclusion: your
credences should either be irregular (i.e., assign zero to some non-empty set)
or probabilistic. But a view that permits violations of the axioms of
probability but only when one has irregular credences seems really
implausible. So your credences should be probabilistic.

The big question is whether _probability distinguishing_ is any more plausible
as a condition on a scoring rule than strictness of propriety. I think it has
_some_ plausibility, but I am not quite sure how to argue for it.

###  Truth-directedness and propriety of scoring rules does not imply strict
propriety

A scoring rule assigns a score to a credence assignment (which can but need
not satisfy the axioms of probability), where a score is a random variable
measuring how close the credence assignment is to the truth.

A scoring rule is strictly truth-directed provided that if _c_ ′ is a credence
assignment that is closer to the truth than _c_ is at _ω_ , then _c_ ′ gets a
better a score at _ω_. A scoring rule is proper provided that for all
probabilities _p_ , the _p_ -expected value of the score of a probability _p_
is at least as good as the _p_ -expected value of the score of any other
credence, and is strictly proper.

Propriety for a scoring rule is a pretty plausible condition, but it’s a bit
harder to argue philosophically for strict propriety. But scoring-rule based
philosophical arguments for probabilism—the doctrine that credences ought to
be probabilities—require strict propriety.

Here’s an interesting fact I will show: propriety plus strict truth-
directedness do _not_ imply strict propriety in the absence of additivity.
Further, my counterexample will be bounded, infinitely differentiable and
strictly proper on the probabilities. Personally don’t find additivity all
that plausible, so I conclude the Campbell-Moore and Levinstein move does not
move the discussion of strict propriety and probabilism ahead much.

Let _Ω_ = {0, 1}. Given a credence function _c_ (with values in [0,1]) on the
powerset of _Ω_ , define the credence function _c_ * which has the same value
as _c_ on the empty set and on _Ω_ , but where _c_ *({0}) is the number _z_ in
[0,1] that minimizes ( _c_ ({0})− _z_ )2 \+ ( _c_ ({1})−(1− _z_ ))2, and where
_c_ *({1}) = 1 − _c_ *({0}). In other words, _c_ * is the credence function
closest to _c_ in the Euclidean metric such that _c_ *({0}) + _c_ *({1}) = 1.

Now let _b_ *( _c_ ) = _b_ ( _c_ *). Then _b_ * agrees with _b_ score on the
probabilities, and hence is strictly proper on them. Further, every value of
_b_ * is a Brier score of some credence, and hence _b_ * is proper.

We now check that it is strictly truth-directed. Brier scores are strictly
truth-directed. Thus, replacing a credence function with one that is closer to
the truth on _Ω_ or on the empty set will improve the _b_ * score. Moreover,
it is easy to check that _c_ *({0}) = (1+ _c_ ({0})− _c_ ({1}))/2. It’s easy
to check that if we tweak _c_ ({0}) to move us closer to the truth at some
fixed _ω_ ∈ {0, 1}, then _c_ * will be closer to the truth at _ω_ as well, and
similarly if we tweak _c_ ({1}) to be closer to the truth at _ω_ , and in both
cases we will improve the score by the strict truth-directedness of Brier
scores.

Finally, however, note that _b_ * is not strictly proper and does not have a
domination theorem of the sort used in arguments for probabilism, since the
_b_ *-score of any credence _c_ that fails to be a probability due to its
being the case _c_ ({0}) + _c_ ({1}) ≠ 1 but that gets the right values on the
empty set and _Ω_ (zero and one, respectively) is equal to the _b_ *-score of
_c_ *, and _c_ * will be a probability in that case.

Note that in the example above we don't have quasi-strict propriety either.

A scoring rule _s_ assigns to a credence _c_ on a space _Ω_ a score _s_ ( _c_
) measuring the inaccuracy of _c_. The score is itself a function from _Ω_ to
[−∞, _M_ ] (for some fixed _M_ ), so that _s_ ( _c_ )( _ω_ ) measures the
inaccuracy of _c_ if the truth of the matter is that we are at _ω_ ∈ _Ω_. A
scoring rule is proper provided that _E_ _p_ _s_ ( _p_ ) ≤ _E_ _p_ _s_ ( _c_ )
for any probability _p_ and any other credence _c_ : i.e., provided that the
_p_ -expected value of the score of _p_ is at least as good as (no more
inaccurate than) as the _p_ -expected value of any other score. It is strictly
proper if the inequality is strict. It is quasi-strictly proper if the
inequality is strict whenever _p_ is a probability and _c_ is not.

**Theorem:** Let _s_ be any continuous bounded proper scoring rule that is
defined only on the probabilities. Then _s_ can be extended to a continuous
bounded quasi-strictly proper scoring rule defined on all credences.

This result works in the finite-dimensional case with standard Euclidean
topologies on the space of credences (considered as elements of [0,1] _P_ _Ω_
) and on the scores (considered as values in [−∞, _M_ ] _Ω_ ). But it also
works in countably-infinite-dimensional contexts in the right topologies (ℓ∞(
_P_ _Ω_ ) on the side of the credences and the product topology on the side of
the scores), regardless of whether by “probabilities” we mean finitely or
countably additive ones.

First, show that the probabilities are a closed subset of the space of
credences.

Third, let _s_ 1( _c_ ) = _d_ ( _c_ , _P_ ) + _s_ 0( _c_ ), where _Q_ is the
set of credences that are probabilities and _d_ ( _c_ , _Q_ ) is the distance
from _c_ to _Q_ in the ℓ∞( _P_ _Ω_ ) norm. This equals _s_ 0( _c_ ) and hence
_s_ ( _c_ ) for a credence _c_.

I don’t know if there is much of a philosophical upshot of this. Maybe a kind
of interesting upshot is that it illustrates that quasi-strict propriety is
easy to generate?

I think that scoring rules for non-probability credences are either ad hoc or
a spandrel, except maybe if we assume additivity.

BTW, in Step 2 we can make s0 have the same range as s if we want: just apply
the Dugundji extension theorem to the identity function on the set of all
probabilities (which is a convex set) to get a continuous function f from
credences to probabilities that is equal to identity on the probabilities.
Then let s0(c)=s(f(c)).

If naturalism is true, the appropriate attitude towards great adversity is
Russellian.

The reason for (1) is the obvious attractiveness of the hopeful-to-calm part
of the emotional spectrum as a way of dealing with diversity.

The reason for (2) is that emotions should fit with reality. But as Russell
argues, a naturalist reality does not care about us: we came from the nebula
and we will go back to the nebula, and the darkness of our life makes Greek
tragedy the supreme form of human art. The most we can do shake our fist at
the injustice of it all.

I'm curious why the naturalist cannot respond to great adversity with calm
like the Stoics. If reality, according to the naturalist, does not care for
us, then it seems reasonable to respond with calm to adversity. After all, one
could not truly expect things to go otherwise. Reality just is what it is, so
calm acceptance of one's fate seems like an acceptable response that fits with
a naturalist reality.

Alex  
  
I would consider myself a naturalist accepting Nature, as it is, calmly.  
But sometimes I'm at the depth of despair and anger while witnessing a
supposedly not just self acclaimed mathematician and philosopher proposing and
suggesting Newtonian Mechanics and with that associated ordinary differential
equations to be false because of them being incompatible with discontinuous
positions and discontinuous functions.  
  
 _"Two things are infinite: the universe and human stupidity; and I'm not sure
about the universe."_  
maybe or maybe not from Albert Einstein,  
but certainly from a wise man

Alex:  
  
Emotions should reflect reality. Distress, sadness, anger and other negative
emotions are the appropriate attitudes to unredeemed evils, just as joy,
gladness and other positive emotions are the appropriate attitudes to non-
undermined goods. The world is full of evil. If naturalism is correct, we do
not expect this evil to be redeemed. On the contrary, on naturalism, we expect
the ultimate destruction of everything of human value (the Russellian return
to the nebula). Negative emotions are the right attitude, then.

I should add that not everyone thinks that there is such normativity to
emotions. I accept the Socratic view that emotions are a way of perceiving
normative features of reality. Thus fear is a way of seeing a potential future
bad, etc.

Alex (P)  
  
Emotions should reflect thé reality that there are things nobody van do
anything about.  
Why on earth should anybody feel angry, distressed etc. about that?  
  
Anyway, I don't feel that way and nobody has the right to Tell me how I
'should' feel.  

My Socratic view is that emotions have a truth-directed proper function much
like the senses do. Our skin's thermal sensors sense temperature in our
physical proximity. If on a hot day I don't feel hot, my thermal sense is
malfunctioning. This is true even if it there is nothing I can do nothing
about the heat and the feeling is inconvenient. Similarly, our irascible
faculty senses injustice in the relevant context. If an injustice becomes
contextually relevant and we feel not the slightest anger, our anger sense is
malfunctioning. This is true even if there is nothing I can do about the
injustice and the feeling is inconvenient.  
  
You may well just not share this truth-directed picture of emotions. If so,
the argument will probably do nothing for you--premise (2) will unsupported.
But I think it is an attractive picture of emotions that helps with ethical
epistemology by explaining how it is that emotions can appropriately
epistemically bear on ethical questions.  
  
On this view, to say how someone should feel anger in some situation is just
as appropriate as saying that one should feel hot when the temperature is
110F, or that one should have a perception of green when looking at healthy
grass in daytime, etc. These are facts about proper function that we just
discover as we go through life, and they are universally applicable.

Alex  
  
I do share a truth -directed picture of emotions.  
But the truth is that there is no 'injustice' and ,to borrow your language, we
'should' accept this.  
So, my emotions are truth-directed, but yours aren't.

I don't see how stoicism wouldn't be a proper response. If the stoic maxim is
to be unperturbed by that which is out of your control, then surely it would
be a fitting response to an indifferent or uncaring universe?

Michael:  
  
Because it's the wrong view of the cognitive content of negative emotions.
Bads outside of one's control are just as bad, and sadness is a response to
badness, not to just to badness-in-one's-control.  
  
In fact, I think on the Stoic view, sadness would never be appropriate. Any
past or present bad is now out of our control, and hence sadness would not be
appropriate. For future bads out of our control, sadness would not be
appropriate. And for future bads in our control, well if they are in our
control, then we shouldn't be sad because we may yet avoid them. But the idea
that a basic emotion is never appropriate is implausible.

The examples, like Rowe’s, of evils in the inductive argument from evil are
chosen to make them have a certain epistemic feature _F_. And the claim is
that _P_ ( _E_ has _F_ | God) < _P_ ( _E_ has _F_ | no God), with the
background information containing the occurrence of _E_ (i.e., the evidence
isn’t that the evil has occurred, but that the evil has _F_ ). Exactly what
_F_ is differs from paper to paper, but roughly the feature is that after
investigation we don’t have a plausible candidate theodicy.

But not every evil has _F_. If every evil had _F_ , then the examples in the
literature wouldn’t run as heavily as they do to lethal harm to children and
animals. The examples used by the atheological arguers are chosen to be
particularly compelling and what makes them compelling is that they have _F_
—nobody runs an inductive argument from evil based on robber barons getting
stomachaches from too much caviar, because such evils do not have _F_.

So there are evils that don’t have _F_. And then _P_ ( _E_ has ∼ _F_ | God) >
_P_ ( _E_ has ∼ _F_ | no God) by Bayesianism. So checking whether an evil has
_F_ sometimes yields an argument against the existence of God (namely when the
evil does have _F_ ) and sometimes yields an argument for the existence of God
(when the evil doesn’t have _F_ ).

And we do not know (as far as I know, Tooley is the only one to have made a
serious attempt to figure it out, and his account fails for technical reasons)
what the result is once the evidence is consolidated.

Some arguments make F be such that ~F entails the existence of God. For
instance, F could be: we do not know the reasons God actually has for allowing
E. In that case, the atheist will not grant that there are Es that have ~F.
But that seems to me to be a bad way to run the argument from evil, because we
should argue from stronger evidence if we can, and the stronger evidence is
that we do not know reasons that God *would have* (if we he existed) for
allowing E.

Alex  
  
But why would a robber barron having a stomach ache be more.probzble on
theism?

I was thinking of the evil being the stomachache, not the robber baron's
existence. :-)

So was I, so how is his stomachache more probable on theism.

Alex, I think perhaps there is a probabilistic mistake here in your reasoning.  
  
Let evidence E in the evidential PoE be  
  
"There are evils that have property F."  
  
If this is evidence against theism, then it's correct to say that ~E must be
evidence for theism. (Though as a digression, I shd. point out that the
evidences can be of vastly different magnitudes.)  
  
But the correct statement of ~E is  
  
A: "It is not the case that there are evils that have property F."  
  
To say, B: "There are evils that do not have property F" is not to state ~E,
nor does it follow from "E is evidence against theism" that B is evidence for
theism. B is fully compatible with either E or ~E.

Lydia,  
That there are evils that have F is quite unsurprising on theism if it's part
of the background that there are lots of evils. If there are lots of evils,
even if none are gratuitous, it's unsurprising that some look gratuitous. Just
as, if there are lots of cats, it's unsurprising that some look like dogs.  
So the evidence I am interested in is that a particular token evil E has or
lacks F.

But no one who is actually pressing the evidential POE is going to grant that
given theism it is highly likely that there are lots of evils, much less that
in that case it's likely that some will look gratuitous. (Btw, I've never seen
a cat that looked like a dog, and I've seen lots of cats, so I'm not sure I
would even grant your premise. But let's make it even crazier--given there are
lots of cats, is it unsurprising that some look like jellyfish? elephants?
airplanes?)  
  
I take it that the person pressing the POE is arguing that some evils really
*are* gratuitous, though perhaps granting that this is a fallible but highly
well-supported premise, and then is taking the E to be that there are evils
that are gratuitous. In which case, the negation is what I've stated--that
there are no evils that are gratuitous.  
  
The occurrence of acknowledged trivial evils--a paper cut, stubbed toe, brief
tummy ache--simply doesn't seem to tell either way. In fact, I have trouble
seeing how anyone could argue that the existence of trivial "evils" is
evidence *for* theism. It's certainly readily compatible with there either
being or not being gratuitous evils, and for that matter it's readily
compatible with there either being or not being evils that *look* gratuitous.  
  
So this just isn't a case of saying that if E is evidence against H, then ~E
must be evidence for H.  
  
And if you aren't reasoning from that probabilistic fact, I'm not seeing how
you're getting so quickly to the conclusion that, "There is a token evil that
lacks property F" must be evidence for theism.

I'm going by the fact that you said that "by Bayesianism" P(E has ∼F | God) >
P(E has ∼F | no God).  
  
So in the op you seemed to be stating this as somehow following from
"Bayesianism" in some direct, clear way from the axioms of probability and
something you had already said. And I'm just not seeing that at all. I really
think you must have been confusing (E has ~F) with ~(E has F). A scope shift
of the negation sign into the parentheses.

Lydia:  
  
1\. The post says that the background include that E has occurred. Given that
background (or given classical logic where all names, such as E, refer), ~(E
has F) is equivalent to (E has ~F).  
  
2\. You are apparently right about cats. I just googled "cat that looks like a
dog", and while I got a number of feline looking dogs, I didn't get any cats
that looked like dogs. But that surprised me! One would kind of expect that
the world's most doglike cat would look rather doglike. But I suppose not.  
  
3\. Regarding the "many evils" thing, I was taking it as part of the
background that there are many, many evils, and thinking that in the inductive
argument what we want to evaluate is the additional evidence arising from
those evils that appear gratuitous.  
  
4\. Some trivial evils look gratuitous and some do not. It's the
gratuitousness, not the triviality, that I am interested in. We can look at it
like this. Theism makes a controversial prediction: There are no gratuitous
evils. Some evils appear to confirm this prediction and others appear to
disconfirm it.  
  
5\. It is possible to make a direct argument on the basis of the existentially
quantified claim that there are gratuitous evils. But generally, that's not
what the literature starting with Rowe looks like. Most of that literature is
focused on specific example evils -- a fawn burning to death, etc. -- and
their apparent gratuitousness.

Alex,  
  
(I'll number these responses according to your numbering in your last comment
so I don't have to copy bits of them. Please excuse typos. In my current
technology set-up I'm particularly typo-prone and don't always see them.)  
  
Re #1: Not equivalent for the confirmation-theoretic purposes that you are
using it, no. In fact, the way that you are using it arguably commits a
confirmation-theoretic fallacy, because we are always required to
conditionalize on the most specific relevant version of the evidence we
possess. And the more specific evidence can point in a different direction
from the evidence as described in soft focus. To see this, consider an urn
model. In the set-up, there is a ball in the urn. That's given. There are
three possible colors the ball could be, all equiprobable--red, white, or
blue. We are given that if the ball is blue, this is evidence for H, if the
ball is white, it is neither evidence for nor against H, and if the ball is
red, it is evidence for ~H. From this set-up it follows that if *all we know*
is that the ball is non-blue, that proposition is evidence for ~H. However,
suppose that we draw the ball and find that it is white. While it is true that
being white entails being non-blue, it is *not* true that the evidence of the
draw of the ball supports ~H. Not everything that entails ~blue has the same
confirmation-theoretical consequences as ~blue has when that is all that we
know. This can be described as a failure of screening. "The ball is non-blue"
does not screen off the probabilistic impact/relevance of "the ball is white"
from H, even though "the ball is white" entails "the ball is non-blue."  
  
  
  
  
So, no, even if "this event has the property of being an evil that appears
gratuitous" is evidence against theism, it does not follow that any particular
evil E, with its further-known properties, is evidence *for* theism *merely*
in virtue of lacking the property of appearing gratuitous. Hence we should not
simply say that if we examine an evil and find it not to be gratuitous, that
is evidence for theism.  
  
  
Re. #2: For real things in the real world, it isn't generally possible
epistemically to tell from one's armchair whether "There are lots of As" makes
it probable that "Some real As look like Bs even though they aren't." That
*entirely* depends on what A and B are! (Hence my example of cats and
elephants.) I don't think any skeptic should ever grant that "there are lots
of evils" probabilifies that "some of them will appear gratuitous" much less
what presumably you need which is "some of them will appear gratuitous even
though they really aren't."  
  

(cont.)  
  
Re. #5: I'm not going to claim to know what is in Rowe's mind, and maybe you
are right to say that he and others aren't arguing from "There exists some
gratuitous evil." But the mere fact that they're focusing on specific
properties of specific events, like fawns burning in a forest, doesn't mean
that they aren't doing so. If I were doing that (focusing on specific
properties), I would be arguing approximately thus: Consider these specific
events of a type that undeniably occur. (E.g. Conscious creatures who have
done nothing wrong experience intense suffering; innocent people are corrupted
by evil-doers and ruin their lives. Etc.) These appear to be instances of
gratuitous evil. Therefore, it is highly probable that either these events
individually or a subset of them or a conjunction of some or all of them
constitutes *actual* gratuitous evil. The occurrence of actual gratuitous evil
is significant evidence against the existence of a good God.  
  
  
Btw, I'm sure it goes without saying (but I've been hanging out,
metaphorically speaking, with New Testament scholars for a few years, and they
tend to be more touchy than analytic philosophers usually are!)... This is all
meant in a spirit of enjoyable give and take. Someone directed me to this blog
post and there seemed to me something fishy about the arg., and I'm just
trying to work out what it is. There's nothing remotely personal in it, and I
hope we can run into one another again sometime.

Lydia:  
  
You are right that we should use the most specific information we have. But
sometimes the more specific information is something that we have no idea what
to do with--we don't have any insight into the relevant conditional
probabilities. For instance, in the lab you weigh a rat as part of a
nutritional experiment. You get a ton of other information than the weight of
the rat as part of that process: how cooperative is the rat in the weighing
process, what color does the rat have, etc. But you really don't know what to
do with this other data: you don't have good likelihoods for them on the
hypotheses you are investigating. So in the actual practice of science, you
delineate, ahead of time, which data you will measure and which data you
won't, and you use that.  
  
I'm thinking that apparent gratuitousness is a nice piece of data, because we
have a direct prediction from theism that all evils are non-gratuitous. The
other features of the evil besides gratuitousness or non-gratuitousness we
don't know much what to do with. And our best way to guess at gratuitousness
is apparent gratuitousness.  
  
So, in theory, lots of other stuff could be taken into account. But in
practice it's really hard to do that.  
  
By the way, some cats do look very much like elephants: early cat embryos. :-)  
  
But I take your point: maybe we can't always expect that there will be things
that look other than they are. Maybe all I can do is report my priors: I would
expect there to be SOME things that God would permit where I would have no
idea of what justifies them, just as I would expect there to be SOME steps
that a master craftsman in pretty much any discipline would do that I would
have no idea what the point of them is.

Alex, As I'll argue below, this is more than merely a theoretical point in
this case. First, tho', I'd like to point out that even the theoretical point
is important. The o.p. and even a follow-up comment seem to imply that it is a
simple matter of Bayesian probability theory that, if the appearance that some
evil is gratuitous is evidence against theism, the appearance that an event
agreed to be an evil fails to be gratuitous (though how we should pick out
*that* event while knowing nothing at first about its more specific properties
is a question in itself!) must be evidence *for* theism. Yet here we are,
discussing the far less straightforward issue of when and whether some more
specific information is relevant to confirmation! So it is *not* a simple and
direct consequence of Bayesianism, for the reason that I have stated--not
everything that entails some P has the same probabilistic consequences as that
which it entails. Hence, tho' "white all over" entails "non-blue all over,"
"white all over" may have very different probabilistic consequences than "non-
blue all over." And it's quite important to avoid this mistake in reasoning,
as it can lead us astray. Hence the technical point is important: "This evil
does not appear to be gratuitous" may well fail to be evidence for theism, due
to the evidence from which we concluded that "this evil does not appear to be
gratuitous," even in a situation where "This evil appears to be gratuitous"
would have been evidence against theism.  
  
Now, to show that this is not merely theoretical: If we are to treat "appears
to be gratuitous evil" as a property of an event (which I have a few
metaphysical doubts about since it seem like a Cambridge property at most, but
perhaps we can waive that) then "appears to be deserved" is a property and so
also is "appears to be of no moral importance." But either of these entails
"does not appear to be gratuitous evil." One of them, such as bad guys getting
their just deserts, might be said to be loosely evidence for theism,
Providence, karma, or something of the sort. We might also argue that "appears
to have brought about a greater good" is a "property" that would be favorable
to theism. But if a man who has done nothing to deserves it briefly stubs his
toe and suffers 60 seconds of easily-endured pain and nothing worse comes of
it, this is *also* a category of "does not appear to be gratuitous evil," due
in this case to its triviality, and arguably it is neither evidence for nor
against theism. So if we have some event in a black box labeled E for "an
evil," and we don't know before we open the black box what the specifics are
of the event (which frankly your set-up treats as the situation in question,
since the event is said to be a specific "evil" apart from its other
properties!), we may open it and find the specifics of it which turn out to be
such either that it seems to be evidence for or against theism or neither for
nor against. Hence the o.p. is incorrect, as far as I can tell.  
  
I'm inclined to agree with you that on theism there could well be some events
that we wrongly take to be gratuitous evil, but bringing in our experience
with master craftsmen, etc., is doing something quite a bit different than
"given that there are many evils, some of them are likely to appear
gratuitous." Rather, it's arguing for a particular likelihood given a
particular concept of God.

Lydia:  
  
'if a man who has done nothing to deserves it briefly stubs his toe and
suffers 60 seconds of easily-endured pain and nothing worse comes of it, this
is *also* a category of "does not appear to be gratuitous evil," due in this
case to its triviality':  
  
It's not that clear that this is in the category of "does not appear to be
gratuitous evil". An evil is gratuitous iff an omniscient and omnipotent being
would have had sufficient moral reason not to prevent it. Triviality is not by
itself a sufficient moral reason not to prevent an evil. (Suppose there is a
heavy object on the floor of a room, and you've seen five out of five people
walking into the room stubbing their toes on it. You expect one more person to
walk in. If you put a chair in front of the object, it'll prevent that person
from stubbing their toe. The effort to put in the chair is even more trivial
than the unpleasantness of the stubbing, so you should put in the chair.)  
  
Maybe, though, you are thinking this: if an evil is trivial, it takes a very
small reason to justify permitting it, and we cannot have much confidence that
God wouldn't have such a reason not to prevent it. So if the evil is trivial,
it won't be the case that it appears gratuitous (though it also won't appear
non-gratuitous). Is that what you're thinking?  
  
All that said, I think what I was imagining is something like this. You have a
block box labeled "evil". You get to ask an honest human expert who was able
to examine the contents of the box: "Does the thing in the box appear
gratuitous?" And then we look at the evidence coming from the answer.  
  
Now, you are quite right that in practice there is other evidence available.
There can be evils that don't positively appear gratuitous but nonetheless
could be some evidence against the existence of God: the toe-stubbing could be
like that (on my suggested way to make the case work). Conversely, there can
be evils that appear gratuitous but are evidence for the existence of God.
Suppose a Roman guard observed the resurrection of Jesus but then lied about
it. Let E = the Roman guard lied that he didn't see Jesus resurrected. It
could be that E appears gratuitous. However, E may nonetheless be evidence for
theism, because E entails that the guard thought that he saw Jesus
resurrected, and that could add more evidence to theism than the apparent
gratuitousness of E adds to atheism.  
  
But whatever other evidence may or may not be available, it is worth examining
what the evidential impact of the appearance of gratuitousness _by itself_ is.  
  
Now let's come back to the probability that some evil would look gratuitous,
and let me see if I can improve my argument. Take a billion items, and suppose
that humans are supposed to judge if one of the items has some property H.
Suppose that a part of the background is that determining that an item has H
is not trivial and determining that an item has non-H is also not trivial.
Then, absent further evidence, we would expect at least one error of judgment,
regardless of whether all the items have H, none of the items have H, or some
but not all the items have H.  
  
But determining an evil to be gratuitous is non-trivial and determining an
evil to be non-gratuitous is non-trivial. So, absent further evidence, given
billions of evils (a typical person suffers and/or perpetrates at least one
evil per day, I assume), we would expect some cases of erroneous judgment,
even if all evils are non-gratuitous. Hence, even if all evils are non-
gratuitous, we would expect some cases where humans judge an evil gratuitous,
and hence the evil appears gratuitous to them.  
  
(This is assuming that standard facts about human error-proneness are in the
background. One might think that these facts are themselves evidence against
theism. Examining the import of that evidence is a separate task.)  
  
So, I agree with you that we can't JUST use the number of cases by itself. We
need some kind of non-triviality constraint.

Alex,  
  
As I understand your most recent comment, you are taking "appears non-
gratuitous" to be something to the effect that we somehow have a very strong
intuition that everyone (or almost everyone?) will agree with that the evil is
not gratuitous. Your example in the o.p. was of a robber baron getting a tummy
ache from eating too much caviar. My guess is that you were clueing there to
the aptness of the tummy ache to the crimes that enabled him to eat too much
caviar, coupled with the fact that a tummy ache isn't that bad. (So it's not
like he's getting tortured to death.) Poetic justice. Hence you assume that
everyone will agree that that is non-gratuitous.  
  
However, as you see even from the toe-stubbing incident, this is not always a
simple matter. I would argue that pretty much everyone would agree that a good
man stubbing his toe and suffering no more than 60 seconds of typical toe-
stubbing pain is not gratuitous simply because of the intuition that it is of
such little moral weight that God doesn't need a reason not to intervene.
Perhaps on the well-known principle embodied in the saying of Horace, "Let not
a god intervene unless there be a knot worthy of a god's untying."  
  
I think it's safe to say that Rowe would be unlikely to use an innocent man's
non-damaging toe stubbing as an example for his evidential POE. Your whole
point in the o.p. concerns the properties of evils in Rowe-style arguments,
and these seem to focus on particularly bad things happening to innocent
conscious being.  
  
In any event, the very fact that we can disagree about whether or not the toe
stubbing has the property of "appears to be non-gratuitous" shows that the
particulars matter and that evils don't divide neatly between "appears clearly
to be gratuitous" and "appears clearly to be non-gratuitous." There's a third
category (and maybe a fourth category too, depending on how we carve it up)
that includes cases where reasonable person A will think it fails to be
gratuitous and reasonable person B will think that it is. If we take Rowe-
style cases (babies dying in horrible pain, fawns burning to death in the
woods) to be "clearly appears to be gratuitous," then we can agree that those
are interesting in themselves and studying cases that have that property is
interesting in itself.  
  
But please remember that your o.p. gave the strong impression that you were
considering "appears gratuitous" and "appears not gratuitous" to constitute a
partition of evils, so that any evil that does not appear to be gratuitous
automatically appears to be non-gratuitous, so that "by Bayesianism" we can
find confirmation of theism from every evil that fails to appear gratuitous a
la "fawn burning in the forest." Our conversation here has shown that it is no
such simple matter. It isn't as though every evil that isn't like a baby dying
in horrible pain is automatically like a bad guy getting his just deserts or
serving a higher good and therefore something that we can see to be plausible
confirmation of theism. Even your "honest human witness" who looks in the
black box may give you a "no" answer to "does the evil in the box appear to be
gratuitous" and then, if you say, "Oh, good, then it's evidence for theism" he
may well demur, due to the fact that there are more relevant categories than
"appears to be gratuitous [hence is prima facie evidence against theism]" and
"fails to appear gratuitous [hence is prima facie evidence for theism]." I
just have to stress that this is a simplistic way of looking at it and
definitely doesn't drop out of the probability axioms.

I think by non-trivial concerning judgements, what you're intending to build
in is something like "not easy." So if a judgement is not trivially easy to
make for some type of being, then we'd expect some errors by that type of
being over a long run of making such judgements. That's obviously true if for
no other reason than that you're building the difficulty and hence the
probability of error into the model from the beginning. So if two animals
really do look similar from a certain distance, then if people are trying to
distinguish them over and over from that distance they are bound to make some
errors doing so over the long run. That's fine, and granted.  
  
But notice that *this* argument now simply *confirms* the point I'm making
about the larger argument, which is that evils don't come merely in two
varieties--really looks gratuitous and hence is evidence against theism" and
"really looks non-gratuitous and hence is evidence for theism." If you are
going to say that it's hard to make that judgement, then it seems that you
should add a middle category at least, "Does not appear to be evidence for or
against theism." Rather as if a person saw an animal from a sufficient
distance and said that, *at that distance and in that lighting*, he would not
say that it looked like a racoon rather than a woodchuck.

Lydia:  
  
I have tried to avoid language like "Does not appear to be gratuitous",
because in English it is ambiguous between "Not (Appears to be gratuitous)"
and "Appears to be non-gratuitous". My original argument concerned "Not
(Appears to be gratuitous)".  
  
I wouldn't take the Horace line uncritically. Maybe, though, we can say that a
regularity theodicy easily handles very minor evils: the fact that preventing
these evils would disturb the regularity of nature gives God a sufficient
moral reason not to prevent them, given the value of the regularity of nature.  
  
I think at the end you make a rather interesting point that does affect my
post significantly. If the witness observing the contents of the box instead
of giving us a binary "appears gratuitous" / "not (appears gratuitous)" gives
us a ternary judgment "appears gratuitous" / "appears non-gratuitous" /
"neither appears gratuitous nor appears non-gratuitous", then things are
different. Intuitively, "appears gratuitous" is evidence against theism,
"appears non-gratuitous" is evidence for theism, and "neither appears
gratuitous nor appears non-gratuitous" is either neutral or weaker evidence
against theism.  
  
It's still true that even on the ternary approach nobody has done a credible
job consolidating all the evidence. My vague intuition is that "neither"
outnumbers "appears gratuitous" which in turn outnumbers "appears non-
gratuitous". But since we don't really have good numbers for the conditional
probabilities of all three on theism/atheism, I don't know what that adds up
to on the whole.  
  
Another way of thinking about this is to replace the witness's judgment with
"I can't think of any plausible theodicy" / "I can think of a plausible
theodicy". Then it sounds more like the binary way of thinking about it is
appropriate, but even so, in practice, there will be a richer set of options:
"I can think of three higly pausible theodicies", "I can think of one barely
plausible theodicy", "I can't think of any theodicy that's close to being
plausible". But maybe we have clearer likelihoods for the binary cases than
for the richer ones and we should go for the binary ones.  
  
There are difficult questions for Bayesianism in the vicinity: What should we
do when we cannot conditionalize on our total evidence because we don't have
the relevant likelihoods? Should we conditionalize on the largest available
set of evidence for which we do have the likelihoods? Or should we just give
up and not conditionalize at all?

" My original argument concerned "Not (Appears to be gratuitous)"."  
  
Yes, that's how I took it originally. Which is why I've been pushing all along
the point that that is a fairly broad category which, arguably, includes
things (maybe even many things) that appear intuitively to be neither evidence
for nor against theism.  
  
What I said about the witness looking into the box is just another way of
saying what I've been saying all along. It's a way of getting past the
strangeness of the whole black-box approach and trying to get closer to what I
think is the true epistemic state, in which we are confronted not with events
designated with total vagueness as "evils" and then simply told baldly that
they either do or don't appear to someone else to be gratuitous but rather are
confronted with concrete envisaged events or event-types which we then
intuitively judge as to whether they seem like gratuitous evils or not. After
all, Rowe uses concrete examples! He doesn't just say, "Take my word for it
that I've looked at some actual evils and I'm here to tell you that they look
like gratuitous evil to me, never mind the particulars of what this would be
like." Which would then be countered by some Christian philosopher saying,
"Well, *I've* looked at a *lot* of other evils and they appear to me to be the
result of a wise and just Providence, never mind what the particulars are, so
there." That would never make a philosophical debate! Which is why the whole
"witness looking into a black box" thing is super-odd as an approach. My
suggestion of a witness that gives you one of three judgements was another
attempt to make it somewhat less artificial in order to bring home what I've
been saying all along is a problem with the o.p.--namely, that not every evil
that fails to appear to be gratuitous is ipso facto evidence against theism,
and that I can think of quite a few examples thereof.  
  
Your last questions are of course big ones. It seems to me a good deal easier
in empirical cases, since then we hope to be able to gather more empirical
evidence to flesh out our likelihoods. But one point I would make: It isn't
always necessary to have separate P(E|H) and P(E|~H) in order to access
P(E|H)/P(E|~H). Tim and I have both pointed out that an estimate of the ratio
is often more accessible than the separate likelihoods. For example, if I get
an e-mail from a new person that gives me some sort of Russellian definite
description for him (e.g., a name, an interest or question he has for me) and
that appears to come from a real individual, it is *much* easier to see (IMO)
that this e-mail is much more probable given that such an individual exists
than given that no such individual exists than it is to estimate separately
what the probability of the e-mail would be if he existed and what the
probability would be if he didn't exist.  
  
How exactly that applies to the evidential POE I'm not sure, but I think it
has lots of applications in design arguments.  

What I get for not proofreading before I hit publish:  
  
Should be, "not every evil that fails to appear to be gratuitous is ipso facto
evidence *for* theism, and that I can think of quite a few examples thereof."

Lydia:  
  
It's a good point that the Bayes' ratio can get a decent estimate even when
the numerator and denominator can't. I'll need to think about that.  
  
Thanks for all the great comments. You've made me realize that this is a lot
more complicated than I thought.

If God is not simple, then some of God’s parts are creatures.

If some of the parts of _x_ are creatures, then _x_ is partly a creature.

I think (2) is very plausible. Premise (3) follows from the transcedence of
God.

That leaves premise (1) to argue for. Here is one argument:

If God is not simple, then God has a part that is not God.

So, if God is not simple, then God has a part that is a creature.

Premise (5) is true by definition of “simple”. Premise (6) follows from the
doctrine of creation: God creates everything other than God.

But perhaps one doesn’t believe the full doctrine of creation, but only thinks
that contingent things are created. I think we can still argue as follows:

If God is not simple, then God has contingent parts that are not God.

So, if God is not simple, then God has a part that is not God.

Why think (8) is true? Well, let’s think about the motivations for denying
divine simplicity. The best reasons to deny divine simplicity are
considerations about God’s contingent intentions or God’s contingent
knowledge, and the idea that these have to constitute proper parts of God. But
that yields _contingent_ parts of God.

Now, what if one rejects even the weaker doctrine of creation in (9)? Then I
can argue as follows:

If God is not simple, then God’s contingent thoughts are proper parts of God.

God is contingently the cause of each of his contingent thoughts.

Anything that God is contingently the cause of is a creature of God.

So, if God is not simple, then God has a part that is not God.

Again, the idea behind (11) is that it flows from the best motivations for
denying divine simplicity.

It seems to me that the person who denies divine simplicity would want to say,
instead of (6), (9), or (13), something like "Anything that is outside of God
is a creature of God" where by "outside of God" one means "not God and not a
part of God". Or perhaps even more modestly "Any substance which is not God is
a creature of God".

Alex  
  
Or perhaps one argue that God's 'parts' are not contingent but necessary.

I wonder how this relates to God's free act of creation. If we assume God has
indeterministic self-motion as the principle of contingent actions like
creating the world, would this fall into the category of contingently caused
thoughts or whatnot, thereby making them parts of God and creatures in this
sense?  
  
How would you interpret the contingency of God's act of creating the world
(especially if it's logically prior to the world's existence, or internal to
God as an action on His part)?

Walter:  
  
Yeah, but the best arguments against divine simplicity have to do with
contingent parts.  
  
Wesley:  
  
I think what is contingent is the effect of the action, while the action
itself is necessary (and identical with God). The intentional content of the
action then is partly grounded in the effect.

Unknown:  
  
This is hardest to do for (13), since it seems analytic that if God
contingently causes something, that something is a creature.

Isn't a wholesale denial of any proper parts, ala WLC, an easy way out of this
argument?

Daryl:  
  
I don't follow. That's what the conclusion is: God is simple, i.e., has no
proper parts.

Alex: A couple of questions come to mind - if God's act of creation itself is
necessary, does this mean that the existence of some creation is necessary,
just not the specific creation that comes about?  
  
As for the intention to create being constituted by the effect, couldn't one
object that this gets the logical hierarchy wrong as intentions are supposed
to be logically prior to the effects that are intended? So saying the effect
is logically prior to the intention ends up basically saying that God didn't
intend creation initially, and it somehow was just...caused?  
  
About the intention being partially based in the effect, an intention by
itself seems not to be indeterministic in the sense that an effect can obtain
completely different from the intention, and since God is omnipotent, nothing
He intends internally in Himself can fail to obtain.  
  
What do you think?

God's act of creation, A, is identical to God. It is not necessary that A be
an act productive of anything external to God.

Then God does not have to be personal, because a quantum vacuum can work in
the same way.  
It doesn't have to be productive of anything external to it either.  
God's act of creation A can be productive of a,b,c ...or nothing at all.
Whatever is the result of A is purely random chance.  
This is one of the best arguments against a personal God. I have ever
encountered.  
  
  
  
  

Dr. Pruss, I was wondering what you thought of Aquinas argument for God in his
De Ente Et Essentia? It seems that he is arguing that because a things essence
is distinct from its existence it needs to be caused to exist by something
that has no distinction between its essence and existence. It seems that if
this argument is successful it would be a good reason to accept divine
simplicity as well as the need for God to concurrently cause anything that
creatures do.

I defend a version of the argument in my PSR book. I think the difficulty with
the argument is that the atheist may say that some finite things have an
existence distinct from the essence, and with all three of existence, essence
and their conjoining being uncaused. In the PSR book I try to argue against
this. I can't remember exactly how.  
  
How do you think the argument establishes the need for concurrence?

I believe the idea is that some properties come from the essence of creatures
while others do not. Humans have the power to have children and this power
does not rely on the previous generations of humans still existing because the
creature has the power in itself. Existence however is not something that
comes from the essence of the creature in itself because the essence would
already have to exist in order to cause its existence. Because the existence
does not come from the essence of the creature it is naturally nothing and
would require existence to be given for any moment it exists. It would seem
that if successful this would require God to conserve our existence and concur
with our actions in order for them to exist at all.

That would be an argument for conservation, but I don't see how it would be an
argument for concurrence. Suppose that I break a window with a stick. The
argument might show that God's sustenance of me, the window and the stick is
needed. But I don't see that it shows that God's concurrence with the stick's
actualization of the causal power for a broekn window is needed.

